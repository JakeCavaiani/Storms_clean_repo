DOD.2019$datetimeAK <- ymd_hms(DOD.2019$datetimeAK) # converting character to datetime
DOD.2019$datetimeAK <- force_tz(DOD.2019$datetimeAK, "America/Anchorage") # converting character to datetime
# POKE ####
POKEstorm_file_list <- list.files(path = "All_sites/",
recursive=F,
pattern="POKE",
full.names=TRUE)
POKE_storms<-do.call("rbind", lapply(POKEstorm_file_list,
read.csv,
check.names = FALSE,
stringsAsFactors=FALSE,
header=T, blank.lines.skip = TRUE, fill=TRUE))
POKE_storms$storm.num = c(rep("storm1", 103),
rep("storm2", 91),
rep("storm3", 147),
rep("storm4", 115),
rep("storm5a", 327),
rep("storm5c", 111),
rep("storm5d", 99),
rep("storm6a", 283),
rep("storm7", 235),
rep("storm8", 95),
rep("storm9", 211))
POKE_storms$DateTime <- as.POSIXct(POKE_storms$DateTime)
POKE.2019.storms.1<- left_join(POKE_storms, POKE_RainGauge_2019, by = "DateTime")
POKE.2019.storms.1<- left_join(POKE.2019.storms.1, airtempmean, by = "DateTime")
names(POKE.2019.storms.1)[names(POKE.2019.storms.1) == ''] <- 'x'
POKE.2019.per.storm.1 <- POKE.2019.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(inst_rainfall_mm), list(precip = sum), na.rm = TRUE)
temp <- POKE.2019.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(airtemp_100.1000cm_mean), list(temp = mean), na.rm = TRUE) # finding the mean temperature for each storm event
POKE.2019.per.storm.1$temp <- temp$temp
POKE.2019 <-  subset(DOD.2019, site.ID == "POKE")
POKE.2019$DateTime <- as.POSIXct(POKE.2019$datetimeAK, tz = "America/Anchorage", format = "%Y-%m-%d %H:%M")
POKE.2019 <- left_join(POKE.2019, POKE_RainGauge_2019, by = "DateTime")
POKE.2019 <- left_join(POKE.2019, airtempmean, by = "DateTime")
POKE.2019$week <- rollapplyr(POKE.2019$inst_rainfall_mm, 672, sum, na.rm = TRUE, fill = NA, partial = TRUE)
POKE.2019$month <- rollapplyr(POKE.2019$inst_rainfall_mm, 2688, sum, na.rm = TRUE, fill = NA, partial = TRUE)
POKE.2019$ThreeMonth <- rollapplyr(POKE.2019$inst_rainfall_mm, 8064, sum, na.rm = TRUE, fill = NA, partial = TRUE)
POKE.2019$temp.week <- rollapplyr(POKE.2019$airtemp_100.1000cm_mean, 672, mean, na.rm = TRUE, fill = NA, partial = TRUE)
POKE.2019.1 <- left_join(POKE.2019.storms.1, POKE.2019, by = "DateTime") # week month and 3 month precip totals
POKE.2019.per.storm.2 <- POKE.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(week), list(precip.week = first), na.rm = TRUE) # grouping weekly precip leading up to storm event
POKE.2019.per.storm.3 <- POKE.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(month), list(precip.month = first), na.rm = TRUE) # groouping monthly precip leading up to a storm
POKE.2019.per.storm.4 <- POKE.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(ThreeMonth), list(ThreeMonth = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
POKE.2019.per.storm.5 <- POKE.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(temp.week), list(temp.week = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.mean.precip.poke.NO3 <- subset(HI.mean.precip.response, year == "2019" & site.ID == "POKE" & response == "NO3")
HI.mean.precip.poke.fDOM <- subset(HI.mean.precip.response, year == "2019" & site.ID == "POKE" & response == "fDOM")
HI.mean.precip.poke.SPC <- subset(HI.mean.precip.response, year == "2019" & site.ID == "POKE" & response == "SPC")
HI.mean.precip.poke.turb <- subset(HI.mean.precip.response, year == "2019" & site.ID == "POKE" & response == "turb")
HI.mean.precip.poke.abs <- subset(HI.mean.precip.response, year == "2019" & site.ID == "POKE" & response == "abs")
HI.poke.no3.2019 <- left_join(HI.mean.precip.poke.NO3, POKE.2019.per.storm.1, by = "storm.num")
HI.poke.no3.2019 <- left_join(HI.poke.no3.2019, POKE.2019.per.storm.2, by = "storm.num")
HI.poke.no3.2019 <- left_join(HI.poke.no3.2019, POKE.2019.per.storm.3, by = "storm.num")
HI.poke.no3.2019 <- left_join(HI.poke.no3.2019, POKE.2019.per.storm.4, by = "storm.num")
HI.poke.no3.2019 <- left_join(HI.poke.no3.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.no3 <- lm(HI.poke.no3.2019$HI ~ HI.poke.no3.2019$precip) # model one with just total precip
poke.lm.no3.2 <- lm(HI.poke.no3.2019$HI ~ HI.poke.no3.2019$precip.week) # model one with just total precip
poke.lm.no3.3 <- lm(HI.poke.no3.2019$HI ~ HI.poke.no3.2019$precip.month) # model one with just total precip
poke.lm.no3.4 <- lm(HI.poke.no3.2019$HI ~ HI.poke.no3.2019$ThreeMonth) # model one with just total precip
poke.formula <- y ~ x
pa <- HI.poke.no3.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
pb <- HI.poke.no3.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("One-weeek Precip") +
ylab("HI-Solute Storage") # plot model
pc <- HI.poke.no3.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
pd <- HI.poke.no3.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.poke.fDOM.2019 <- left_join(HI.mean.precip.poke.fDOM, POKE.2019.per.storm.1, by = "storm.num")
HI.poke.fDOM.2019 <- left_join(HI.poke.fDOM.2019, POKE.2019.per.storm.2, by = "storm.num")
HI.poke.fDOM.2019 <- left_join(HI.poke.fDOM.2019, POKE.2019.per.storm.3, by = "storm.num")
HI.poke.fDOM.2019 <- left_join(HI.poke.fDOM.2019, POKE.2019.per.storm.4, by = "storm.num")
HI.poke.fDOM.2019 <- left_join(HI.poke.fDOM.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.fDOM <- lm(HI.poke.fDOM.2019$HI ~ HI.poke.fDOM.2019$precip) # model one with just total precip
poke.lm.fDOM.2 <- lm(HI.poke.fDOM.2019$HI ~ HI.poke.fDOM.2019$precip.week) # model one with just total precip
poke.lm.fDOM.3 <- lm(HI.poke.fDOM.2019$HI ~ HI.poke.fDOM.2019$precip.month) # model one with just total precip
poke.lm.fDOM.4 <- lm(HI.poke.fDOM.2019$HI ~ HI.poke.fDOM.2019$ThreeMonth) # model one with just total precip
pe <- HI.poke.fDOM.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
pf <- HI.poke.fDOM.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
pg <- HI.poke.fDOM.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
ph <- HI.poke.fDOM.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.poke.SPC.2019 <- left_join(HI.mean.precip.poke.SPC, POKE.2019.per.storm.1, by = "storm.num")
HI.poke.SPC.2019 <- left_join(HI.poke.SPC.2019, POKE.2019.per.storm.2, by = "storm.num")
HI.poke.SPC.2019 <- left_join(HI.poke.SPC.2019, POKE.2019.per.storm.3, by = "storm.num")
HI.poke.SPC.2019 <- left_join(HI.poke.SPC.2019, POKE.2019.per.storm.4, by = "storm.num")
HI.poke.SPC.2019 <- left_join(HI.poke.SPC.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.SPC <- lm(HI.poke.SPC.2019$HI ~ HI.poke.SPC.2019$precip) # model one with just total precip
poke.lm.SPC.2 <- lm(HI.poke.SPC.2019$HI ~ HI.poke.SPC.2019$precip.week) # model one with just total precip
poke.lm.SPC.3 <- lm(HI.poke.SPC.2019$HI ~ HI.poke.SPC.2019$precip.month) # model one with just total precip
poke.lm.SPC.4 <- lm(HI.poke.SPC.2019$HI ~ HI.poke.SPC.2019$ThreeMonth) # model one with just total precip
pi <- HI.poke.SPC.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
pj <- HI.poke.SPC.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
pk <- HI.poke.SPC.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
pl <- HI.poke.SPC.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.poke.turb.2019 <- left_join(HI.mean.precip.poke.turb, POKE.2019.per.storm.1, by = "storm.num")
HI.poke.turb.2019 <- left_join(HI.poke.turb.2019, POKE.2019.per.storm.2, by = "storm.num")
HI.poke.turb.2019 <- left_join(HI.poke.turb.2019, POKE.2019.per.storm.3, by = "storm.num")
HI.poke.turb.2019 <- left_join(HI.poke.turb.2019, POKE.2019.per.storm.4, by = "storm.num")
HI.poke.turb.2019 <- left_join(HI.poke.turb.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.turb <- lm(HI.poke.turb.2019$HI ~ HI.poke.turb.2019$precip) # model one with just total precip
poke.lm.turb.2 <- lm(HI.poke.turb.2019$HI ~ HI.poke.turb.2019$precip.week) # model one with just total precip
poke.lm.turb.3 <- lm(HI.poke.turb.2019$HI ~ HI.poke.turb.2019$precip.month) # model one with just total precip
poke.lm.turb.4 <- lm(HI.poke.turb.2019$HI ~ HI.poke.turb.2019$ThreeMonth) # model one with just total precip
pm <- HI.poke.turb.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
pn <- HI.poke.turb.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
po <- HI.poke.turb.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
pp <- HI.poke.turb.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
sum.time <- POKE.2019.storms.1 %>%
mutate(grp=data.table::rleid(storm.num))%>%
group_by(grp) %>%
summarise(storm.num=max(storm.num),TOTAL.TIME=difftime(max(DateTime),
min(DateTime),units="hour"))%>%
group_by(storm.num) %>%
summarise(TOTAL.TIME=sum(TOTAL.TIME)) # creating a total time column
HI.poke.no3.2.2019 <- left_join(HI.poke.no3.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.poke.no3.2.2019$TOTAL.TIME <- as.numeric(HI.poke.no3.2.2019$TOTAL.TIME)
HI.poke.no3.2.2019$Intensity <- HI.poke.no3.2.2019$precip/HI.poke.no3.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
poke.lm.no3.2 <- lm(HI.poke.no3.2.2019$HI ~ HI.poke.no3.2.2019$precip + HI.poke.no3.2.2019$Intensity) # model one with total precip and intensity
pq <- HI.poke.no3.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.fDOM.2.2019 <- left_join(HI.poke.fDOM.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.poke.fDOM.2.2019$TOTAL.TIME <- as.numeric(HI.poke.fDOM.2.2019$TOTAL.TIME)
HI.poke.fDOM.2.2019$Intensity <- HI.poke.fDOM.2.2019$precip/HI.poke.fDOM.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
poke.lm.fDOM.2 <- lm(HI.poke.fDOM.2.2019$HI ~ HI.poke.fDOM.2.2019$precip + HI.poke.fDOM.2.2019$Intensity) # model one with total precip and intensity
pr <- HI.poke.fDOM.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.SPC.2.2019 <- left_join(HI.poke.SPC.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.poke.SPC.2.2019$TOTAL.TIME <- as.numeric(HI.poke.SPC.2.2019$TOTAL.TIME)
HI.poke.SPC.2.2019$Intensity <- HI.poke.SPC.2.2019$precip/HI.poke.SPC.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
poke.lm.SPC.2.2019 <- lm(HI.poke.SPC.2.2019$HI ~ HI.poke.SPC.2.2019$precip + HI.poke.SPC.2.2019$Intensity) # model one with total precip and intensity
ps <- HI.poke.SPC.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.turb.2.2019 <- left_join(HI.poke.turb.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.poke.turb.2.2019$TOTAL.TIME <- as.numeric(HI.poke.turb.2.2019$TOTAL.TIME)
HI.poke.turb.2.2019$Intensity <- HI.poke.turb.2.2019$precip/HI.poke.turb.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
poke.lm.turb.2 <- lm(HI.poke.turb.2.2019$HI ~ HI.poke.turb.2.2019$precip + HI.poke.turb.2.2019$Intensity) # model one with total precip and intensity
pt <- HI.poke.turb.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
# day of year #
POKE.2019.1$day <- julian(POKE.2019.1$DateTime, origin = as.POSIXct('2019-01-01', tz = 'America/Anchorage')) # making a fractional day column
POKE.2019.1$day <- as.numeric(POKE.2019.1$day)
POKE.2019.per.storm.5 <- POKE.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(day), list(doy = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.poke.no3.2.2019 <- left_join(HI.poke.no3.2.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.no3.5 <- lm(HI.poke.no3.2.2019$HI ~ HI.poke.no3.2.2019$doy)
pu <- HI.poke.no3.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE NO3") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.fDOM.2.2019 <- left_join(HI.poke.fDOM.2.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.fDOM.5 <- lm(HI.poke.fDOM.2.2019$HI ~ HI.poke.fDOM.2.2019$doy)
pv <- HI.poke.fDOM.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE fDOM") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.SPC.2.2019 <- left_join(HI.poke.SPC.2.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.SPC.5 <- lm(HI.poke.SPC.2.2019$HI ~ HI.poke.SPC.2.2019$doy)
pw <- HI.poke.SPC.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE SPC") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.poke.turb.2.2019 <- left_join(HI.poke.turb.2.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.turb.5 <- lm(HI.poke.turb.2.2019$HI ~ HI.poke.turb.2.2019$doy)
px <- HI.poke.turb.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("POKE turb") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
#plot_grid(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj,pk,pl,pm,pn,po,pp,pq,pr,ps,pt,pu,pv,pw,px,
#  ncol = 4)
# abs #
HI.poke.abs.2019 <- left_join(HI.mean.precip.poke.abs, POKE.2019.per.storm.1, by = "storm.num")
HI.poke.abs.2019 <- left_join(HI.poke.abs.2019, POKE.2019.per.storm.2, by = "storm.num")
HI.poke.abs.2019 <- left_join(HI.poke.abs.2019, POKE.2019.per.storm.3, by = "storm.num")
HI.poke.abs.2019 <- left_join(HI.poke.abs.2019, POKE.2019.per.storm.4, by = "storm.num")
HI.poke.abs.2019 <- left_join(HI.poke.abs.2019, POKE.2019.per.storm.5, by = "storm.num")
poke.lm.abs <- lm(HI.poke.abs.2019$HI ~ HI.poke.abs.2019$precip) # model one with just total precip
poke.lm.abs.2 <- lm(HI.poke.abs.2019$HI ~ HI.poke.abs.2019$precip.week) # model one with just total precip
poke.lm.abs.3 <- lm(HI.poke.abs.2019$HI ~ HI.poke.abs.2019$precip.month) # model one with just total precip
poke.lm.abs.4 <- lm(HI.poke.abs.2019$HI ~ HI.poke.abs.2019$ThreeMonth) # model one with just total precip
poke.lm.abs.5 <- lm(HI.poke.turb.2019$HI ~ HI.poke.turb.2019$temp.week) # model one with just total precip
HI.poke.abs.2.2019 <- left_join(HI.poke.abs.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.poke.abs.2.2019$TOTAL.TIME <- as.numeric(HI.poke.abs.2.2019$TOTAL.TIME)
HI.poke.abs.2.2019$Intensity <- HI.poke.abs.2.2019$precip/HI.poke.abs.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
HI.poke.2019 <- rbind(HI.poke.no3.2.2019, HI.poke.fDOM.2.2019,
HI.poke.SPC.2.2019, HI.poke.turb.2.2019,
HI.poke.abs.2.2019) # merging all responses together
HI.poke.2019$burn <- "burned" # adding a burn column
HI.poke.2019$pf <- "medium" # adding a pf column
write.csv(HI.poke.2019, here("Output_from_analysis", "04_Antecedent_Conditions", "2019", "HI.poke.2019.csv"))
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2019")
storm_file_list_beta <- list.files(path="FRCH_MOOS_VAUL_POKE_STRT_CARI/",
recursive=F,
pattern=".csv",
full.names=TRUE)
storm_list_beta<-do.call("list", lapply(storm_file_list_beta,
read.csv,
stringsAsFactors=FALSE,
header=T, row.names=1))
storm_file_list_beta = sub("FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
storm_file_list_beta = sub(".csv", storm_file_list_beta, replacement = "")
names(storm_list_beta) = storm_file_list_beta
FRCH_storm_list_beta = storm_list_beta[c(1:72)] #72
POKE_storm_list_beta = storm_list_beta[c(73:138)] # 66
STRT_storm_list_beta = storm_list_beta[c(139:204)] # 66
VAUL_storm_list_beta = storm_list_beta[c(205:264)] # 60
POKE_NO3_storm_list_beta = POKE_storm_list_beta[c(grep("NO3", names(POKE_storm_list_beta)))]
POKE_fDOM_storm_list_beta = POKE_storm_list_beta[c(grep("fDOM", names(POKE_storm_list_beta)))]
POKE_SpCond_storm_list_beta = POKE_storm_list_beta[c(grep("SPC", names(POKE_storm_list_beta)))]
POKE_turb_storm_list_beta = POKE_storm_list_beta[c(grep("Turb", names(POKE_storm_list_beta)))]
POKE_abs_storm_list_beta = POKE_storm_list_beta[c(grep("abs", names(POKE_storm_list_beta)))]
POKE_Q_storm_list_beta = POKE_storm_list_beta[c(grep("Q", names(POKE_storm_list_beta)))]
# POKE
for(i in 1:length(POKE_Q_storm_list_beta)){
POKE_Q_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_Q_storm_list_beta[[i]][["datavalue"]]-min(POKE_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(POKE_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(POKE_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(POKE_NO3_storm_list_beta)){
POKE_NO3_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_NO3_storm_list_beta[[i]][["datavalue"]]-min(POKE_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=TRUE))/
(max(POKE_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=TRUE)-min(POKE_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=TRUE))
}
for(i in 1:length(POKE_fDOM_storm_list_beta)){
POKE_fDOM_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_fDOM_storm_list_beta[[i]][["datavalue"]]-min(POKE_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(POKE_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(POKE_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(POKE_SpCond_storm_list_beta)){
POKE_SpCond_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_SpCond_storm_list_beta[[i]][["datavalue"]]-min(POKE_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(POKE_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(POKE_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(POKE_turb_storm_list_beta)){
POKE_turb_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_turb_storm_list_beta[[i]][["datavalue"]]-min(POKE_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(POKE_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(POKE_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(POKE_abs_storm_list_beta)){
POKE_abs_storm_list_beta[[i]][["datavalue.norm"]] =
(POKE_abs_storm_list_beta[[i]][["datavalue"]]-min(POKE_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(POKE_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(POKE_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
POKE_NO3_storm <- map2_df(POKE_Q_storm_list_beta, POKE_NO3_storm_list_beta, inner_join, by = "valuedatetime")
# POKE #
POKE_NO3_storm$storm.ID = c(rep("storm1", 103),
rep("storm2", 91),
rep("storm3", 147),
rep("storm4", 115),
rep("storm5a", 327),
rep("storm5c", 111),
rep("storm5d", 99),
rep("storm6a", 283),
rep("storm7", 235),
rep("storm8", 95),
rep("storm9", 211))
