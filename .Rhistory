import pickle
import pandas
import pickle
import pandas
import pandas as pd
import datetime
from hysteresis_metrics import hysteresisMetrics
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
quit()
FRCH_storm1_07_01_Q = pd.read_csv("~/Documents/Storms_clean_repo/Storm_Events/2015/FRCH/FRCH_storm1_07_01_Q.csv")
FRCH_storm1_07_01_Q = pd.read_csv(here("Storm_events", "2015", "FRCH", "FRCH_storm1_07_01_Q.csv"))
FRCH_storm1_07_01_Q = pd.read_csv(here("Storm_events", "2015", "FRCH", "FRCH_storm1_07_01_Q.csv"))
FRCH_storm1_07_01_Q = pd.read_csv("Storm_Events/2015/FRCH/FRCH_storm1_07_01_Q.csv")
FRCH_storm1_07_01_Q = pd.read_csv("~/GitHub/Storms_clean_repo/Storm_Events/2015/FRCH/FRCH_storm1_07_01_Q.csv")
here
here()
from pyprojroot.here import here
import pyprojroot
from pyprojroot.here import here
FRCH_storm1_07_01_Q <- pd.read_csv(here("Storm_events", "2015", "FRCH", "FRCH_storm1_07_01_Q.csv"))
FRCH_storm1_07_01_NO3 <- pd.read_csv(here("Storm_events", "2015", "FRCH", "FRCH_storm1_07_01_NO3.csv"))
here()
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(boot)
library(lubridate)
library(here)
Sys.which("python")
use_python("/usr/local/bin/python3")
options(tz="America/Anchorage")
# install pandas #
virtualenv_create("r-reticulate")
# RETICULATE_PYTHON = "lib/python3.8"
reticulate::py_config()
reticulate::py_install("pandas")
reticulate::repl_python()
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2015")
reticulate::repl_python()
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(boot)
library(lubridate)
library(here)
Sys.which("python")
use_python("/usr/local/bin/python3")
options(tz="America/Anchorage")
# install pandas #
virtualenv_create("r-reticulate")
# RETICULATE_PYTHON = "lib/python3.8"
reticulate::py_config()
reticulate::py_install("pandas")
reticulate::repl_python()
MOOS.hyst.results.list = list(py$hysdict_MOOS_storm1_07_01_NO3,
py$hysdict_MOOS_storm1_07_01_fDOM,
py$hysdict_MOOS_storm1_07_01_SPC,
py$hysdict_MOOS_storm1_07_01_turb,
py$hysdict_MOOS_storm1_07_01_abs,
py$hysdict_MOOS_storm2_07_18_NO3,
py$hysdict_MOOS_storm2_07_18_fDOM,
py$hysdict_MOOS_storm2_07_18_SPC,
py$hysdict_MOOS_storm2_07_18_turb,
py$hysdict_MOOS_storm3a_07_27_NO3,
py$hysdict_MOOS_storm3a_07_27_fDOM,
py$hysdict_MOOS_storm3a_07_27_abs,
py$hysdict_MOOS_storm4_08_16_NO3,
py$hysdict_MOOS_storm4_08_16_fDOM,
py$hysdict_MOOS_storm4_08_16_SPC,
py$hysdict_MOOS_storm4_08_16_turb,
py$hysdict_MOOS_storm4_08_16_abs,
py$hysdict_MOOS_storm5_08_25_fDOM,
py$hysdict_MOOS_storm5_08_25_SPC,
py$hysdict_MOOS_storm5_08_25_turb,
py$hysdict_MOOS_storm6_09_14_NO3,
py$hysdict_MOOS_storm6_09_14_fDOM,
py$hysdict_MOOS_storm6_09_14_SPC,
py$hysdict_MOOS_storm6_09_14_turb,
py$hysdict_MOOS_storm6_09_14_abs
)
reticulate::repl_python()
MOOS.hyst.results.list = list(py$hysdict_MOOS_storm1_07_01_NO3,
py$hysdict_MOOS_storm1_07_01_fDOM,
py$hysdict_MOOS_storm1_07_01_SPC,
py$hysdict_MOOS_storm1_07_01_turb,
py$hysdict_MOOS_storm1_07_01_abs,
py$hysdict_MOOS_storm2_07_18_NO3,
py$hysdict_MOOS_storm2_07_18_fDOM,
py$hysdict_MOOS_storm2_07_18_SPC,
py$hysdict_MOOS_storm2_07_18_turb,
py$hysdict_MOOS_storm3a_07_27_NO3,
py$hysdict_MOOS_storm3a_07_27_abs,
py$hysdict_MOOS_storm4_08_16_NO3,
py$hysdict_MOOS_storm4_08_16_fDOM,
py$hysdict_MOOS_storm4_08_16_SPC,
py$hysdict_MOOS_storm4_08_16_turb,
py$hysdict_MOOS_storm4_08_16_abs,
py$hysdict_MOOS_storm5_08_25_fDOM,
py$hysdict_MOOS_storm5_08_25_SPC,
py$hysdict_MOOS_storm5_08_25_turb,
py$hysdict_MOOS_storm6_09_14_NO3,
py$hysdict_MOOS_storm6_09_14_fDOM,
py$hysdict_MOOS_storm6_09_14_SPC,
py$hysdict_MOOS_storm6_09_14_turb,
py$hysdict_MOOS_storm6_09_14_abs
)
reticulate::repl_python()
FRCH.hyst.results.list = list(py$hysdict_FRCH_storm1_07_01_fDOM) # output of the hysteresis function
FRCH.hyst.results.list.2 = list()
for (i in 1:length(FRCH.hyst.results.list)){
FRCH.hyst.results.list.2[[i]] = as.data.frame(t(as.numeric(c(
FRCH.hyst.results.list[[i]][["HI_mean_with_Interp"]],
FRCH.hyst.results.list[[i]][["HI_standard_deviation_with_Interp"]],
FRCH.hyst.results.list[[i]][["Normalized slope of response"]],
FRCH.hyst.results.list[[i]][["interpolated Max width of response"]],
FRCH.hyst.results.list[[i]][["Min response"]],
FRCH.hyst.results.list[[i]][["Max response"]],
FRCH.hyst.results.list[[i]][["Peak Q"]]
))))
names(FRCH.hyst.results.list.2[[i]]) = c("HI_mean_Interp", "HI_sd_with_Interp", "N.S.", "Max_width_Interp", "Min_response", "Max_response", "Peak_Q")
} # Clipping the variables of interests, restructuring the dataframe to numerica and renaming the variables
View(FRCH.hyst.results.list.2)
HIs.list = list()
HIs.tests = list()
FRCH.hyst.results.list.2[[1]]
for (i in 1:length(FRCH.hyst.results.list)){
HIs.list[[i]] = unlist(FRCH.hyst.results.list[[i]][["Hysteresis_Index"]],recursive=FALSE)
HIs.tests[[i]] = as.data.frame(t(round(as.numeric(c(shapiro.test(HIs.list[[i]])$statistic, shapiro.test(HIs.list[[i]])$p.value,
t.test(HIs.list[[i]], mu=0)$statistic, t.test(HIs.list[[i]], mu=0)$p.value,
t.test(HIs.list[[i]], mu=0)$conf.int[1],t.test(HIs.list[[i]], mu=0)$conf.int[2],
wilcox.test(HIs.list[[i]], mu=0)$statistic, wilcox.test(HIs.list[[i]], mu=0)$p.value)), 4)))
names(HIs.tests[[i]]) = c("ShapiroTest.W", "ShapiroTest.p", "t.test.stat", "t.test.p", "t.test.CIlow", "t.test.CIhigh",
"wilcox.test.stat", "wilcox.test.p")
}# these are the stats of the function. Going to give you the t.tests and the CIs
View(HIs.list)
View(HIs.tests)
FRCH.hyst.results.list.3 =list()
for (i in 1:length(FRCH.hyst.results.list)){
FRCH.hyst.results.list.3[[i]] = cbind(FRCH.hyst.results.list.2[[i]], HIs.tests[[i]])
} # this is combining the previous two created dataframes
View(FRCH.hyst.results.list.3)
FRCH.hyst.results.df = bind_rows(FRCH.hyst.results.list.3, .id = "column_label")
View(FRCH.hyst.results.df)
FRCH.hyst.results.df$storm.ID = c("FRCH_storm1_07_01_NO3") # naming it
FRCH.hyst.results.df$storm.ID = c("FRCH_storm1_07_01_fDOM") # naming it
FRCH.hyst.results.df$site.ID = "FRCH" # making sure it is named the correct site
for (i in 1:length(HIs.list)) {
HIs.Q.list[[i]] = names(HIs.list[[i]])
HIs.Q.list[[i]] = (sapply(strsplit(HIs.Q.list[[i]], " "), "[[", 4))
HIs.Q.list[[i]] = as.numeric(gsub("%", "", HIs.Q.list[[i]]))
HIs.df.list[[i]] = as.data.frame(cbind(HIs.list[[i]], HIs.Q.list[[i]]))
HIs.df.list[[i]]= HIs.df.list[[i]][order(HIs.df.list[[i]][["V2"]]),]
names(HIs.df.list[[i]]) = c("HI", "Q_interval")
}
## plot HI with bootstrapped 95% CIs around the median ##
HIs.Q.list =list()
HIs.df.list = list()
for (i in 1:length(HIs.list)) {
HIs.Q.list[[i]] = names(HIs.list[[i]])
HIs.Q.list[[i]] = (sapply(strsplit(HIs.Q.list[[i]], " "), "[[", 4))
HIs.Q.list[[i]] = as.numeric(gsub("%", "", HIs.Q.list[[i]]))
HIs.df.list[[i]] = as.data.frame(cbind(HIs.list[[i]], HIs.Q.list[[i]]))
HIs.df.list[[i]]= HIs.df.list[[i]][order(HIs.df.list[[i]][["V2"]]),]
names(HIs.df.list[[i]]) = c("HI", "Q_interval")
}
FRCH.HI.df = bind_rows(HIs.df.list, .id = "column_label")
FRCH.HI.df = bind_rows(HIs.df.list, .id = "column_label")
View(FRCH.HI.df)
FRCH.HI.df$storm.ID = c(rep("FRCH_storm1_07_01_fDOM", 50))
FRCH.HI.df$storm.ID = as.factor(FRCH.HI.df$storm.ID)
FRCH.HI.df = separate(data=FRCH.HI.df, col=storm.ID, into=c("site.ID","storm.num", "month", "day", "response"), sep = "_", remove = F)
median_cl_boot <- function(x, conf = 0.95) {
lconf <- (1 - conf)/2
uconf <- 1 - lconf
require(boot)
bmedian <- function(x, ind) median(x[ind])
bt <- boot(x, bmedian, 10000)
bb <- boot.ci(bt, conf = 0.95, type = "perc")
data.frame(y = median(x), ymin = quantile(bt$t, lconf), ymax = quantile(bt$t,
uconf))
} # Boot straping CIs
g0 <- ggplot(FRCH.HI.df, aes(x = storm.num, y = HI, label=storm.num, fill=response))
g0
g1 = g0 + geom_jitter(width = 0.1, fill = "grey", colour = "#0571B0", alpha=0.25, size=3) +
theme(axis.text.x = element_text(angle = 0))+  labs(x="") + facet_wrap(~ response, scales = "free_x") +
theme_bw() +geom_hline(yintercept=0) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "none")
g1
g2 <- g1 +
stat_summary(fun.data = median_cl_boot, geom = "errorbar",
colour = "black", width = 0.2, size=1) +
stat_summary(fun.y = median, geom = "point",
colour = "black", size = 3)
g2
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
here()
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2015")
storm_file_list_beta <- list.files(path="FRCH_MOOS/",
recursive=F,
pattern=".csv",
full.names=TRUE)
storm_list_beta<-do.call("list", lapply(storm_file_list_beta,
read.csv,
stringsAsFactors=FALSE,
header=T, row.names=1))
View(storm_list_beta)
storm_list_beta[[1]]
storm_file_list_beta = sub("FRCH_MOOS//", storm_file_list_beta, replacement = "")
storm_file_list_beta = sub(".csv", storm_file_list_beta, replacement = "")
names(storm_list_beta) = storm_file_list_beta
View(storm_list_beta)
for(i in 1:length(storm_list_beta)){
storm_list_beta[[i]][["valuedatetime"]] = as.POSIXct(storm_list_beta[[i]][["valuedatetime"]],
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
} # changing character format into datetime
#  organize storm data by site and solute
FRCH_storm_list_beta = storm_list_beta[c(1:42)] #42
View(FRCH_storm_list_beta)
MOOS_storm_list_beta = storm_list_beta[c(43:78)] #36
View(FRCH_storm_list_beta)
View(FRCH_storm_list_beta)
FRCH_NO3_storm_list_beta = FRCH_storm_list_beta[c(grep("NO3", names(FRCH_storm_list_beta)))]
View(FRCH_NO3_storm_list_beta)
FRCH_fDOM_storm_list_beta = FRCH_storm_list_beta[c(grep("fDOM", names(FRCH_storm_list_beta)))]
View(FRCH_fDOM_storm_list_beta)
FRCH_SpCond_storm_list_beta = FRCH_storm_list_beta[c(grep("SPC", names(FRCH_storm_list_beta)))]
FRCH_turb_storm_list_beta = FRCH_storm_list_beta[c(grep("turb", names(FRCH_storm_list_beta)))]
FRCH_abs_storm_list_beta = FRCH_storm_list_beta[c(grep("abs", names(FRCH_storm_list_beta)))]
FRCH_Q_storm_list_beta = FRCH_storm_list_beta[c(grep("Q", names(FRCH_storm_list_beta)))]
MOOS_NO3_storm_list_beta = MOOS_storm_list_beta[c(grep("NO3", names(MOOS_storm_list_beta)))]
MOOS_fDOM_storm_list_beta = MOOS_storm_list_beta[c(grep("fDOM", names(MOOS_storm_list_beta)))]
MOOS_SpCond_storm_list_beta = MOOS_storm_list_beta[c(grep("SPC", names(MOOS_storm_list_beta)))]
MOOS_turb_storm_list_beta = MOOS_storm_list_beta[c(grep("turb", names(MOOS_storm_list_beta)))]
MOOS_abs_storm_list_beta = MOOS_storm_list_beta[c(grep("abs", names(MOOS_storm_list_beta)))]
MOOS_Q_storm_list_beta = MOOS_storm_list_beta[c(grep("Q", names(MOOS_storm_list_beta)))]
View(FRCH_Q_storm_list_beta)
# normalize Q data
# FRCH
for(i in 1:length(FRCH_Q_storm_list_beta)){
FRCH_Q_storm_list_beta[[i]][["datavalue.norm"]] =
(FRCH_Q_storm_list_beta[[i]][["datavalue"]]-min(FRCH_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(FRCH_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(FRCH_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
FRCH_Q_storm_list_beta[["FRCH_storm1_07_01_Q"]][["datavalue.norm"]]
# normalize solute data
#
#NO3
for(i in 1:length(FRCH_NO3_storm_list_beta)){
FRCH_NO3_storm_list_beta[[i]][["datavalue.norm"]] =
(FRCH_NO3_storm_list_beta[[i]][["datavalue"]]-min(FRCH_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(FRCH_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(FRCH_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
FRCH_NO3_storm <- map2_df(FRCH_Q_storm_list_beta, FRCH_NO3_storm_list_beta, inner_join, by = "valuedatetime")
View(FRCH_NO3_storm)
FRCH_NO3_storm$storm.ID = c(rep("storm1", 287),
rep("storm2", 331),
rep("storm3", 383),
rep("storm4", 299),
rep("storm5a", 453),
rep("storm6a", 1295),
rep("storm7", 242))
names(FRCH_NO3_storm) <- c("DateTime", "Q", "Q.norm", "NO3", "NO3.norm", "storm.ID")
FRCH_NO3_storm$site.ID <- "FRCH"
cols <- c("NO3.norm","Q.norm")
FRCH_NO3_storm[cols] <- log(FRCH_NO3_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
FRCH_NO3_storm <- FRCH_NO3_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
FRCH_NO3_storm_ascending <- filter(FRCH_NO3_storm, limb == "ascending")
View(FRCH_NO3_storm_ascending)
FRCH_NO3_storm_ascending <- FRCH_NO3_storm_ascending[is.finite(FRCH_NO3_storm_ascending$Q.norm) & is.finite(FRCH_NO3_storm_ascending$NO3.norm), ]
beta.all.no3 <- FRCH_NO3_storm_ascending %>% group_by(storm.ID) %>%
dplyr::summarize(beta = slope(Q.norm, NO3.norm)) # this works just like the beta one that is for an individual site
View(beta.all.no3)
