HIs.list[[i]] = unlist(VAUL.hyst.results.list[[i]][["Hysteresis_Index"]],recursive=FALSE)
HIs.tests[[i]] = as.data.frame(t(round(as.numeric(c(shapiro.test(HIs.list[[i]])$statistic, shapiro.test(HIs.list[[i]])$p.value,
t.test(HIs.list[[i]], mu=0)$statistic, t.test(HIs.list[[i]], mu=0)$p.value,
t.test(HIs.list[[i]], mu=0)$conf.int[1],t.test(HIs.list[[i]], mu=0)$conf.int[2],
wilcox.test(HIs.list[[i]], mu=0)$statistic, wilcox.test(HIs.list[[i]], mu=0)$p.value)), 4)))
names(HIs.tests[[i]]) = c("ShapiroTest.W", "ShapiroTest.p", "t.test.stat", "t.test.p", "t.test.CIlow", "t.test.CIhigh",
"wilcox.test.stat", "wilcox.test.p")
}
VAUL.hyst.results.list.3 =list()
for (i in 1:length(VAUL.hyst.results.list)){
VAUL.hyst.results.list.3[[i]] = cbind(VAUL.hyst.results.list.2[[i]], HIs.tests[[i]])
}
VAUL.hyst.results.df = bind_rows(VAUL.hyst.results.list.3, .id = "column_label")
VAUL.hyst.results.df$storm.ID = c("VAUL_storm1_08_01_NO3",
"VAUL_storm1_08_01_abs",
"VAUL_storm1_09_14_NO3",
"VAUL_storm1_09_14_fDOM",
"VAUL_storm1_09_14_SPC",
"VAUL_storm1_09_14_turb",
"VAUL_storm1_09_14_abs")
VAUL.hyst.results.df$site.ID = "VAUL"
write_csv(VAUL.hyst.results.df, here("Output_from_analysis", "03_HI_FI", "2022", "VAUL", "VAUL.hyst.results.csv"))
## plot HI with bootstrapped 95% CIs around the median ##
HIs.Q.list =list()
HIs.df.list = list()
par(mfrow=c(1,1))
for (i in 1:length(HIs.list)) {
HIs.Q.list[[i]] = names(HIs.list[[i]])
HIs.Q.list[[i]] = (sapply(strsplit(HIs.Q.list[[i]], " "), "[[", 4))
HIs.Q.list[[i]] = as.numeric(gsub("%", "", HIs.Q.list[[i]]))
HIs.df.list[[i]] = as.data.frame(cbind(HIs.list[[i]], HIs.Q.list[[i]]))
HIs.df.list[[i]]= HIs.df.list[[i]][order(HIs.df.list[[i]][["V2"]]),]
names(HIs.df.list[[i]]) = c("HI", "Q_interval")
}
VAUL.HI.df = bind_rows(HIs.df.list, .id = "column_label")
VAUL.HI.df$storm.ID = c(rep("VAUL_storm1_08_01_NO3", 50),
rep("VAUL_storm1_08_01_abs", 50),
rep("VAUL_storm2_09_14_NO3", 50),
rep("VAUL_storm2_09_14_fDOM", 50),
rep("VAUL_storm2_09_14_SPC", 50),
rep("VAUL_storm2_09_14_turb", 50),
rep("VAUL_storm2_09_14_abs", 50))
VAUL.HI.df$storm.ID = as.factor(VAUL.HI.df$storm.ID)
VAUL.HI.df = separate(data=VAUL.HI.df, col=storm.ID, into=c("site.ID","storm.num", "month", "day", "response"), sep = "_", remove = F)
par(mfrow=c(1,1))
median_cl_boot <- function(x, conf = 0.95) {
lconf <- (1 - conf)/2
uconf <- 1 - lconf
require(boot)
bmedian <- function(x, ind) median(x[ind])
bt <- boot(x, bmedian, 10000)
bb <- boot.ci(bt, conf = 0.95, type = "perc")
data.frame(y = median(x), ymin = quantile(bt$t, lconf), ymax = quantile(bt$t,
uconf))
}
g0 <- ggplot(VAUL.HI.df, aes(x = storm.num, y = HI, label=storm.num, fill=response))
g1 = g0 + geom_jitter(width = 0.1, fill = "grey", colour = "#0571B0", alpha=0.25, size=3) +
theme(axis.text.x = element_text(angle = 0))+  labs(x="") + facet_wrap(~ response, scales = "free_x") +
theme_bw() +geom_hline(yintercept=0) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "none")
g2 <- g1 +
stat_summary(fun.data = median_cl_boot, geom = "errorbar",
colour = "black", width = 0.2, size=1) +
stat_summary(fun.y = median, geom = "point",
colour = "black", size = 3)
ggsave(here("plots", "HI_plots", "2022", "VAUL", "VAUL.HI.median.boot.pdf"), plot = g2,
width = 8, height = 6, units = "in")
write.csv(VAUL.HI.df, here("Output_from_analysis", "03_HI_FI", "2022", "VAUL", "VAUL.HI.df.csv"))
VAUL.HI.df$date <- as.Date(with(VAUL.HI.df, paste(month, day, sep = "-")), "%m-%d")
VAUL.HI.df$doy <- yday(VAUL.HI.df$date)
g0 <- ggplot(VAUL.HI.df, aes(x = doy, y = HI, label=doy, fill=response))
g1 = g0 + geom_jitter(width = 0.1, fill = "grey", colour = "#0571B0", alpha=0.25, size=3) +
theme(axis.text.x = element_text(angle = 0))+  labs(x="") + facet_wrap(~ response, scales = "free_x") +
theme_bw() +geom_hline(yintercept=0) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "none")
g2 <- g1 +
stat_summary(fun.data = median_cl_boot, geom = "errorbar",
colour = "black", width = 0.2, size=1) +
stat_summary(fun.y = median, geom = "point",
colour = "black", size = 3)
ggsave(here("plots", "HI_plots", "2022", "VAUL", "VAUL.HI.median.boot.doy.pdf"), plot = g2,
width = 8, height = 6, units = "in")
write.csv(VAUL.HI.df, here("Output_from_analysis", "03_HI_FI", "2022", "VAUL", "VAUL.HI.df.doy.csv"))
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
FRCH_HI_doy_df_2015 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2015", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2015 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2015", "MOOS","MOOS.HI.df.doy.csv"))
# 2018
FRCH_HI_doy_df_2018 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2018", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2018 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2018", "MOOS","MOOS.HI.df.doy.csv"))
CARI_HI_doy_df_2018 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2018", "CARI","CARI.HI.df.doy.csv"))
# 2019
FRCH_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "MOOS","MOOS.HI.df.doy.csv"))
POKE_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "POKE","POKE.HI.df.doy.csv"))
STRT_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "STRT","STRT.HI.df.doy.csv"))
VAUL_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "VAUL","VAUL.HI.df.doy.csv"))
CARI_HI_doy_df_2019 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2019", "CARI","CARI.HI.df.doy.csv"))
# 2020
FRCH_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "MOOS","MOOS.HI.df.doy.csv"))
POKE_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "POKE","POKE.HI.df.doy.csv"))
STRT_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "STRT","STRT.HI.df.doy.csv"))
VAUL_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "VAUL","VAUL.HI.df.doy.csv"))
CARI_HI_doy_df_2020 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2020", "CARI","CARI.HI.df.doy.csv"))
# 2021
FRCH_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "MOOS","MOOS.HI.df.doy.csv"))
POKE_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "POKE","POKE.HI.df.doy.csv"))
STRT_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "STRT","STRT.HI.df.doy.csv"))
VAUL_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "VAUL","VAUL.HI.df.doy.csv"))
CARI_HI_doy_df_2021 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2021", "CARI","CARI.HI.df.doy.csv"))
# 2022
FRCH_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "FRCH","FRCH.HI.df.doy.csv"))
MOOS_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "MOOS","MOOS.HI.df.doy.csv"))
POKE_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "POKE","POKE.HI.df.doy.csv"))
STRT_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "STRT","STRT.HI.df.doy.csv"))
VAUL_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "VAUL","VAUL.HI.df.doy.csv"))
CARI_HI_doy_df_2022 <- read.csv(here("Output_from_analysis", "03_HI_FI", "2022", "CARI","CARI.HI.df.doy.csv"))
HI.dat_2015 <- rbind(FRCH_HI_doy_df_2015, MOOS_HI_doy_df_2015)
HI.dat_2015$year <- "2015"
HI.dat_2018 <- rbind(FRCH_HI_doy_df_2018, MOOS_HI_doy_df_2018, CARI_HI_doy_df_2018)
HI.dat_2018$year <- "2018"
HI.dat_2019 <- rbind(FRCH_HI_doy_df_2019, MOOS_HI_doy_df_2019, POKE_HI_doy_df_2019,
STRT_HI_doy_df_2019, VAUL_HI_doy_df_2019, CARI_HI_doy_df_2019)
HI.dat_2019$year <- "2019"
HI.dat_2020 <- rbind(FRCH_HI_doy_df_2020, MOOS_HI_doy_df_2020, POKE_HI_doy_df_2020,
STRT_HI_doy_df_2020, VAUL_HI_doy_df_2020, CARI_HI_doy_df_2020)
HI.dat_2020$year <- "2020"
HI.dat_2021 <- rbind(FRCH_HI_doy_df_2021, MOOS_HI_doy_df_2021, POKE_HI_doy_df_2021,
STRT_HI_doy_df_2021, VAUL_HI_doy_df_2021, CARI_HI_doy_df_2021)
HI.dat_2021$year <- "2021"
HI.dat_2022 <- rbind(FRCH_HI_doy_df_2022, MOOS_HI_doy_df_2022, POKE_HI_doy_df_2022,
STRT_HI_doy_df_2022, VAUL_HI_doy_df_2022, CARI_HI_doy_df_2022)
HI.dat_2022$year <- "2022"
HI.dat <- rbind(HI.dat_2015, HI.dat_2018, HI.dat_2019, HI.dat_2020, HI.dat_2021, HI.dat_2022)
# write.csv(HI.dat, "~/Documents/Storms_clean_repo/Output_from_analysis/04_Antecedent_Conditions/HI.dat.csv")
#HI.dat <- read_csv("~/Documents/Storms/Output_from_analysis/HI.dat.csv")
HI.mean<- HI.dat %>% group_by(site.ID, response, year) %>%
summarise_at(vars(HI), list(HI = median)) # takes the median by site response and year
# merged #
# By site and response
FRCH.fDOM <- subset(HI.mean, site.ID == "FRCH" & response == "fDOM")
POKE.fDOM <- subset(HI.mean, site.ID == "POKE" & response == "fDOM")
MOOS.fDOM <- subset(HI.mean, site.ID == "MOOS" & response == "fDOM")
STRT.fDOM <- subset(HI.mean, site.ID == "STRT" & response == "fDOM")
VAUL.fDOM <- subset(HI.mean, site.ID == "VAUL" & response == "fDOM")
CARI.fDOM <- subset(HI.mean, site.ID == "CARI" & response == "fDOM")
FRCH.NO3 <- subset(HI.mean, site.ID == "FRCH" & response == "NO3")
POKE.NO3 <- subset(HI.mean, site.ID == "POKE" & response == "NO3")
MOOS.NO3 <- subset(HI.mean, site.ID == "MOOS" & response == "NO3")
STRT.NO3 <- subset(HI.mean, site.ID == "STRT" & response == "NO3")
VAUL.NO3 <- subset(HI.mean, site.ID == "VAUL" & response == "NO3")
CARI.NO3 <- subset(HI.mean, site.ID == "CARI" & response == "NO3")
FRCH.fDOM$burn <- "unburned"
POKE.fDOM$burn <- "burned"
MOOS.fDOM$burn <- "burned"
STRT.fDOM$burn <- "burned"
VAUL.fDOM$burn <- "unburned"
CARI.fDOM$burn <- "unburned"
FRCH.NO3$burn <- "unburned"
POKE.NO3$burn <- "burned"
MOOS.NO3$burn <- "burned"
STRT.NO3$burn <- "burned"
VAUL.NO3$burn <- "unburned"
CARI.NO3$burn <- "unburned"
fdom.hi <- rbind(FRCH.fDOM, POKE.fDOM, MOOS.fDOM, STRT.fDOM, VAUL.fDOM, CARI.fDOM)
no3.hi <- rbind(FRCH.NO3, POKE.NO3, MOOS.NO3, STRT.NO3, VAUL.NO3, CARI.NO3)
fdom.hi$year <- as.character(fdom.hi$year)
no3.hi$year <- as.character(no3.hi$year)
fdom.lm <- lm(fdom.hi$HI ~ fdom.hi$burn)
no3.lm <- lm(no3.hi$HI ~ no3.hi$burn)
fdom.hi %>%
ggplot(aes(x=burn,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("DOC") +
xlab("Catchment burned (%)") +
ylab("HI-Solute Storage")
no3.hi %>%
ggplot(aes(x=burn,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("NO3") +
xlab("Catchment burned (%)") +
ylab("HI-Solute Storage")
# Permafrost #
FRCH.fDOM$pf <- "Moderate"
POKE.fDOM$pf <- "Moderate"
MOOS.fDOM$pf <- "Moderate"
STRT.fDOM$pf <- "High"
VAUL.fDOM$pf <- "High"
CARI.fDOM$pf <- "Moderate"
FRCH.NO3$pf <- "Moderate"
POKE.NO3$pf <- "Moderate"
MOOS.NO3$pf <- "Moderate"
STRT.NO3$pf <- "High"
VAUL.NO3$pf <- "High"
CARI.NO3$pf <- "Moderate"
pf.fdom.hi <- rbind(FRCH.fDOM, POKE.fDOM, MOOS.fDOM, STRT.fDOM, VAUL.fDOM, CARI.fDOM)
pf.no3.hi <- rbind(FRCH.NO3, POKE.NO3, MOOS.NO3, STRT.NO3, VAUL.NO3, CARI.NO3)
pf.fdom.hi$year <- as.character(pf.fdom.hi$year)
pf.no3.hi$year <- as.character(pf.no3.hi$year)
pf.fdom.lm <- lm(pf.fdom.hi$HI ~ pf.fdom.hi$burn)
pf.no3.lm <- lm(pf.no3.hi$HI ~ pf.no3.hi$burn)
pf.fdom.hi %>%
ggplot(aes(x=pf,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("DOC") +
xlab("Permafrost Extent (%)") +
ylab("HI-Solute Storage")
pf.no3.hi %>%
ggplot(aes(x=pf,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("NO3") +
xlab("Permafrost Extent (%)") +
ylab("HI-Solute Storage")
### H 1.1: HI against precip ###
HI.mean.precip <- HI.dat %>% group_by(site.ID, year, storm.num) %>%
summarise_at(vars(HI), list(HI = median)) # take mean by site response and year
HI.mean.precip.response <- HI.dat %>% group_by(site.ID, year, storm.num, response) %>%
summarise_at(vars(HI), list(HI = median)) # take mean by site response and year
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2022")
CPCRW <- read_csv(here("Climate", "Precip", "CPCRW.RainGauge.2022.final.csv"))
CPCRW$datetimeAK <- force_tz(CPCRW$datetimeAK, "America/Anchorage") # it already is in AK time so I want to make it recognize it without changing the actually time value
# this needs to be updated to include 2022 data
airtempmean <- read.csv(here("Climate", "airtempmean.csv"))
airtempmean$datetimeAK <- airtempmean$date_timeAK
airtempmean$datetimeAK <- as.POSIXct(airtempmean$datetimeAK, tz = "America/Anchorage", format = "%Y-%m-%d %H:%M")
# Reading in chem data to join with the antecedent moisture condition data
DOD.2022 <- read.csv(here("processed_sensor_data", "2022", "SUNA.EXO.int.corr.lab_2022.csv"))
DOD.2022 <- DOD.2022[c("datetimeAK", "site.ID", "fDOM.QSU.T.turb.col", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
names(DOD.2022) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
# summing up week/month/threemonth antecedent precip
DOD.2022$datetimeAK <- ymd_hms(DOD.2022$datetimeAK) # converting character to datetime
DOD.2022$datetimeAK <- force_tz(DOD.2022$datetimeAK, "America/Anchorage") # converting character to datetime
DOD.2022 <- left_join(DOD.2022, CPCRW, by = "datetimeAK")
FRCH.2022 <- subset(DOD.2022, site.ID == "FRCH")
MOOS.2022 <- subset(DOD.2022, site.ID == "MOOS")
POKE.2022 <- subset(DOD.2022, site.ID == "POKE")
VAUL.2022 <- subset(DOD.2022, site.ID == "VAUL")
STRT.2022 <- subset(DOD.2022, site.ID == "STRT")
VAULstorm_file_list <- list.files(path = "All_sites/",
recursive=F,
pattern="VAUL",
full.names=TRUE)
VAUL_storms<-do.call("rbind", lapply(VAULstorm_file_list,
read.csv,
check.names = FALSE,
stringsAsFactors=FALSE,
header=T, blank.lines.skip = TRUE, fill=TRUE))
VAUL_storms$storm.num = c(rep("storm1", 127),
rep("storm2", 763))
VAUL_storms$datetimeAK <- as.POSIXct(VAUL_storms$datetimeAK, tz = "America/Anchorage", format = "%Y-%m-%d %H:%M")
VAUL.2022.storms.1<- left_join(VAUL_storms, CPCRW, by = "datetimeAK")
VAUL.2022.storms.1<- left_join(VAUL.2022.storms.1, airtempmean, by = "datetimeAK")
names(VAUL.2022.storms.1)[names(VAUL.2022.storms.1) == ''] <- 'x'
VAUL.2022.per.storm.1 <- VAUL.2022.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(mean), list(precip = sum), na.rm = TRUE)
temp <- VAUL.2022.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(airtemp_100.1000cm_mean), list(temp = mean), na.rm = TRUE) # finding the mean temperature for each storm event
VAUL.2022.per.storm.1$temp <- temp$temp
#making a uniform time series with 15 minute intervals and then I can sum precip by 24/48hour windows
ts <- seq(as.POSIXct("2022-05-01", tz = "America/Anchorage"),
as.POSIXct("2022-10-31", tz = "America/Anchorage"),
by = "15 min")
head(ts)
ts <- as.data.frame(ts)
names(ts) <- c("datetimeAK")
VAUL.2022 <- left_join(ts, VAUL.2022, by = "datetimeAK")
VAUL.2022 <- left_join(VAUL.2022, airtempmean, by = "datetimeAK")
VAUL.2022$week <- rollapplyr(VAUL.2022$mean, 672, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2022$month <- rollapplyr(VAUL.2022$mean, 2688, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2022$ThreeMonth <- rollapplyr(VAUL.2022$mean, 8064, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2022$temp.week <- rollapplyr(VAUL.2022$airtemp_100.1000cm_mean.x, 672, mean, na.rm = TRUE, fill = NA, partial = TRUE)
# joining with storms
VAUL.2022.1 <- left_join(VAUL.2022.storms.1, VAUL.2022, by = c("datetimeAK", "NO3", "fDOM", "SPC", "Turb", "ABS_254", "site.ID",
"CRREL", "CARI")) # week month and 3 month precip totals
# renaming antecedent month
names(VAUL.2022.1)[names(VAUL.2022.1) == 'month.y'] <- 'month'
names(VAUL.2022.1)[names(VAUL.2022.1) == 'airtemp_100.1000cm_mean.y'] <- 'airtemp_100.1000cm_mean'
VAUL.2022.per.storm.2 <- VAUL.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(week), list(precip.week = first), na.rm = TRUE) # grouping weekly precip leading up to storm event
VAUL.2022.per.storm.3 <- VAUL.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(month), list(precip.month = first), na.rm = TRUE) # groouping monthly precip leading up to a storm
VAUL.2022.per.storm.4 <- VAUL.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(ThreeMonth), list(ThreeMonth = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
# VAUL2022.per.storm.5 <- VAUL.2022.1 %>% group_by(storm.num) %>%
#   summarise_at(vars(temp.week), list(temp.week = first), na.rm = TRUE) # grouping one week mean temperature leading up to a storm
HI.mean.precip.vaul.NO3 <- subset(HI.mean.precip.response, year == "2022" & site.ID == "VAUL" & response == "NO3")
HI.mean.precip.vaul.fDOM <- subset(HI.mean.precip.response, year == "2022" & site.ID == "VAUL" & response == "fDOM")
HI.mean.precip.vaul.SPC <- subset(HI.mean.precip.response, year == "2022" & site.ID == "VAUL" & response == "SPC")
HI.mean.precip.vaul.turb <- subset(HI.mean.precip.response, year == "2022" & site.ID == "VAUL" & response == "turb")
HI.mean.precip.vaul.abs <- subset(HI.mean.precip.response, year == "2022" & site.ID == "VAUL" & response == "abs")
# NO3
HI.vaul.no3.2022 <- left_join(HI.mean.precip.vaul.NO3, VAUL.2022.per.storm.1, by = "storm.num")
HI.vaul.no3.2022 <- left_join(HI.vaul.no3.2022, VAUL.2022.per.storm.2, by = "storm.num")
HI.vaul.no3.2022 <- left_join(HI.vaul.no3.2022, VAUL.2022.per.storm.3, by = "storm.num")
HI.vaul.no3.2022 <- left_join(HI.vaul.no3.2022, VAUL.2022.per.storm.4, by = "storm.num")
#HI.vaul.no3.2022 <- left_join(HI.vaul.no3.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.no3 <- lm(HI.vaul.no3.2022$HI ~ HI.vaul.no3.2022$precip) # model one with just total precip
vaul.lm.no3.2 <- lm(HI.vaul.no3.2022$HI ~ HI.vaul.no3.2022$precip.week) # model one with just total precip
vaul.lm.no3.3 <- lm(HI.vaul.no3.2022$HI ~ HI.vaul.no3.2022$precip.month) # model one with just total precip
vaul.lm.no3.4 <- lm(HI.vaul.no3.2022$HI ~ HI.vaul.no3.2022$ThreeMonth) # model one with just total precip
# fDOM #
HI.vaul.fDOM.2022 <- left_join(HI.mean.precip.vaul.fDOM, VAUL.2022.per.storm.1, by = "storm.num")
HI.vaul.fDOM.2022 <- left_join(HI.vaul.fDOM.2022, VAUL.2022.per.storm.2, by = "storm.num")
HI.vaul.fDOM.2022 <- left_join(HI.vaul.fDOM.2022, VAUL.2022.per.storm.3, by = "storm.num")
HI.vaul.fDOM.2022 <- left_join(HI.vaul.fDOM.2022, VAUL.2022.per.storm.4, by = "storm.num")
#HI.vaul.fDOM.2021 <- left_join(HI.vaul.fDOM.2021, VAUL.2021.per.storm.5, by = "storm.num")
vaul.lm.fDOM <- lm(HI.vaul.fDOM.2022$HI ~ HI.vaul.fDOM.2022$precip) # model one with just total precip
vaul.lm.fDOM.2 <- lm(HI.vaul.fDOM.2022$HI ~ HI.vaul.fDOM.2022$precip.week) # model one with just total precip
vaul.lm.fDOM.3 <- lm(HI.vaul.fDOM.2022$HI ~ HI.vaul.fDOM.2022$precip.month) # model one with just total precip
vaul.lm.fDOM.4 <- lm(HI.vaul.fDOM.2022$HI ~ HI.vaul.fDOM.2022$ThreeMonth) # model one with just total precip
#vaul.lm.fDOM.5 <- lm(HI.vaul.fDOM.2022$HI ~ HI.vaul.fDOM.2022$temp.week) # model one with just total precip
# SPC #
HI.vaul.SPC.2022 <- left_join(HI.mean.precip.vaul.SPC, VAUL.2022.per.storm.1, by = "storm.num")
HI.vaul.SPC.2022 <- left_join(HI.vaul.SPC.2022, VAUL.2022.per.storm.2, by = "storm.num")
HI.vaul.SPC.2022 <- left_join(HI.vaul.SPC.2022, VAUL.2022.per.storm.3, by = "storm.num")
HI.vaul.SPC.2022 <- left_join(HI.vaul.SPC.2022, VAUL.2022.per.storm.4, by = "storm.num")
#HI.vaul.SPC.2021 <- left_join(HI.vaul.SPC.2021, VAUL.2021.per.storm.5, by = "storm.num")
vaul.lm.SPC <- lm(HI.vaul.SPC.2022$HI ~ HI.vaul.SPC.2022$precip) # model one with just total precip
vaul.lm.SPC.2 <- lm(HI.vaul.SPC.2022$HI ~ HI.vaul.SPC.2022$precip.week) # model one with just total precip
vaul.lm.SPC.3 <- lm(HI.vaul.SPC.2022$HI ~ HI.vaul.SPC.2022$precip.month) # model one with just total precip
vaul.lm.SPC.4 <- lm(HI.vaul.SPC.2022$HI ~ HI.vaul.SPC.2022$ThreeMonth) # model one with just total precip
#vaul.lm.SPC.5 <- lm(HI.vaul.SPC.2022$HI ~ HI.vaul.SPC.2022$temp.week) # model one with just total precip
# turb #
HI.vaul.turb.2022 <- left_join(HI.mean.precip.vaul.turb, VAUL.2022.per.storm.1, by = "storm.num")
HI.vaul.turb.2022 <- left_join(HI.vaul.turb.2022, VAUL.2022.per.storm.2, by = "storm.num")
HI.vaul.turb.2022 <- left_join(HI.vaul.turb.2022, VAUL.2022.per.storm.3, by = "storm.num")
HI.vaul.turb.2022 <- left_join(HI.vaul.turb.2022, VAUL.2022.per.storm.4, by = "storm.num")
#HI.vaul.turb.2021 <- left_join(HI.vaul.turb.2021, VAUL.2021.per.storm.5, by = "storm.num")
vaul.lm.turb <- lm(HI.vaul.turb.2022$HI ~ HI.vaul.turb.2022$precip) # model one with just total precip
vaul.lm.turb.2 <- lm(HI.vaul.turb.2022$HI ~ HI.vaul.turb.2022$precip.week) # model one with just total precip
vaul.lm.turb.3 <- lm(HI.vaul.turb.2022$HI ~ HI.vaul.turb.2022$precip.month) # model one with just total precip
vaul.lm.turb.4 <- lm(HI.vaul.turb.2022$HI ~ HI.vaul.turb.2022$ThreeMonth) # model one with just total precip
#vaul.lm.turb.5 <- lm(HI.vaul.turb.2022$HI ~ HI.vaul.turb.2022$temp.week) # model one with just total precip
# abs #
HI.vaul.abs.2022 <- left_join(HI.mean.precip.vaul.abs, VAUL.2022.per.storm.1, by = "storm.num")
HI.vaul.abs.2022 <- left_join(HI.vaul.abs.2022, VAUL.2022.per.storm.2, by = "storm.num")
HI.vaul.abs.2022 <- left_join(HI.vaul.abs.2022, VAUL.2022.per.storm.3, by = "storm.num")
HI.vaul.abs.2022 <- left_join(HI.vaul.abs.2022, VAUL.2022.per.storm.4, by = "storm.num")
#HI.vaul.abs.2021 <- left_join(HI.vaul.abs.2021, VAUL.2021.per.storm.5, by = "storm.num")
vaul.lm.abs <- lm(HI.vaul.abs.2022$HI ~ HI.vaul.abs.2022$precip) # model one with just total precip
vaul.lm.abs.2 <- lm(HI.vaul.abs.2022$HI ~ HI.vaul.abs.2022$precip.week) # model one with just total precip
vaul.lm.abs.3 <- lm(HI.vaul.abs.2022$HI ~ HI.vaul.abs.2022$precip.month) # model one with just total precip
vaul.lm.abs.4 <- lm(HI.vaul.abs.2022$HI ~ HI.vaul.abs.2022$ThreeMonth) # model one with just total precip
#vaul.lm.abs.5 <- lm(HI.vaul.abs.2022$HI ~ HI.vaul.abs.2022$temp.week) # model one with just total precip
# this would be for intensity but we are not doing this right now if just comparing to the DOD stuff
# sum.time <- FRCH.2018.storms.1 %>%
#   mutate(grp=data.table::rleid(storm.num))%>%
#   group_by(grp) %>%
#   summarise(storm.num=max(storm.num),TOTAL.TIME=difftime(max(DateTime),
#                                                          min(DateTime),units="hour"))%>%
#   group_by(storm.num) %>%
#   summarise(TOTAL.TIME=sum(TOTAL.TIME)) # creating a total time column for each individual storm and then I can generate an intensity metric which would be TotalPrecip/duration of event
#
# HI.frch.fDOM.2.2018 <- left_join(HI.frch.fDOM.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.fDOM.2.2018$TOTAL.TIME <- as.numeric(HI.frch.fDOM.2.2018$TOTAL.TIME)
# HI.frch.fDOM.2.2018$Intensity <- HI.frch.fDOM.2.2018$precip/HI.frch.fDOM.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.fDOM.2 <- lm(HI.frch.fDOM.2.2018$HI ~ HI.frch.fDOM.2.2018$precip + HI.frch.fDOM.2.2018$Intensity) # model one with total precip and intensity
#
# br <- HI.frch.fDOM.2.2018 %>%
#   ggplot(aes(x=Intensity,
#              y=HI)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   stat_poly_eq(formula = frch.formula,
#                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
#                parse = TRUE) +
#   ggtitle("FRCH fDOM") +
#   xlab("Intensity (mm/hr)") +
#   ylab("HI-Solute Storage") +
#   theme_classic() # plot model
#
# HI.frch.SPC.2.2018 <- left_join(HI.frch.SPC.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.SPC.2.2018$TOTAL.TIME <- as.numeric(HI.frch.SPC.2.2018$TOTAL.TIME)
# HI.frch.SPC.2.2018$Intensity <- HI.frch.SPC.2.2018$precip/HI.frch.SPC.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.SPC.2 <- lm(HI.frch.SPC.2.2018$HI ~ HI.frch.SPC.2.2018$precip + HI.frch.SPC.2.2018$Intensity) # model one with total precip and intensity
#
# HI.frch.turb.2.2018 <- left_join(HI.frch.turb.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.turb.2.2018$TOTAL.TIME <- as.numeric(HI.frch.turb.2.2018$TOTAL.TIME)
# HI.frch.turb.2.2018$Intensity <- HI.frch.turb.2.2018$precip/HI.frch.turb.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.turb.2 <- lm(HI.frch.turb.2.2018$HI ~ HI.frch.turb.2.2018$precip + HI.frch.turb.2.2018$Intensity) # model one with total precip and intensity
# day of year # SEASONALITY
VAUL.2022.1$day <- julian(VAUL.2022.1$datetimeAK, origin = as.POSIXct('2022-01-01', tz = 'America/Anchorage')) # making a fractional day column
VAUL.2022.1$day <- as.numeric(VAUL.2022.1$day)
VAUL.2022.per.storm.5 <- VAUL.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(day), list(doy = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.vaul.fDOM.2.2022 <- left_join(HI.vaul.fDOM.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.fDOM.5 <- lm(HI.vaul.fDOM.2.2022$HI ~ HI.vaul.fDOM.2.2022$doy)
# HI.salcha.fDOM.2.2021 %>%
#   ggplot(aes(x=doy,
#              y=HI)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   stat_poly_eq(formula = salcha.formula,
#                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
#                parse = TRUE) +
#   ggtitle("SALCHA fDOM") +
#   xlab("Day of year") +
#   ylab("HI-Solute Storage") +
#   theme_classic() # plot model
HI.vaul.SPC.2.2022 <- left_join(HI.vaul.SPC.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.SPC.5 <- lm(HI.vaul.SPC.2.2022$HI ~ HI.vaul.SPC.2.2022$doy)
HI.vaul.turb.2.2022 <- left_join(HI.vaul.turb.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.turb.5 <- lm(HI.vaul.turb.2.2022$HI ~ HI.vaul.turb.2.2022$doy)
HI.vaul.no3.2.2022 <- left_join(HI.vaul.no3.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.no3.5 <- lm(HI.vaul.no3.2.2022$HI ~ HI.vaul.no3.2.2022$doy)
HI.vaul.abs.2.2022 <- left_join(HI.vaul.abs.2022, VAUL.2022.per.storm.5, by = "storm.num")
vaul.lm.abs.5 <- lm(HI.vaul.turb.2.2022$HI ~ HI.vaul.turb.2.2022$doy)
HI.vaul.2022 <- rbind(HI.vaul.no3.2.2022, HI.vaul.fDOM.2.2022, HI.vaul.SPC.2.2022, HI.vaul.turb.2.2022, HI.vaul.abs.2.2022) # merging all responses together
HI.vaul.2022$date <- as.Date(HI.vaul.2022$doy, origin = "2022-01-01")
origin_date <- as.Date("2022-05-13")
HI.vaul.2022$TimeSinceChena <- julian(HI.vaul.2022$date, origin_date)
write.csv(HI.vaul.2022, here("Output_from_analysis", "04_Antecedent_Conditions", "2022", "HI.vaul.2022.csv"))
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
storm_file_list_beta <- list.files(path="FRCH_MOOS_VAUL_POKE_STRT_CARI/",
recursive=F,
pattern=".csv",
full.names=TRUE)
storm_list_beta<-do.call("list", lapply(storm_file_list_beta,
read.csv,
stringsAsFactors=FALSE,
header=T, row.names=1))
storm_file_list_beta = sub("FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
# storm_file_list_beta = sub("~/Documents/Storms_clean_repo/Storm_Events/2022/FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
storm_file_list_beta = sub(".csv", storm_file_list_beta, replacement = "")
names(storm_list_beta) = storm_file_list_beta
for(i in 1:length(storm_list_beta)){
storm_list_beta[[i]][["valuedatetime"]] = as.POSIXct(storm_list_beta[[i]][["valuedatetime"]],
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
} # changing character format into datetime
VAUL_storm_list_beta = storm_list_beta[c(136:147)] #12
View(storm_list_beta)
View(VAUL_storm_list_beta)
VAUL_NO3_storm_list_beta = VAUL_storm_list_beta[c(grep("NO3", names(VAUL_storm_list_beta)))]
VAUL_fDOM_storm_list_beta = VAUL_storm_list_beta[c(grep("fDOM", names(VAUL_storm_list_beta)))]
VAUL_SpCond_storm_list_beta = VAUL_storm_list_beta[c(grep("SPC", names(VAUL_storm_list_beta)))]
VAUL_turb_storm_list_beta = VAUL_storm_list_beta[c(grep("turb", names(VAUL_storm_list_beta)))]
VAUL_abs_storm_list_beta = VAUL_storm_list_beta[c(grep("abs", names(VAUL_storm_list_beta)))]
VAUL_Q_storm_list_beta = VAUL_storm_list_beta[c(grep("Q", names(VAUL_storm_list_beta)))]
# VAUL #
VAUL_NO3_storm$storm.ID = c(rep("storm1", 127),
rep("storm2", 763))
VAUL_NO3_storm <- map2_df(VAUL_Q_storm_list_beta, VAUL_NO3_storm_list_beta, inner_join, by = "valuedatetime")
# VAUL #
VAUL_NO3_storm$storm.ID = c(rep("storm1", 127),
rep("storm2", 763))
