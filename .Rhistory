# convert to datetime
FRCH_RainGauge_2019$Datetime <- ymd_hms(FRCH_RainGauge_2019$Datetime)
POKE_RainGauge_2019$DateTime <- ymd_hms(POKE_RainGauge_2019$DateTime)
VAUL_RainGauge_2019$DateTime <- ymd_hms(VAUL_RainGauge_2019$DateTime)
airtempmean$date_timeAK <- ymd_hms(airtempmean$date_timeAK)
# force to AK time
FRCH_RainGauge_2019$Datetime <- force_tz(FRCH_RainGauge_2019$Datetime, "America/Anchorage") # converting character to datetime
POKE_RainGauge_2019$DateTime <- force_tz(POKE_RainGauge_2019$DateTime, "America/Anchorage") # converting character to datetime
VAUL_RainGauge_2019$DateTime <- force_tz(VAUL_RainGauge_2019$DateTime, "America/Anchorage") # converting character to datetime
airtempmean$date_timeAK <- force_tz(airtempmean$date_timeAK, "America/Anchorage") # converting character to datetime
names(airtempmean)[2] <- "DateTime"
# round to nearest 15 min
FRCH_RainGauge_2019$DateTime <- lubridate::floor_date(FRCH_RainGauge_2019$Datetime, "15 minutes")
POKE_RainGauge_2019$DateTime <- lubridate::floor_date(POKE_RainGauge_2019$DateTime, "15 minutes")
VAUL_RainGauge_2019$DateTime <- lubridate::floor_date(VAUL_RainGauge_2019$DateTime, "15 minutes")
DOD.2019 <- read.csv(here("processed_sensor_data", "2019", "SUNA.EXO.int.corr.lab_2019.csv"))
DOD.2019 <- DOD.2019[c("datetimeAK", "site.ID", "fDOM.QSU.T.turb.col", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
names(DOD.2019) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
DOD.2019$datetimeAK <- ymd_hms(DOD.2019$datetimeAK) # converting character to datetime
DOD.2019$datetimeAK <- force_tz(DOD.2019$datetimeAK, "America/Anchorage") # converting character to datetime
# VAUL ####
VAULstorm_file_list <- list.files(path = "All_sites/",
recursive=F,
pattern="VAUL",
full.names=TRUE)
VAUL_storms<-do.call("rbind", lapply(VAULstorm_file_list,
read.csv,
check.names = FALSE,
stringsAsFactors=FALSE,
header=T, blank.lines.skip = TRUE, fill=TRUE))
VAUL_storms$storm.num = c(rep("storm1", 191),
rep("storm2", 207),
rep("storm3", 191),
rep("storm4a", 307),
rep("storm4c", 227),
rep("storm5", 275),
rep("storm6", 263),
rep("storm7", 107),
rep("storm8a", 455),
rep("storm8c", 191))
VAUL_storms$DateTime <- as.POSIXct(VAUL_storms$DateTime)
VAUL.2019.storms.1<- left_join(VAUL_storms, VAUL_RainGauge_2019, by = "DateTime")
VAUL.2019.storms.1<- left_join(VAUL.2019.storms.1, airtempmean, by = "DateTime")
names(VAUL.2019.storms.1)[names(VAUL.2019.storms.1) == ''] <- 'x'
VAUL.2019.per.storm.1 <- VAUL.2019.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(inst_rainfall_mm), list(precip = sum), na.rm = TRUE)
temp <- VAUL.2019.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(airtemp_100.1000cm_mean), list(temp = mean), na.rm = TRUE) # finding the mean temperature for each storm event
VAUL.2019.per.storm.1$temp <- temp$temp
VAUL.2019 <-  subset(DOD.2019, site.ID == "VAUL")
VAUL.2019$DateTime <- as.POSIXct(VAUL.2019$datetimeAK, tz = "America/Anchorage", format = "%Y-%m-%d %H:%M")
VAUL.2019 <- left_join(VAUL.2019, VAUL_RainGauge_2019, by = "DateTime")
VAUL.2019 <- left_join(VAUL.2019, airtempmean, by = "DateTime")
VAUL.2019$week <- rollapplyr(VAUL.2019$inst_rainfall_mm, 672, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2019$month <- rollapplyr(VAUL.2019$inst_rainfall_mm, 2688, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2019$ThreeMonth <- rollapplyr(VAUL.2019$inst_rainfall_mm, 8064, sum, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2019$temp.week <- rollapplyr(VAUL.2019$airtemp_100.1000cm_mean, 672, mean, na.rm = TRUE, fill = NA, partial = TRUE)
VAUL.2019.1 <- left_join(VAUL.2019.storms.1, VAUL.2019, by = "DateTime") # week month and 3 month precip totals
VAUL.2019.per.storm.2 <- VAUL.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(week), list(precip.week = first), na.rm = TRUE) # grouping weekly precip leading up to storm event
VAUL.2019.per.storm.3 <- VAUL.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(month), list(precip.month = first), na.rm = TRUE) # groouping monthly precip leading up to a storm
VAUL.2019.per.storm.4 <- VAUL.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(ThreeMonth), list(ThreeMonth = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
VAUL.2019.per.storm.5 <- VAUL.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(temp.week), list(temp.week = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.mean.precip.vaul.NO3 <- subset(HI.mean.precip.response, year == "2019" & site.ID == "VAUL" & response == "NO3")
HI.mean.precip.vaul.fDOM <- subset(HI.mean.precip.response, year == "2019" & site.ID == "VAUL" & response == "fDOM")
HI.mean.precip.vaul.SPC <- subset(HI.mean.precip.response, year == "2019" & site.ID == "VAUL" & response == "SPC")
HI.mean.precip.vaul.turb <- subset(HI.mean.precip.response, year == "2019" & site.ID == "VAUL" & response == "turb")
HI.mean.precip.vaul.abs <- subset(HI.mean.precip.response, year == "2019" & site.ID == "VAUL" & response == "abs")
HI.vaul.no3.2019 <- left_join(HI.mean.precip.vaul.NO3, VAUL.2019.per.storm.1, by = "storm.num")
HI.vaul.no3.2019 <- left_join(HI.vaul.no3.2019, VAUL.2019.per.storm.2, by = "storm.num")
HI.vaul.no3.2019 <- left_join(HI.vaul.no3.2019, VAUL.2019.per.storm.3, by = "storm.num")
HI.vaul.no3.2019 <- left_join(HI.vaul.no3.2019, VAUL.2019.per.storm.4, by = "storm.num")
HI.vaul.no3.2019 <- left_join(HI.vaul.no3.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.no3 <- lm(HI.vaul.no3.2019$HI ~ HI.vaul.no3.2019$precip) # model one with just total precip
vaul.lm.no3.2 <- lm(HI.vaul.no3.2019$HI ~ HI.vaul.no3.2019$precip.week) # model one with just total precip
vaul.lm.no3.3 <- lm(HI.vaul.no3.2019$HI ~ HI.vaul.no3.2019$precip.month) # model one with just total precip
vaul.lm.no3.4 <- lm(HI.vaul.no3.2019$HI ~ HI.vaul.no3.2019$ThreeMonth) # model one with just total precip
vaul.formula <- y ~ x
va <- HI.vaul.no3.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
vb <- HI.vaul.no3.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
vc <- HI.vaul.no3.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
vd <- HI.vaul.no3.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.vaul.fDOM.2019 <- left_join(HI.mean.precip.vaul.fDOM, VAUL.2019.per.storm.1, by = "storm.num")
HI.vaul.fDOM.2019 <- left_join(HI.vaul.fDOM.2019, VAUL.2019.per.storm.2, by = "storm.num")
HI.vaul.fDOM.2019 <- left_join(HI.vaul.fDOM.2019, VAUL.2019.per.storm.3, by = "storm.num")
HI.vaul.fDOM.2019 <- left_join(HI.vaul.fDOM.2019, VAUL.2019.per.storm.4, by = "storm.num")
HI.vaul.fDOM.2019 <- left_join(HI.vaul.fDOM.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.fDOM <- lm(HI.vaul.fDOM.2019$HI ~ HI.vaul.fDOM.2019$precip) # model one with just total precip
vaul.lm.fDOM.2 <- lm(HI.vaul.fDOM.2019$HI ~ HI.vaul.fDOM.2019$precip.week) # model one with just total precip
vaul.lm.fDOM.3 <- lm(HI.vaul.fDOM.2019$HI ~ HI.vaul.fDOM.2019$precip.month) # model one with just total precip
vaul.lm.fDOM.4 <- lm(HI.vaul.fDOM.2019$HI ~ HI.vaul.fDOM.2019$ThreeMonth) # model one with just total precip
ve <- HI.vaul.fDOM.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
vf <- HI.vaul.fDOM.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
vg <- HI.vaul.fDOM.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
vh <- HI.vaul.fDOM.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.vaul.SPC.2019 <- left_join(HI.mean.precip.vaul.SPC, VAUL.2019.per.storm.1, by = "storm.num")
HI.vaul.SPC.2019 <- left_join(HI.vaul.SPC.2019, VAUL.2019.per.storm.2, by = "storm.num")
HI.vaul.SPC.2019 <- left_join(HI.vaul.SPC.2019, VAUL.2019.per.storm.3, by = "storm.num")
HI.vaul.SPC.2019 <- left_join(HI.vaul.SPC.2019, VAUL.2019.per.storm.4, by = "storm.num")
HI.vaul.SPC.2019 <- left_join(HI.vaul.SPC.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.SPC <- lm(HI.vaul.SPC.2019$HI ~ HI.vaul.SPC.2019$precip) # model one with just total precip
vaul.lm.SPC.2 <- lm(HI.vaul.SPC.2019$HI ~ HI.vaul.SPC.2019$precip.week) # model one with just total precip
vaul.lm.SPC.3 <- lm(HI.vaul.SPC.2019$HI ~ HI.vaul.SPC.2019$precip.month) # model one with just total precip
vaul.lm.SPC.4 <- lm(HI.vaul.SPC.2019$HI ~ HI.vaul.SPC.2019$ThreeMonth) # model one with just total precip
vi <- HI.vaul.SPC.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
vj <- HI.vaul.SPC.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
vk <- HI.vaul.SPC.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
vl <- HI.vaul.SPC.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
HI.vaul.turb.2019 <- left_join(HI.mean.precip.vaul.turb, VAUL.2019.per.storm.1, by = "storm.num")
HI.vaul.turb.2019 <- left_join(HI.vaul.turb.2019, VAUL.2019.per.storm.2, by = "storm.num")
HI.vaul.turb.2019 <- left_join(HI.vaul.turb.2019, VAUL.2019.per.storm.3, by = "storm.num")
HI.vaul.turb.2019 <- left_join(HI.vaul.turb.2019, VAUL.2019.per.storm.4, by = "storm.num")
HI.vaul.turb.2019 <- left_join(HI.vaul.turb.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.turb <- lm(HI.vaul.turb.2019$HI ~ HI.vaul.turb.2019$precip) # model one with just total precip
vaul.lm.turb.2 <- lm(HI.vaul.turb.2019$HI ~ HI.vaul.turb.2019$precip.week) # model one with just total precip
vaul.lm.turb.3 <- lm(HI.vaul.turb.2019$HI ~ HI.vaul.turb.2019$precip.month) # model one with just total precip
vaul.lm.turb.4 <- lm(HI.vaul.turb.2019$HI ~ HI.vaul.turb.2019$ThreeMonth) # model one with just total precip
vm <- HI.vaul.turb.2019 %>%
ggplot(aes(x=precip,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL turb") +
xlab("Precip") +
ylab("HI-Solute Storage") # plot model
vn <- HI.vaul.turb.2019 %>%
ggplot(aes(x=precip.week,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL turb") +
xlab("One-week Precip") +
ylab("HI-Solute Storage") # plot model
vo <- HI.vaul.turb.2019 %>%
ggplot(aes(x=precip.month,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL turb") +
xlab("One-month Precip") +
ylab("HI-Solute Storage") # plot model
vp <- HI.vaul.turb.2019 %>%
ggplot(aes(x=ThreeMonth,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL turb") +
xlab("Three-month Precip") +
ylab("HI-Solute Storage") # plot model
sum.time <- VAUL.2019.storms.1 %>%
mutate(grp=data.table::rleid(storm.num))%>%
group_by(grp) %>%
summarise(storm.num=max(storm.num),TOTAL.TIME=difftime(max(DateTime),
min(DateTime),units="hour"))%>%
group_by(storm.num) %>%
summarise(TOTAL.TIME=sum(TOTAL.TIME)) # creating a total time column
HI.vaul.no3.2.2019 <- left_join(HI.vaul.no3.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.vaul.no3.2.2019$TOTAL.TIME <- as.numeric(HI.vaul.no3.2.2019$TOTAL.TIME)
HI.vaul.no3.2.2019$Intensity <- HI.vaul.no3.2.2019$precip/HI.vaul.no3.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
vaul.lm.no3.2 <- lm(HI.vaul.no3.2.2019$HI ~ HI.vaul.no3.2.2019$precip + HI.vaul.no3.2.2019$Intensity) # model one with total precip and intensity
vq <- HI.vaul.no3.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.fDOM.2.2019 <- left_join(HI.vaul.fDOM.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.vaul.fDOM.2.2019$TOTAL.TIME <- as.numeric(HI.vaul.fDOM.2.2019$TOTAL.TIME)
HI.vaul.fDOM.2.2019$Intensity <- HI.vaul.fDOM.2.2019$precip/HI.vaul.fDOM.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
vaul.lm.fDOM.2 <- lm(HI.vaul.fDOM.2.2019$HI ~ HI.vaul.fDOM.2.2019$precip + HI.vaul.fDOM.2.2019$Intensity) # model one with total precip and intensity
vr <- HI.vaul.fDOM.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.SPC.2.2019 <- left_join(HI.vaul.SPC.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.vaul.SPC.2.2019$TOTAL.TIME <- as.numeric(HI.vaul.SPC.2.2019$TOTAL.TIME)
HI.vaul.SPC.2.2019$Intensity <- HI.vaul.SPC.2.2019$precip/HI.vaul.SPC.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
vaul.lm.SPC.2 <- lm(HI.vaul.SPC.2.2019$HI ~ HI.vaul.SPC.2.2019$precip + HI.vaul.SPC.2.2019$Intensity) # model one with total precip and intensity
vs <- HI.vaul.SPC.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.turb.2.2019 <- left_join(HI.vaul.turb.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.vaul.turb.2.2019$TOTAL.TIME <- as.numeric(HI.vaul.turb.2.2019$TOTAL.TIME)
HI.vaul.turb.2.2019$Intensity <- HI.vaul.turb.2.2019$precip/HI.vaul.turb.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
vaul.lm.turb.2 <- lm(HI.vaul.turb.2.2019$HI ~ HI.vaul.turb.2.2019$precip + HI.vaul.turb.2.2019$Intensity) # model one with total precip and intensity
vt <- HI.vaul.turb.2.2019 %>%
ggplot(aes(x=Intensity,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL turb") +
xlab("Intensity (mm/hr)") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
# day of year #
VAUL.2019.1$day <- julian(VAUL.2019.1$DateTime, origin = as.POSIXct('2019-01-01', tz = 'America/Anchorage')) # making a fractional day column
VAUL.2019.1$day <- as.numeric(VAUL.2019.1$day)
VAUL.2019.per.storm.5 <- VAUL.2019.1 %>% group_by(storm.num) %>%
summarise_at(vars(day), list(doy = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.vaul.no3.2.2019 <- left_join(HI.vaul.no3.2.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.no3.5 <- lm(HI.vaul.no3.2.2019$HI ~ HI.vaul.no3.2.2019$doy)
vu <- HI.vaul.no3.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL NO3") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.fDOM.2.2019 <- left_join(HI.vaul.fDOM.2.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.fDOM.5 <- lm(HI.vaul.fDOM.2.2019$HI ~ HI.vaul.fDOM.2.2019$doy)
vv <- HI.vaul.fDOM.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL fDOM") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.SPC.2.2019 <- left_join(HI.vaul.SPC.2.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.SPC.5 <- lm(HI.vaul.SPC.2.2019$HI ~ HI.vaul.SPC.2.2019$doy)
vw <- HI.vaul.SPC.2.2019 %>%
ggplot(aes(x=doy,
y=HI)) +
geom_point() +
geom_smooth(method = "lm") +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
ggtitle("VAUL SPC") +
xlab("Day of year") +
ylab("HI-Solute Storage") +
theme_classic() # plot model
HI.vaul.abs.2019 <- left_join(HI.mean.precip.vaul.abs, VAUL.2019.per.storm.1, by = "storm.num")
HI.vaul.abs.2019 <- left_join(HI.vaul.abs.2019, VAUL.2019.per.storm.2, by = "storm.num")
HI.vaul.abs.2019 <- left_join(HI.vaul.abs.2019, VAUL.2019.per.storm.3, by = "storm.num")
HI.vaul.abs.2019 <- left_join(HI.vaul.abs.2019, VAUL.2019.per.storm.4, by = "storm.num")
HI.vaul.abs.2019 <- left_join(HI.vaul.abs.2019, VAUL.2019.per.storm.5, by = "storm.num")
vaul.lm.abs <- lm(HI.vaul.abs.2019$HI ~ HI.vaul.abs.2019$precip) # model one with just total precip
vaul.lm.abs.2 <- lm(HI.vaul.abs.2019$HI ~ HI.vaul.abs.2019$precip.week) # model one with just total precip
vaul.lm.abs.3 <- lm(HI.vaul.abs.2019$HI ~ HI.vaul.abs.2019$precip.month) # model one with just total precip
vaul.lm.abs.4 <- lm(HI.vaul.abs.2019$HI ~ HI.vaul.abs.2019$ThreeMonth) # model one with just total precip
vaul.lm.abs.5 <- lm(HI.vaul.turb.2019$HI ~ HI.vaul.turb.2019$temp.week) # model one with just total precip
HI.vaul.abs.2.2019 <- left_join(HI.vaul.abs.2019, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
HI.vaul.abs.2.2019$TOTAL.TIME <- as.numeric(HI.vaul.abs.2.2019$TOTAL.TIME)
HI.vaul.abs.2.2019$Intensity <- HI.vaul.abs.2.2019$precip/HI.vaul.abs.2.2019$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
HI.vaul.2019 <- rbind(HI.vaul.no3.2.2019, HI.vaul.fDOM.2.2019,
HI.vaul.SPC.2.2019, HI.vaul.turb.2.2019,
HI.vaul.abs.2.2019) # merging all responses together
HI.vaul.2019$burn <- "unburned" # adding a burn column
HI.vaul.2019$pf <- "high" # adding a pf column
View(HI.vaul.2019)
write.csv(HI.vaul.2019, here("Output_from_analysis", "04_Antecedent_Conditions", "2019", "HI.vaul.2019.csv"))
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2019")
storm_file_list_beta <- list.files(path="FRCH_MOOS_VAUL_POKE_STRT_CARI/",
recursive=F,
pattern=".csv",
full.names=TRUE)
storm_list_beta<-do.call("list", lapply(storm_file_list_beta,
read.csv,
stringsAsFactors=FALSE,
header=T, row.names=1))
storm_file_list_beta = sub("FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
storm_file_list_beta = sub(".csv", storm_file_list_beta, replacement = "")
names(storm_list_beta) = storm_file_list_beta
FRCH_storm_list_beta = storm_list_beta[c(1:72)] #72
STRT_storm_list_beta = storm_list_beta[c(73:138)] # 66
VAUL_storm_list_beta = storm_list_beta[c(139:198)] # 60
VAUL_NO3_storm_list_beta = VAUL_storm_list_beta[c(grep("NO3", names(VAUL_storm_list_beta)))]
VAUL_fDOM_storm_list_beta = VAUL_storm_list_beta[c(grep("fDOM", names(VAUL_storm_list_beta)))]
VAUL_SpCond_storm_list_beta = VAUL_storm_list_beta[c(grep("SPC", names(VAUL_storm_list_beta)))]
VAUL_turb_storm_list_beta = VAUL_storm_list_beta[c(grep("turb", names(VAUL_storm_list_beta)))]
VAUL_abs_storm_list_beta = VAUL_storm_list_beta[c(grep("abs", names(VAUL_storm_list_beta)))]
VAUL_Q_storm_list_beta = VAUL_storm_list_beta[c(grep("Q", names(VAUL_storm_list_beta)))]
# VAUL
for(i in 1:length(VAUL_Q_storm_list_beta)){
VAUL_Q_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_Q_storm_list_beta[[i]][["datavalue"]]-min(VAUL_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(VAUL_NO3_storm_list_beta)){
VAUL_NO3_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_NO3_storm_list_beta[[i]][["datavalue"]]-min(VAUL_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(VAUL_fDOM_storm_list_beta)){
VAUL_fDOM_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_fDOM_storm_list_beta[[i]][["datavalue"]]-min(VAUL_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(VAUL_SpCond_storm_list_beta)){
VAUL_SpCond_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_SpCond_storm_list_beta[[i]][["datavalue"]]-min(VAUL_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(VAUL_turb_storm_list_beta)){
VAUL_turb_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_turb_storm_list_beta[[i]][["datavalue"]]-min(VAUL_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(VAUL_abs_storm_list_beta)){
VAUL_abs_storm_list_beta[[i]][["datavalue.norm"]] =
(VAUL_abs_storm_list_beta[[i]][["datavalue"]]-min(VAUL_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(VAUL_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(VAUL_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
VAUL_NO3_storm <- map2_df(VAUL_Q_storm_list_beta, VAUL_NO3_storm_list_beta, inner_join, by = "valuedatetime")
# VAUL #
VAUL_NO3_storm$storm.ID = c(rep("storm1", 191),
rep("storm2", 207),
rep("storm3", 191),
rep("storm4a", 307),
rep("storm4c", 227),
rep("storm5", 275),
rep("storm6", 263),
rep("storm7", 107),
rep("storm8a", 455),
rep("storm8c", 191))
