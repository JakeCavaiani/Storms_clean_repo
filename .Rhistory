"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
CARI_turb_storm_ascending$DateTime <- as.POSIXct(CARI_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE_turb_storm_ascending$DateTime <- as.POSIXct(POKE_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
All_turb_storm<- rbind(FRCH_turb_storm_ascending, MOOS_turb_storm_ascending,
POKE_turb_storm_ascending, VAUL_turb_storm_ascending,
STRT_turb_storm_ascending, CARI_turb_storm_ascending )
beta.all.turb <- All_turb_storm %>% group_by(storm.ID, site.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
beta.all.turb$response_var <- "turb"
all.2022.ci.turb <- All_turb_storm %>%
group_by(site.ID, storm.ID) %>%
group_modify(~ parameters::model_parameters(stats::lm(turb.norm ~ Q.norm, data = .x)))
all.2022.ci.turb$response_var <- "turb"
### ABS ####
FRCH_abs_storm <- map2_df(FRCH_Q_storm_list_beta, FRCH_abs_storm_list_beta, inner_join, by = "valuedatetime")
MOOS_abs_storm <- map2_df(MOOS_Q_storm_list_beta, MOOS_abs_storm_list_beta, inner_join, by = "valuedatetime")
POKE_abs_storm <- map2_df(POKE_Q_storm_list_beta, POKE_abs_storm_list_beta, inner_join, by = "valuedatetime")
STRT_abs_storm <- map2_df(STRT_Q_storm_list_beta, STRT_abs_storm_list_beta, inner_join, by = "valuedatetime")
VAUL_abs_storm <- map2_df(VAUL_Q_storm_list_beta, VAUL_abs_storm_list_beta, inner_join, by = "valuedatetime")
FRCH_abs_storm$storm.ID = c(rep("storm1", 219),
rep("storm2", 235),
rep("storm3", 223),
rep("storm4", 167))
names(FRCH_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
FRCH_abs_storm$site.ID <- "FRCH"
cols <- c("abs.norm","Q.norm")
FRCH_abs_storm[cols] <- log(FRCH_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
FRCH_abs_storm <- FRCH_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
FRCH_abs_storm_ascending <- filter(FRCH_abs_storm, limb == "ascending")
FRCH_abs_storm_ascending <- FRCH_abs_storm_ascending[is.finite(FRCH_abs_storm_ascending$Q.norm) & is.finite(FRCH_abs_storm_ascending$abs.norm), ]
beta.all.abs <- FRCH_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# MOOS #
MOOS_abs_storm$storm.ID = c(rep("storm1", 199),
rep("storm2a", 71),
rep("storm2b", 151),
rep("storm3", 99),
rep("storm4", 215))
names(MOOS_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
MOOS_abs_storm$site.ID <- "MOOS"
MOOS_abs_storm[cols] <- log(MOOS_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
MOOS_abs_storm <- MOOS_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
MOOS_abs_storm_ascending <- filter(MOOS_abs_storm, limb == "ascending")
MOOS_abs_storm_ascending <- MOOS_abs_storm_ascending[is.finite(MOOS_abs_storm_ascending$Q.norm) & is.finite(MOOS_abs_storm_ascending$abs.norm), ]
beta.all.abs.moos.with.all <- MOOS_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# POKE #
POKE_abs_storm$storm.ID = c(rep("storm1", 139),
rep("storm2", 119),
rep("storm3", 95),
rep("storm4", 187))
names(POKE_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
POKE_abs_storm$site.ID <- "POKE"
POKE_abs_storm[cols] <- log(POKE_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
POKE_abs_storm <- POKE_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
POKE_abs_storm_ascending <- filter(POKE_abs_storm, limb == "ascending")
POKE_abs_storm_ascending <- POKE_abs_storm_ascending[is.finite(POKE_abs_storm_ascending$Q.norm) & is.finite(POKE_abs_storm_ascending$abs.norm), ]
beta.all.poke.moos.with.all <- POKE_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# STRT #
STRT_abs_storm$storm.ID = c(rep("storm1", 103),
rep("storm2", 191),
rep("storm3", 107))
names(STRT_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
STRT_abs_storm$site.ID <- "STRT"
STRT_abs_storm[cols] <- log(STRT_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
STRT_abs_storm <- STRT_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
STRT_abs_storm_ascending <- filter(STRT_abs_storm, limb == "ascending")
STRT_abs_storm_ascending <- STRT_abs_storm_ascending[is.finite(STRT_abs_storm_ascending$Q.norm) & is.finite(STRT_abs_storm_ascending$abs.norm), ]
beta.all.abs.strt <- STRT_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# VAUL #
VAUL_abs_storm$storm.ID = c(rep("storm1", 127),
rep("storm2", 763))
names(VAUL_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
VAUL_abs_storm$site.ID <- "VAUL"
VAUL_abs_storm[cols] <- log(VAUL_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
VAUL_abs_storm <- VAUL_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
VAUL_abs_storm_ascending <- filter(VAUL_abs_storm, limb == "ascending")
VAUL_abs_storm_ascending <- VAUL_abs_storm_ascending[is.finite(VAUL_abs_storm_ascending$Q.norm) & is.finite(VAUL_abs_storm_ascending$abs.norm), ]
beta.all.abs.vaul <- VAUL_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# ALL #
FRCH_abs_storm_ascending$DateTime <- as.POSIXct(FRCH_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS_abs_storm_ascending$DateTime <- as.POSIXct(MOOS_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT_abs_storm_ascending$DateTime <- as.POSIXct(STRT_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL_abs_storm_ascending$DateTime <- as.POSIXct(VAUL_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE_abs_storm_ascending$DateTime <- as.POSIXct(POKE_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
All_abs_storm <- rbind(FRCH_abs_storm_ascending, MOOS_abs_storm_ascending,
STRT_abs_storm_ascending, VAUL_abs_storm_ascending,
POKE_abs_storm_ascending)
beta.all.abs <- All_abs_storm %>% group_by(storm.ID, site.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
beta.all.abs$response_var <- "abs"
all.2022.ci.abs <- All_abs_storm %>%
group_by(site.ID, storm.ID) %>%
group_modify(~ parameters::model_parameters(stats::lm(abs.norm ~ Q.norm, data = .x)))
all.2022.ci.abs$response_var <- "abs"
beta.all.2022 <- rbind(all.2022.ci.no3, all.2022.ci.fDOM,
all.2022.ci.SPC, all.2022.ci.turb,
all.2022.ci.abs)
View(beta.all.2022)
write.csv(beta.all.2022, "~/Documents/Storms_clean_repo/Output_from_analysis/06_BETA/beta.2022.csv")
beta.all.2022 <- beta.all.2022 %>%
filter(Parameter != "(Intercept)")
library(here)
library(tidyverse)
library(nlme)
library(forecast)
library(stats)
library(readr)
library(ggplot2)
library(plotly)
library(GGally)
library(ggpmisc)
library(ggpubr)
library(ggExtra)
library(lubridate)
library(nlme)
library(MuMIn)
library(multcomp)
library(lme4)
library(car)
library(ggeffects)
library(dotwhisker)
library(broom)
library(jtools)
library(sjPlot)
library(AICcmodavg)
library(gtable)
library(gridExtra)
library(grid)
# reading in data
AMC <- read.csv(here("Output_from_analysis", "08_Catchment_characteristics", "Antecedent_HI_BETA_Catchment.csv"))
AMC <- AMC[c("Hyst_index", "HI_ymin", "HI_ymax", "site.ID", "storm.ID", "response_var", "Flush_index", "FI_ymin", "FI_ymax", "month.y", "day.y", "year", "Beta_index", "Beta_ymin", "Beta_ymax", "precip", "temp", "precip.week", "precip.month", "ThreeMonth", "temp.week", "TOTAL.TIME", "Intensity", "doy", "burn", "pf", "date", "TimeSinceChena", "SLOPE_MEAN", "fireyear_lg", "pctburn_lg", "areaburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central", "NDVI_p50__mean", "NDVI_p50__standard_deviation")] # selecting the columns that I want
AMC <- AMC[!duplicated(AMC$Hyst_index), ] # removing duplicated rows
Catchment_characteristics <- read.csv(here("Ancillary_data", "AK_polys_190903_Predictors.csv"))
Catchment_characteristics <- Catchment_characteristics[c("SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation")]
# scaling data #
#scaling #
Catchment_characteristics[c("SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation")] <- lapply(Catchment_characteristics[c("SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x","NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation")], function(x) c(scale(x)))
DOD_characteristics <- read.csv(here("Ancillary_data", "DOD_Sites_AK_polys_190903_Predictors.csv")) # this file only contains our DoD sites rather than the whole shabang
DOD_characteristics <- DOD_characteristics[c("site.ID", "SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation")]
DOD_characteristics$Deciduous.2010 <- NA # adding decidous metrics that we got from Neal
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "VAUL", 18.58329933,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "CARI", 18.20288543,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "STRT", 24.73179123,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "MOOS", 28.25133033,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "FRCH", 21.84850526,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "POKE", 20.1648046,.)))
DOD_characteristics$Deciduous.2016 <- NA # adding decidous metrics that we got from Neal
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "VAUL", 20.6,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "CARI", 22.5,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "STRT", 16.9,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "MOOS", 21.6,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "FRCH", 29.6,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2016),
~ifelse(site.ID == "POKE", 27.3,.)))
DOD_characteristics$Deciduous.2020 <- NA
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "VAUL", 18.77078206,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "CARI", 18.32282211,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "STRT", 19.85717556,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "MOOS", 22.65342014,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "FRCH", 22.48530634,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "POKE", 21.60550729,.)))
DOD_characteristics$Evergreen <- NA
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "VAUL", 50.8,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "CARI", 51.9,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "STRT", 15.2,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "MOOS", 10.3,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "FRCH", 53.4,.)))
DOD_characteristics <- DOD_characteristics %>%
mutate(across(c(Evergreen),
~ifelse(site.ID == "POKE", 30.5,.)))
# scaling data #
#scaling #
DOD_characteristics[c("SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation", "Deciduous.2010", "Deciduous.2016", "Deciduous.2020", "Evergreen")] <- lapply(DOD_characteristics[c("SLOPE_MEAN", "pctburn_lg", "Pf_Prob_1m_mean_x", "NDVI_p50__mean_abs_change", "NDVI_p50__mean_second_derivative_central",  "NDVI_p50__mean", "NDVI_p50__standard_deviation", "Deciduous.2010", "Deciduous.2016", "Deciduous.2020", "Evergreen")], function(x) c(scale(x)))
# CV and means across all years
CV.all <- AMC %>% group_by(response_var,site.ID) %>%
dplyr::summarise(n = n(),
meanHI = mean(Hyst_index, na.rm = TRUE),
meanBETA = mean(Beta_index, na.rm = TRUE),
sdHI = sd(Hyst_index, na.rm = TRUE),
sdBETA = sd(Beta_index, na.rm = TRUE),
CVhi = sdHI/meanHI,
CVbeta = sdBETA/meanBETA,
CatBurn = paste(burn),
CatPF = paste(pf),
Slope = as.numeric(SLOPE_MEAN),
fireyear_lg = as.numeric(fireyear_lg),
pctburn_lg = as.numeric(pctburn_lg),
areaburn_lg = as.numeric(areaburn_lg),
PF = as.numeric(Pf_Prob_1m_mean_x),
NDVI = as.numeric(NDVI_p50__mean)) %>%
mutate(seHI = sdHI/sqrt(n),
seBETA = sdBETA/sqrt(n))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "CARI", 0.2106070103, .)))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "FRCH", 0.2125723437, .)))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "MOOS", 0.2294949194, .)))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "POKE", 0.232423168, .)))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "STRT", 0.2558581085, .)))
CV.all <- CV.all %>%
mutate(across(c(NDVI),
~ifelse(site.ID == "VAUL", 0.227537246, .)))
# scaling data #
# all years in one
CV.all[c("Slope", "fireyear_lg", "pctburn_lg", "areaburn_lg", "PF", "NDVI")] <- lapply(CV.all[c("Slope", "fireyear_lg", "pctburn_lg", "areaburn_lg", "PF", "NDVI")], function(x) c(scale(x)))
# Adding scaled data for the deciduous cover from Neal data
CV.all$Deciduous.2010 <- NA
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "VAUL", -0.5862145,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "CARI", -0.1377014,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "STRT", -1.4596347,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "MOOS", -0.3501550,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "FRCH", 1.5383212,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2010),
~ifelse(site.ID == "POKE", 0.9953843,.)))
CV.all$Deciduous.2020 <- NA
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "VAUL", -1.068837,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "CARI", -1.3259120,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "STRT", -0.4386875,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "MOOS", 1.1782128,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "FRCH", 1.0810027,.)))
CV.all <- CV.all %>%
mutate(across(c(Deciduous.2020),
~ifelse(site.ID == "POKE", 0.5722677,.)))
CV_all_NO3 = subset(CV.all, response_var == "NO3")
# fDOM #
CV_all_fDOM = subset(CV.all, response_var == "fDOM")
# SPC #
CV_all_SPC = subset(CV.all, response_var == "SPC")
# turb #
CV_all_turb = subset(CV.all, response_var == "turb")
``
fDOM_data<- CV_all_fDOM[,c("site.ID", "n", "meanHI", "meanBETA", "sdHI", "sdBETA", "Slope", "fireyear_lg", "pctburn_lg", "areaburn_lg", "PF", "NDVI", "Deciduous.2010", "Deciduous.2020", "CatBurn", "CatPF", "seHI", "seBETA")]
fDOM_data <- fDOM_data[!duplicated(fDOM_data$meanHI), ] # removing duplicated rows
HI.fDOM.slope <- lm(meanHI ~ Slope,
data = fDOM_data)
HI.fDOM.burn <- lm(meanHI ~ pctburn_lg,
data = fDOM_data)
HI.fDOM.deciduous <- lm(meanHI ~ Deciduous.2010,
data = fDOM_data)
models <- list(HI.fDOM.slope, HI.fDOM.burn, HI.fDOM.deciduous)
aictab(cand.set = models) # slope is better model, deltaAIC > 2
summary(HI.fDOM.slope) # p-value 0.0624
fdom.hi.slope <- ggplot(fDOM_data, aes(x = Deciduous.2020, y = meanHI)) +
geom_point(size = 3) +
geom_smooth(method = "lm", na.rm = TRUE, fullrange = TRUE, color = "black") +
stat_poly_eq(formula = y~x,
label.y = "top", label.x = "right",
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE, size = 5) +
geom_errorbar(aes(x=Slope, ymin=meanHI-seHI, ymax=meanHI+seHI), width=0.2, colour="black", alpha=0.9, size=1.0) +
stat_fit_glance(method = 'lm',
method.args = list(formula = y~x),
geom = 'text',
aes(label = paste("P-value = ", signif(..p.value.., digits = 2), sep = "")),
label.y = 0.15, label.x = 0, size = 5) +
theme_classic() +
theme(axis.text.x=element_text(size=20),
axis.text.y = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.key.size = unit(2.0, 'cm'),
strip.text = element_text(size = 20)) +
xlab("Catchment slope") +
ylab("Mean HI-fDOM")
View(fdom.hi.slope)
fdom.hi.slope
fdom.hi.slope <- ggplot(fDOM_data, aes(x = Slope, y = meanHI)) +
geom_point(size = 3) +
geom_smooth(method = "lm", na.rm = TRUE, fullrange = TRUE, color = "black") +
stat_poly_eq(formula = y~x,
label.y = "top", label.x = "right",
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE, size = 5) +
geom_errorbar(aes(x=Slope, ymin=meanHI-seHI, ymax=meanHI+seHI), width=0.2, colour="black", alpha=0.9, size=1.0) +
stat_fit_glance(method = 'lm',
method.args = list(formula = y~x),
geom = 'text',
aes(label = paste("P-value = ", signif(..p.value.., digits = 2), sep = "")),
label.y = 0.15, label.x = 0, size = 5) +
theme_classic() +
theme(axis.text.x=element_text(size=20),
axis.text.y = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.key.size = unit(2.0, 'cm'),
strip.text = element_text(size = 20)) +
xlab("Catchment slope") +
ylab("Mean HI-fDOM")
fdom.hi.slope
BETA.fDOM.slope <- lm(meanBETA ~ Slope,
data = fDOM_data)
BETA.fDOM.burn <- lm(meanBETA ~ pctburn_lg,
data = fDOM_data)
BETA.fDOM.deciduous <- lm(meanBETA ~ Deciduous.2020,
data = fDOM_data)
models <- list(BETA.fDOM.slope, BETA.fDOM.burn, BETA.fDOM.deciduous)
fDOM.beta.slope <- ggplot(fDOM_data, aes(x = Deciduous.2020, y = meanBETA)) +
geom_point(size = 3) +
geom_smooth(method = "lm", na.rm = TRUE, fullrange = TRUE, color = "black") +
stat_poly_eq(formula = y~x,
label.y = "top", label.x = "left",
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE, size = 5) +
geom_errorbar(aes(x=Slope, ymin=meanBETA-seBETA, ymax=meanBETA+seBETA), width=0.2, colour="black", alpha=0.9, size=1.0) +
stat_fit_glance(method = 'lm',
method.args = list(formula = y~x),
geom = 'text',
aes(label = paste("P-value = ", signif(..p.value.., digits = 2), sep = "")),
label.y = 1.1, label.x = -1, size = 5.1) +
theme_classic() +
theme(axis.text.x=element_text(size=20),
axis.text.y = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.key.size = unit(2.0, 'cm'),
strip.text = element_text(size = 20)) +
xlab("Catchment slope") +
ylab("Mean ÃŸ-fDOM")
fDOM.beta.slope
View(fDOM_data)
fdom.hi.slope <- ggplot(fDOM_data, aes(x = Deciduous.2020, y = meanHI)) +
geom_point(size = 3) +
geom_smooth(method = "lm", na.rm = TRUE, fullrange = TRUE, color = "black") +
stat_poly_eq(formula = y~x,
label.y = "top", label.x = "right",
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE, size = 5) +
geom_errorbar(aes(x=Slope, ymin=meanHI-seHI, ymax=meanHI+seHI), width=0.2, colour="black", alpha=0.9, size=1.0) +
stat_fit_glance(method = 'lm',
method.args = list(formula = y~x),
geom = 'text',
aes(label = paste("P-value = ", signif(..p.value.., digits = 2), sep = "")),
label.y = 0.15, label.x = 0, size = 5) +
theme_classic() +
theme(axis.text.x=element_text(size=20),
axis.text.y = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.key.size = unit(2.0, 'cm'),
strip.text = element_text(size = 20)) +
xlab("Catchment slope") +
ylab("Mean HI-fDOM")
fdom.hi.slope
NO3_data <- NO3_data[!duplicated(NO3_data$meanHI), ] # removing duplicated rows
HI.no3.slope <- lm(meanHI ~ Slope,
data = NO3_data)
NO3_data<- CV_all_NO3[,c("site.ID", "n", "meanHI", "meanBETA", "sdHI", "sdBETA", "Slope", "fireyear_lg", "pctburn_lg", "areaburn_lg", "PF", "NDVI", "Deciduous.2010", "Deciduous.2020", "CatBurn", "CatPF", "seHI", "seBETA")]
NO3_data <- NO3_data[!duplicated(NO3_data$meanHI), ] # removing duplicated rows
HI.no3.slope <- lm(meanHI ~ Slope,
data = NO3_data)
HI.no3.burn <- lm(meanHI ~ pctburn_lg,
data = NO3_data)
HI.no3.deciduous <- lm(meanHI ~ Deciduous.2010,
data = NO3_data)
models <- list(HI.no3.slope, HI.no3.burn, HI.no3.deciduous)
aictab(cand.set = models) # burn is the better model
#no3.hi.burn
vn = expression(paste("Mean HI-"*N*O[3]^"-"))
no3.hi.burn <- ggplot(NO3_data, aes(x = Deciduous.2020, y = meanHI)) +
geom_point(size = 3) +
geom_smooth(method = "lm", na.rm = TRUE, fullrange = TRUE, color = "black") +
geom_errorbar(aes(x=pctburn_lg, ymin=meanHI-seHI, ymax=meanHI+seHI), width=0.2, colour="black", alpha=0.9, size=1.0) +
stat_poly_eq(formula = y~x,
label.y = "top", label.x = "left",
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE, size = 5.5) +
stat_fit_glance(method = 'lm',
method.args = list(formula = y~x),
geom = 'text',
aes(label = paste("P-value = ", signif(..p.value.., digits = 2), sep = "")),
label.y = 0.32, label.x = -.35, size = 5.5) +
theme_classic() +
theme(axis.text.x=element_text(size=20),
axis.text.y = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.key.size = unit(2.0, 'cm'),
strip.text = element_text(size = 20)) +
xlab("Burn Extent") +
ylab(vn) +
theme(aspect.ratio = 1)
no3.hi.burn
