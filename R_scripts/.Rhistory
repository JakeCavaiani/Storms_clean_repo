"Precipitation Week",
"Storm Precipitation")) +
theme_bw() +
ggtitle("HI-fDOM") +
theme(axis.text.x=element_text(size=15),
axis.text.y = element_blank(),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.position = "none",
plot.title = element_text(size = 20))
fDOM_hi
ggsave("HI_fDOM.pdf",
path = here("plots", "Coefficient_Plots", "HI"),
width = 7, height = 7)
fDOM_hi <- Plot_1 +
xlab("") + ylab("") +
geom_vline(xintercept = 0,
colour = "grey80",
linetype = 1) +
scale_y_discrete(labels= c("Seasonality",
"Precipitation Month",
"Precipitation Week",
"Storm Precipitation"))
fDOM_hi
fDOM_hi <- Plot_1 +
xlab("") + ylab("") +
geom_vline(xintercept = 0,
colour = "grey80",
linetype = 1) +
scale_y_discrete(labels= c("Seasonality",
"Precipitation Month",
"Precipitation Week",
"Storm Precipitation")) +
theme_bw() +
ggtitle("HI-fDOM") +
theme(axis.text.x=element_text(size=15),
axis.text.y = element_text(size = 15),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
legend.position = "none",
plot.title = element_text(size=20))
fDOM_hi
ggsave("HI_fDOM.pdf",
path = here("plots", "Coefficient_Plots", "HI"),
width = 7, height = 7)
library(xfun)
library(bit)
library(vctrs)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(plyr)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
library(EcoHydRology)
library(dplyr)
library(readr)
library(googledrive)
library(purrr)
library(here)
############################ 2015 ################################################
# here #
Q.daily.2015 <- read.csv(here("processed_sensor_data", "2015", "Q.daily.2015.csv"))
Q.2015 <- read.csv(here("processed_sensor_data", "2015", "Predicted_Q_2015.csv"))
View(Q.daily.2015)
View(Q.2015)
names(Q.2015)
Q.2015 <- Q.2015[c("Site", "DateTimeAK", "Q")]
str(Q.2015)
Q.2015$day <- as.Date(Q.2015$DateTimeAK)
names(Q.2015) <- c("site.ID", "datetimeAK", "Q", "day") # renaming the column headers to match that of the chem file
Q.2015$datetimeAK <- ymd_hms(Q.2015$datetimeAK) # converting character to datetime
str(Q.2015)
head(Q.2015$datetimeAK)
?force_tz
Q.2015$datetimeAK <- force_tz(Q.2015$datetimeAK, "America/Anchorage") # converting character to datetime
head(Q.2015$datetimeAK)
chem.2015 <- read.csv(here("processed_sensor_data", "2015", "SUNA.EXO.int.corr.lab_2015.csv"), na.strings = "NA")
names(chem.2015)
chem.2015 <- chem.2015[c("datetimeAK", "site.ID", "fDOM.QSU.mn.adj", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj")]
chem.2015 <- chem.2015[c("datetimeAK", "site.ID", "fDOM.QSU.mn.adj", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab")]
chem.2015 <- chem.2015[c("datetimeAK", "Site", "fDOM.QSU.adj.T.turb.int", "SpCond.uScm.adj",
"Turbidity.FNU.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
View(chem.2015)
chem.2015$datetimeAK <- ymd_hms(chem.2015$datetimeAK) # converting character to datetime
names(chem.2015)
names(chem.2015) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
### PLOTTING TO MAKE SURE OUR INPUT DATA LOOKS GOOD BEFORE DOING LITERALLY EVERYTHING ELSE ####
# pivot long to get all the response variables in one column
chem_2015_long <- chem.2015 %>%
filter(site.ID %in% c("FRCH", "MOOS")) %>%
pivot_longer(
cols = fDOM:ABS_254,
names_to = "response_var",
values_to = "concentration",
values_drop_na = TRUE
) # converting to a long format so each response_var is within a single column
ggplot(chem_2015_long, aes(x = datetimeAK, y = concentration, color = site.ID)) +
geom_point(size = 0.5) +
scale_color_manual(values=c("#FF7F00", "#A6761D")) +
facet_wrap(~response_var, scales = "free") +
theme_classic()
library(xfun)
library(bit)
library(vctrs)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(plyr)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
#library(EcoHydRology)
library(dplyr)
library(readr)
library(googledrive)
library(purrr)
library(here)
############################ 2015 ################################################
# here #
Q.daily.2015 <- read.csv(here("processed_sensor_data", "2015", "Q.daily.2015.csv"))
Q.2015 <- read.csv(here("processed_sensor_data", "2015", "Predicted_Q_2015.csv"))
Q.2015 <- Q.2015[c("Site", "DateTimeAK", "Q")]
Q.2015$day <- as.Date(Q.2015$DateTimeAK)
names(Q.2015) <- c("site.ID", "datetimeAK", "Q", "day") # renaming the column headers to match that of the chem file
Q.2015$datetimeAK <- ymd_hms(Q.2015$datetimeAK) # converting character to datetime
Q.2015$datetimeAK <- force_tz(Q.2015$datetimeAK, "America/Anchorage") # converting character to datetime
chem.2015 <- read.csv(here("processed_sensor_data", "2015", "SUNA.EXO.int.corr.lab_2015.csv"), na.strings = "NA")
chem.2015 <- chem.2015[c("datetimeAK", "Site", "fDOM.QSU.adj.T.turb.int", "SpCond.uScm.adj",
"Turbidity.FNU.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
chem.2015$datetimeAK <- ymd_hms(chem.2015$datetimeAK) # converting character to datetime
names(chem.2015) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
### PLOTTING TO MAKE SURE OUR INPUT DATA LOOKS GOOD BEFORE DOING LITERALLY EVERYTHING ELSE ####
# pivot long to get all the response variables in one column
chem_2015_long <- chem.2015 %>%
filter(site.ID %in% c("FRCH", "MOOS")) %>%
pivot_longer(
cols = fDOM:ABS_254,
names_to = "response_var",
values_to = "concentration",
values_drop_na = TRUE
) # converting to a long format so each response_var is within a single column
ggplot(chem_2015_long, aes(x = datetimeAK, y = concentration, color = site.ID)) +
geom_point(size = 0.5) +
scale_color_manual(values=c("#FF7F00", "#A6761D")) +
facet_wrap(~response_var, scales = "free") +
theme_classic()
# subset data by site #
FRCH.2015 <-  subset(chem.2015, site.ID == "FRCH")
View(FRCH.2015)
FRCH.2015 <- FRCH.2015[-c(12519:12849), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
MOOS.2015 <-  subset(chem.2015, site.ID == "MOOS")
View(MOOS.2015)
MOOS.2015 <- MOOS.2015[-c(12540:12796), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
DOD.2015 <- rbind(FRCH.2015, MOOS.2015)
View(DOD.2015)
DOD.2015 <- full_join(DOD.2015, Q.2015) # merging chem and discharge data
str(Q.2015)
str(chem.2015)
head(chem.2015$datetimeAK)
chem.2015$datetimeAK <- force_tz(chem.2015$datetimeAK, "America/Anchorage") # converting character to datetime
DOD.2015 <- full_join(DOD.2015, Q.2015) # merging chem and discharge data
DOD.2015 <- full_join(DOD.2015, Q.2015, by = "datetimeAK") # merging chem and discharge data
DOD.2015 <- full_join(DOD.2015, Q.2015, by = c("datetimeAK", "site.ID")) # merging chem and discharge data
DOD.2015 <- rbind(FRCH.2015, MOOS.2015)
View(DOD.2015)
View(Q.2015)
DOD.2015 <- full_join(DOD.2015, Q.2015, by = c("datetimeAK", "site.ID")) # merging chem and discharge data
DOD.2015 <- rbind(FRCH.2015, MOOS.2015)
DOD.2015 <- full_join(DOD.2015, Q.2015, by = c("datetimeAK")) # merging chem and discharge data
Q.2015 <- Q.2015 %>%
mutate(across(c(site.ID),
~ifelse(site.ID == "FRCH", "FRCH", "MOOS")))
Q.2015 <- Q.2015 %>%
mutate(across(c(site.ID),
~ifelse(site.ID == "French", "FRCH", "MOOS")))
Q.2015 <- Q.2015 %>%
mutate(across(c(site.ID),
~ifelse(site.ID == French, "FRCH", "MOOS")))
View(Q.2015)
Q.2015$site.ID
Q.2015 <- Q.2015 %>%
mutate(across(c(site.ID),
~ifelse(site.ID == French, NA, "MOOS")))
Q.2015 <- Q.2015 %>%
mutate(across(c(site.ID),
~ifelse(site.ID == "French", NA, "MOOS")))
head(Q.2015$site.ID)
?ifelse
Q.2015$site.ID <- ifelse(site.ID == "French", "FRCH", "MOOS")
Q.2015$site.ID <- ifelse(site.ID == "French", "FRCH", "MOOS")
Q.2015$site.ID <- ifelse(Q.2015$site.ID == "French", "FRCH", "MOOS")
DOD.2015 <- rbind(FRCH.2015, MOOS.2015)
DOD.2015 <- full_join(DOD.2015, Q.2015) # merging chem and discharge data
frch.final.discharge.2015 <- subset(Q.2015, site.ID == "FRCH")
moos.final.discharge.2015 <- subset(Q.2015, site.ID == "MOOS")
View(frch.final.discharge.2015)
Q.2015$day = format(as.POSIXct(Q.2015$datetimeAK,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q.2015$day = as.POSIXct(Q.2015$day, "%Y-%m-%d", tz="America/Anchorage")
Q.daily.2015 = with(Q.2015, tapply(Q, list(day, site.ID), mean))
Q.daily.2015 = as.data.frame(Q.daily.2015)
View(Q.daily.2015)
FRCH.Q.2015 = as.data.frame(Q.daily.2015$FRCH)
View(FRCH.Q.2015)
FRCH.Q.2015$day = as.Date(rownames(Q.daily.2015))
names(FRCH.Q.2015) = c("Discharge_Lsec", "day")
MOOS.Q.2015 = as.data.frame(Q.daily.2015$MOOS)
MOOS.Q.2015$day = as.Date(rownames(Q.daily.2015))
names(MOOS.Q.2015) = c("Discharge_Lsec", "day")
View(MOOS.Q.2015)
# join Q and chem data
# FRCH #
FRCH = full_join(frch.final.discharge.2015, FRCH.2015)
View(FRCH)
# MOOS #
MOOS = full_join(moos.final.discharge.2015, MOOS.2015)
any(is.na(FRCH.Q.2015$day))
any(is.na(FRCH.Q.2015$Discharge_Lsec))
View(FRCH.Q.2015)
any(is.na(MOOS.Q.2015$day))
any(is.na(MOOS.Q.2015$Discharge_Lsec))
View(MOOS.Q.2015)
nrow(MOOS.Q.2015)
MOOS.Q.2015 <- na.omit(MOOS.Q.2015) # Removed 34 rows - (126 to 144)
### examine the recursive digital filter at .9, .925, .95 levels ###
plot(FRCH$Q ~ FRCH$datetimeAK, type = "l", xlab = "", ylab = "Q (L/sec)",
xlim =  as.POSIXct(c("2015-05-01 00:00:00","2015-10-31 00:00:00"), tz="America/Anchorage"),
ylim = c(0, 3000), col="blue")
View(FRCH.2015)
View(frch.final.discharge.2015)
str(frch.final.discharge.2015)
head(frch.final.discharge.2015$datetimeAK)
head(FRCH.2015$datetimeAK)
Q.daily.2015 <- read.csv(here("processed_sensor_data", "2015", "Q.daily.2015.csv"))
Q.2015 <- read.csv(here("processed_sensor_data", "2015", "Predicted_Q_2015.csv"))
Q.2015 <- Q.2015[c("Site", "DateTimeAK", "Q")]
names(Q.2015) <- c("site.ID", "datetimeAK", "Q", "day") # renaming the column headers to match that of the chem file
############################ 2015 ################################################
# here #
Q.daily.2015 <- read.csv(here("processed_sensor_data", "2015", "Q.daily.2015.csv"))
Q.2015 <- read.csv(here("processed_sensor_data", "2015", "Predicted_Q_2015.csv"))
Q.2015 <- Q.2015[c("Site", "DateTimeAK", "Q")]
names(Q.2015) <- c("site.ID", "datetimeAK", "Q") # renaming the column headers to match that of the chem file
Q.2015$datetimeAK <- ymd_hms(Q.2015$datetimeAK) # converting character to datetime
Q.2015$datetimeAK <- force_tz(Q.2015$datetimeAK, "America/Anchorage") # converting character to datetime
Q.2015$site.ID <- ifelse(Q.2015$site.ID == "French", "FRCH", "MOOS")
chem.2015 <- read.csv(here("processed_sensor_data", "2015", "SUNA.EXO.int.corr.lab_2015.csv"), na.strings = "NA")
chem.2015 <- chem.2015[c("datetimeAK", "Site", "fDOM.QSU.adj.T.turb.int", "SpCond.uScm.adj",
"Turbidity.FNU.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
chem.2015$datetimeAK <- ymd_hms(chem.2015$datetimeAK) # converting character to datetime
chem.2015$datetimeAK <- force_tz(chem.2015$datetimeAK, "America/Anchorage") # converting character to datetime
names(chem.2015) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
### PLOTTING TO MAKE SURE OUR INPUT DATA LOOKS GOOD BEFORE DOING LITERALLY EVERYTHING ELSE ####
# pivot long to get all the response variables in one column
chem_2015_long <- chem.2015 %>%
filter(site.ID %in% c("FRCH", "MOOS")) %>%
pivot_longer(
cols = fDOM:ABS_254,
names_to = "response_var",
values_to = "concentration",
values_drop_na = TRUE
) # converting to a long format so each response_var is within a single column
ggplot(chem_2015_long, aes(x = datetimeAK, y = concentration, color = site.ID)) +
geom_point(size = 0.5) +
scale_color_manual(values=c("#FF7F00", "#A6761D")) +
facet_wrap(~response_var, scales = "free") +
theme_classic()
# subset data by site #
FRCH.2015 <-  subset(chem.2015, site.ID == "FRCH")
FRCH.2015 <- FRCH.2015[-c(12519:12849), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
MOOS.2015 <-  subset(chem.2015, site.ID == "MOOS")
MOOS.2015 <- MOOS.2015[-c(12540:12796), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
DOD.2015 <- rbind(FRCH.2015, MOOS.2015)
DOD.2015 <- full_join(DOD.2015, Q.2015) # merging chem and discharge data
frch.final.discharge.2015 <- subset(Q.2015, site.ID == "FRCH")
moos.final.discharge.2015 <- subset(Q.2015, site.ID == "MOOS")
Q.2015$day = format(as.POSIXct(Q.2015$datetimeAK,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q.2015$day = as.POSIXct(Q.2015$day, "%Y-%m-%d", tz="America/Anchorage")
Q.daily.2015 = with(Q.2015, tapply(Q, list(day, site.ID), mean))
Q.daily.2015 = as.data.frame(Q.daily.2015)
FRCH.Q.2015 = as.data.frame(Q.daily.2015$FRCH)
FRCH.Q.2015$day = as.Date(rownames(Q.daily.2015))
names(FRCH.Q.2015) = c("Discharge_Lsec", "day")
MOOS.Q.2015 = as.data.frame(Q.daily.2015$MOOS)
MOOS.Q.2015$day = as.Date(rownames(Q.daily.2015))
names(MOOS.Q.2015) = c("Discharge_Lsec", "day")
# join Q and chem data
# FRCH #
FRCH = full_join(frch.final.discharge.2015, FRCH.2015)
# MOOS #
MOOS = full_join(moos.final.discharge.2015, MOOS.2015)
any(is.na(FRCH.Q.2015$day))
any(is.na(FRCH.Q.2015$Discharge_Lsec))
any(is.na(MOOS.Q.2015$day))
any(is.na(MOOS.Q.2015$Discharge_Lsec))
MOOS.Q.2015 <- na.omit(MOOS.Q.2015) # Removed 3 rows - (126 to 123)
View(FRCH)
head(frch.final.discharge.2015$datetimeAK)
head(FRCH.2015$datetimeAK)
View(DOD.2015)
# join Q and chem data
# FRCH #
FRCH = full_join(FRCH.2015, frch.final.discharge.2015)
View(FRCH)
# MOOS #
MOOS = full_join(MOOS.2015, moos.final.discharge.2015)
range(FRCH$Q)
range(FRCH$Q, na.rm = TRUE)
### examine the recursive digital filter at .9, .925, .95 levels ###
plot(FRCH$Q ~ FRCH$datetimeAK, type = "l", xlab = "", ylab = "Q (L/sec)",
xlim =  as.POSIXct(c("2015-05-01 00:00:00","2015-10-31 00:00:00"), tz="America/Anchorage"),
ylim = c(0, 10000), col="blue")
### examine the recursive digital filter at .9, .925, .95 levels ###
plot(FRCH$Q ~ FRCH$datetimeAK, type = "l", xlab = "", ylab = "Q (L/sec)",
xlim =  as.POSIXct(c("2015-05-01 00:00:00","2015-10-31 00:00:00"), tz="America/Anchorage"),
ylim = c(0, 5000), col="blue")
### examine the recursive digital filter at .9, .925, .95 levels ###
plot(frch.final.discharge.2015$Q ~ frch.final.discharge.2015$datetimeAK, type = "l", xlab = "", ylab = "Q (L/sec)",
xlim =  as.POSIXct(c("2015-05-01 00:00:00","2015-10-31 00:00:00"), tz="America/Anchorage"),
ylim = c(0, 5000), col="blue")
View(frch.final.discharge.2015)
#
plot(moos.final.discharge.2015$Q ~ moos.final.discharge.2015$datetimeAK, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2015-05-01 00:00:00","2015-10-31 00:00:00"), tz="America/Anchorage"),
ylim = c(0,5000), col="blue")
# FRCH
frch.final.discharge.2015 <- na.omit(frch.final.discharge.2015) # Removed 2 rows
# FRCH
frch.final.discharge.2015 <- na.omit(frch.final.discharge.2015) # Removed 2 rows
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge.2015$Q)
install.packages("EcoHydRology")
FRCH.hyst.results.list = list(py$hysdict_FRCH_storm1_07_10_NO3,
py$hysdict_FRCH_storm1_07_10_fDOM,
py$hysdict_FRCH_storm1_07_10_SPC,
py$hysdict_FRCH_storm1_07_10_turb,
py$hysdict_FRCH_storm1_07_10_abs,
py$hysdict_FRCH_storm2_08_05_NO3,
py$hysdict_FRCH_storm2_08_05_fDOM,
py$hysdict_FRCH_storm2_08_05_SPC,
py$hysdict_FRCH_storm2_08_05_turb,
py$hysdict_FRCH_storm2_08_05_abs,
py$hysdict_FRCH_storm3_09_14_NO3,
py$hysdict_FRCH_storm3_09_14_fDOM,
py$hysdict_FRCH_storm3_09_14_SPC,
py$hysdict_FRCH_storm3_09_14_turb,
py$hysdict_FRCH_storm3_09_14_abs,
py$hysdict_FRCH_storm4_09_19_NO3,
py$hysdict_FRCH_storm4_09_19_fDOM,
py$hysdict_FRCH_storm4_09_19_SPC,
py$hysdict_FRCH_storm4_09_19_turb,
py$hysdict_FRCH_storm4_09_19_abs
)
FRCH.hyst.results.list.2 = list()
for (i in 1:length(FRCH.hyst.results.list)){
FRCH.hyst.results.list.2[[i]] = as.data.frame(t(as.numeric(c(
FRCH.hyst.results.list[[i]][["HI_mean_with_Interp"]],
FRCH.hyst.results.list[[i]][["HI_standard_deviation_with_Interp"]],
FRCH.hyst.results.list[[i]][["Normalized slope of response"]],
FRCH.hyst.results.list[[i]][["interpolated Max width of response"]],
FRCH.hyst.results.list[[i]][["Min response"]],
FRCH.hyst.results.list[[i]][["Max response"]],
FRCH.hyst.results.list[[i]][["Peak Q"]]
))))
names(FRCH.hyst.results.list.2[[i]]) = c("HI_mean_Interp", "HI_sd_with_Interp", "N.S.", "Max_width_Interp", "Min_response", "Max_response", "Peak_Q")
}
HIs.list = list()
HIs.tests = list()
for (i in 1:length(FRCH.hyst.results.list)){
HIs.list[[i]] = unlist(FRCH.hyst.results.list[[i]][["Hysteresis_Index"]],recursive=FALSE)
HIs.tests[[i]] = as.data.frame(t(round(as.numeric(c(shapiro.test(HIs.list[[i]])$statistic, shapiro.test(HIs.list[[i]])$p.value,
t.test(HIs.list[[i]], mu=0)$statistic, t.test(HIs.list[[i]], mu=0)$p.value,
t.test(HIs.list[[i]], mu=0)$conf.int[1],t.test(HIs.list[[i]], mu=0)$conf.int[2],
wilcox.test(HIs.list[[i]], mu=0)$statistic, wilcox.test(HIs.list[[i]], mu=0)$p.value)), 4)))
names(HIs.tests[[i]]) = c("ShapiroTest.W", "ShapiroTest.p", "t.test.stat", "t.test.p", "t.test.CIlow", "t.test.CIhigh",
"wilcox.test.stat", "wilcox.test.p")
}
FRCH.hyst.results.list.3 =list()
for (i in 1:length(FRCH.hyst.results.list)){
FRCH.hyst.results.list.3[[i]] = cbind(FRCH.hyst.results.list.2[[i]], HIs.tests[[i]])
}
FRCH.hyst.results.df = bind_rows(FRCH.hyst.results.list.3, .id = "column_label")
FRCH.hyst.results.df$storm.ID = c("FRCH_storm1_07_10_NO3",
"FRCH_storm1_07_10_fDOM",
"FRCH_storm1_07_10_SPC",
"FRCH_storm1_07_10_turb",
"FRCH_storm1_07_10_abs",
"FRCH_storm2_08_05_NO3",
"FRCH_storm2_08_05_fDOM",
"FRCH_storm2_08_05_SPC",
"FRCH_storm2_08_05_turb",
"FRCH_storm2_08_05_abs",
"FRCH_storm3_09_14_NO3",
"FRCH_storm3_09_14_fDOM",
"FRCH_storm3_09_14_SPC",
"FRCH_storm3_09_14_turb",
"FRCH_storm3_09_14_abs",
"FRCH_storm4_09_19_NO3",
"FRCH_storm4_09_19_fDOM",
"FRCH_storm4_09_19_SPC",
"FRCH_storm4_09_19_turb",
"FRCH_storm4_09_19_abs"
)
FRCH.hyst.results.df$site.ID = "FRCH"
write.csv(FRCH.hyst.results.df, "~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2022/FRCH/FRCH.hyst.results.csv")
# plot HI by normalized discharge
HIs.Q.list =list()
HIs.df.list = list()
#pdf("~/Documents/Storms/Output_from_analysis/HI_plots/2020/FRCH/FRCH.hyst.HI_Q.plots.pdf", width = 25, height =15, onefile=FALSE)
par(mfrow=c(4,7))
for (i in 1:length(HIs.list)) {
HIs.Q.list[[i]] = names(HIs.list[[i]])
HIs.Q.list[[i]] = (sapply(strsplit(HIs.Q.list[[i]], " "), "[[", 4))
HIs.Q.list[[i]] = as.numeric(gsub("%", "", HIs.Q.list[[i]]))
HIs.df.list[[i]] = as.data.frame(cbind(HIs.list[[i]], HIs.Q.list[[i]]))
HIs.df.list[[i]]= HIs.df.list[[i]][order(HIs.df.list[[i]][["V2"]]),]
plot(HIs.df.list[[i]][["V1"]] ~ HIs.df.list[[i]][["V2"]], type="l",
ylab="norm.response", xlab="Q intervals", main= FRCH.hyst.results.df$storm.ID[i])
abline(h=0, lty=2)
}
dev.off()
## plot HI with bootstrapped 95% CIs around the median ##
HIs.Q.list =list()
HIs.df.list = list()
par(mfrow=c(1,1))
for (i in 1:length(HIs.list)) {
HIs.Q.list[[i]] = names(HIs.list[[i]])
HIs.Q.list[[i]] = (sapply(strsplit(HIs.Q.list[[i]], " "), "[[", 4))
HIs.Q.list[[i]] = as.numeric(gsub("%", "", HIs.Q.list[[i]]))
HIs.df.list[[i]] = as.data.frame(cbind(HIs.list[[i]], HIs.Q.list[[i]]))
HIs.df.list[[i]]= HIs.df.list[[i]][order(HIs.df.list[[i]][["V2"]]),]
names(HIs.df.list[[i]]) = c("HI", "Q_interval")
}
FRCH.HI.df = bind_rows(HIs.df.list, .id = "column_label")
FRCH.HI.df$storm.ID = c(rep("FRCH_storm1_07_10_NO3", 50),
rep("FRCH_storm1_07_10_fDOM", 50),
rep("FRCH_storm1_07_10_SPC", 50),
rep("FRCH_storm1_07_10_turb", 50),
rep("FRCH_storm1_07_10_abs", 50),
rep("FRCH_storm2_08_05_NO3", 50),
rep("FRCH_storm2_08_05_fDOM", 50),
rep("FRCH_storm2_08_05_SPC", 50),
rep("FRCH_storm2_08_05_turb", 50),
rep("FRCH_storm2_08_05_abs", 50),
rep("FRCH_storm3_09_14_NO3", 50),
rep("FRCH_storm3_09_14_fDOM", 50),
rep("FRCH_storm3_09_14_SPC", 50),
rep("FRCH_storm3_09_14_turb", 50),
rep("FRCH_storm3_09_14_abs", 50),
rep("FRCH_storm4_09_19_NO3", 50),
rep("FRCH_storm4_09_19_fDOM", 50),
rep("FRCH_storm4_09_19_SPC", 50),
rep("FRCH_storm4_09_19_turb", 50),
rep("FRCH_storm4_09_19_abs", 50))
FRCH.HI.df$storm.ID = as.factor(FRCH.HI.df$storm.ID)
FRCH.HI.df = separate(data=FRCH.HI.df, col=storm.ID, into=c("site.ID","storm.num", "month", "day", "response"), sep = "_", remove = F)
par(mfrow=c(1,1))
median_cl_boot <- function(x, conf = 0.95) {
lconf <- (1 - conf)/2
uconf <- 1 - lconf
require(boot)
bmedian <- function(x, ind) median(x[ind])
bt <- boot(x, bmedian, 10000)
bb <- boot.ci(bt, conf = 0.95, type = "perc")
data.frame(y = median(x), ymin = quantile(bt$t, lconf), ymax = quantile(bt$t,
uconf))
}
g0 <- ggplot(FRCH.HI.df, aes(x = storm.num, y = HI, label=storm.num, fill=response))
g1 = g0 + geom_jitter(width = 0.1, fill = "grey", colour = "#0571B0", alpha=0.25, size=3) +
theme(axis.text.x = element_text(angle = 0))+  labs(x="") + facet_wrap(~ response, scales = "free_x") +
theme_bw() +geom_hline(yintercept=0) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "none")
g2 <- g1 +
stat_summary(fun.data = median_cl_boot, geom = "errorbar",
colour = "black", width = 0.2, size=1) +
stat_summary(fun.y = median, geom = "point",
colour = "black", size = 3)
ggsave("~/Documents/Storms_clean_repo/plots/HI_plots/2022/FRCH/FRCH.HI.median.boot.pdf", plot=g2, width = 8, height = 6, units ="in")
write.csv(FRCH.HI.df, "~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2022/FRCH/FRCH.HI.df.csv")
FRCH.HI.df$date <- as.Date(with(FRCH.HI.df, paste(month, day, sep = "-")), "%m-%d")
FRCH.HI.df$doy <- yday(FRCH.HI.df$date)
g0 <- ggplot(FRCH.HI.df, aes(x = doy, y = HI, label=doy, fill=response))
g1 = g0 + geom_jitter(width = 0.1, fill = "grey", colour = "#0571B0", alpha=0.25, size=3) +
theme(axis.text.x = element_text(angle = 0))+  labs(x="") + facet_wrap(~ response, scales = "free_x") +
theme_bw() +geom_hline(yintercept=0) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "none")
g2 <- g1 +
stat_summary(fun.data = median_cl_boot, geom = "errorbar",
colour = "black", width = 0.2, size=1) +
stat_summary(fun.y = median, geom = "point",
colour = "black", size = 3)
ggsave("~/Documents/Storms_clean_repo/plots/HI_plots/2022/FRCH/FRCH.HI.median.boot.doy.pdf", plot=g2, width = 8, height = 6, units ="in")
write.csv(FRCH.HI.df, "~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2022/FRCH/FRCH.HI.df.doy.csv")
reticulate::repl_python()
