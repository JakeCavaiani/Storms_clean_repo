mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
MOOS_turb_storm_ascending <- filter(MOOS_turb_storm, limb == "ascending")
MOOS_turb_storm_ascending <- MOOS_turb_storm_ascending[is.finite(MOOS_turb_storm_ascending$Q.norm) & is.finite(MOOS_turb_storm_ascending$turb.norm), ]
beta.all.turb.moos.with.all <- MOOS_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# POKE #
POKE_turb_storm$storm.ID = c(rep("storm1", 95),
rep("storm10", 99),
rep("storm11", 199),
rep("storm12", 307),
rep("storm13", 87),
rep("storm14", 383),
rep("storm15", 335),
rep("storm16", 95),
rep("storm17", 119),
rep("storm18", 95),
rep("storm19", 135),
rep("storm20", 87),
rep("storm21", 139),
rep("storm22a", 219),
rep("storm2", 107),
rep("storm3", 120),
rep("storm4a", 98),
rep("storm4b", 95),
rep("storm4c", 159),
rep("storm5", 219),
rep("storm6", 95),
rep("storm7", 127),
rep("storm8", 135),
rep("storm9", 265))
# POKE #
POKE_turb_storm$storm.ID = c(rep("storm1", 95),
rep("storm10", 99),
rep("storm11", 199),
rep("storm12", 307),
rep("storm13", 87),
rep("storm14", 383),
rep("storm15", 335),
rep("storm16", 95),
rep("storm17", 119),
rep("storm18", 95),
rep("storm19", 135),
rep("storm20", 87),
rep("storm21", 139),
rep("storm22a", 219),
rep("storm22b", 208),
rep("storm2", 107),
rep("storm3", 120),
rep("storm4a", 98),
rep("storm4b", 95),
rep("storm4c", 159),
rep("storm5", 219),
rep("storm6", 95),
rep("storm7", 127),
rep("storm8", 135),
rep("storm9", 265))
names(POKE_turb_storm) <- c("DateTime", "Q", "Q.norm", "turb", "turb.norm", "storm.ID")
POKE_turb_storm$site.ID <- "POKE"
POKE_turb_storm[cols] <- log(POKE_turb_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
POKE_turb_storm <- POKE_turb_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
POKE_turb_storm_ascending <- filter(POKE_turb_storm, limb == "ascending")
POKE_turb_storm_ascending <- POKE_turb_storm_ascending[is.finite(POKE_turb_storm_ascending$Q.norm) & is.finite(POKE_turb_storm_ascending$turb.norm), ]
beta.all.turb.moos.with.all <- POKE_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# STRT #
STRT_turb_storm$storm.ID = c(rep("storm10", 247),
rep("storm1a", 108),
rep("storm1b", 162),
rep("storm1c", 106),
rep("storm1d", 87),
rep("storm1e", 445),
rep("storm2", 167),
rep("storm3", 387),
rep("storm4a", 141),
rep("storm4b", 323),
rep("storm5", 239),
rep("storm6", 123),
rep("storm7a", 99),
rep("storm7b", 96),
rep("storm8", 83),
rep("storm9a", 295),
rep("storm9b", 135),
rep("storm9c", 483))
names(STRT_turb_storm) <- c("DateTime", "Q", "Q.norm", "turb", "turb.norm", "storm.ID")
STRT_turb_storm$site.ID <- "STRT"
STRT_turb_storm[cols] <- log(STRT_turb_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
STRT_turb_storm <- STRT_turb_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
STRT_turb_storm_ascending <- filter(STRT_turb_storm, limb == "ascending")
STRT_turb_storm_ascending <- STRT_turb_storm_ascending[is.finite(STRT_turb_storm_ascending$Q.norm) & is.finite(STRT_turb_storm_ascending$turb.norm), ]
beta.all.turb.strt <- STRT_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# VAUL #
VAUL_turb_storm$storm.ID = c(rep("storm10", 195),
rep("stor11", 400),
rep("storm12", 171),
rep("storm13", 319),
rep("storm14", 211),
rep("storm1a", 111),
rep("storm1b", 234),
rep("storm1c", 406),
rep("storm2", 182),
rep("storm3", 310),
rep("storm4", 318),
rep("storm5", 198),
rep("storm6a", 107),
rep("storm6b", 511),
rep("storm7", 284),
rep("storm8", 91),
rep("storm9", 95))
names(VAUL_turb_storm) <- c("DateTime", "Q", "Q.norm", "turb", "turb.norm", "storm.ID")
VAUL_turb_storm$site.ID <- "VAUL"
VAUL_turb_storm[cols] <- log(VAUL_turb_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
VAUL_turb_storm <- VAUL_turb_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
VAUL_turb_storm_ascending <- filter(VAUL_turb_storm, limb == "ascending")
VAUL_turb_storm_ascending <- VAUL_turb_storm_ascending[is.finite(VAUL_turb_storm_ascending$Q.norm) & is.finite(VAUL_turb_storm_ascending$turb.norm), ]
beta.all.turb.vaul <- VAUL_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# CARI #
CARI_turb_storm$storm.ID = c(rep("storm1", 0),
rep("storm2a", 103),
rep("storm2b", 95),
rep("storm2c", 155),
rep("storm3", 262),
rep("storm4", 155),
rep("storm5", 219),
rep("storm6", 183),
rep("storm7", 307),
rep("storm8a", 111),
rep("storm8b", 473),
rep("storm9", 99))
names(CARI_turb_storm) <- c("DateTime", "Q", "Q.norm", "turb", "turb.norm", "storm.ID")
CARI_turb_storm$site.ID <- "CARI"
CARI_turb_storm[cols] <- log(CARI_turb_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
CARI_turb_storm <- CARI_turb_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
CARI_turb_storm_ascending <- filter(CARI_turb_storm, limb == "ascending")
CARI_turb_storm_ascending <- CARI_turb_storm_ascending[is.finite(CARI_turb_storm_ascending$Q.norm) & is.finite(CARI_turb_storm_ascending$turb.norm), ]
beta.all.turb.cari <- CARI_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# ALL #
FRCH_turb_storm_ascending$DateTime <- as.POSIXct(FRCH_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS_turb_storm_ascending$DateTime <- as.POSIXct(MOOS_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT_turb_storm_ascending$DateTime <- as.POSIXct(STRT_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL_turb_storm_ascending$DateTime <- as.POSIXct(VAUL_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
CARI_turb_storm_ascending$DateTime <- as.POSIXct(CARI_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE_turb_storm_ascending$DateTime <- as.POSIXct(POKE_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
All_turb_storm<- rbind(FRCH_turb_storm_ascending, MOOS_turb_storm_ascending,
POKE_turb_storm_ascending, VAUL_turb_storm_ascending,
STRT_turb_storm_ascending, CARI_turb_storm_ascending )
beta.all.turb <- All_turb_storm %>% group_by(storm.ID, site.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
beta.all.turb$response_var <- "turb"
all.2020.ci.turb <- All_turb_storm %>%
group_by(site.ID, storm.ID) %>%
group_modify(~ parameters::model_parameters(stats::lm(turb.norm ~ Q.norm, data = .x)))
all.2020.ci.turb$response_var <- "turb"
beta.all.2020 <- rbind(all.2020.ci.no3, all.2020.ci.fDOM,
all.2020.ci.SPC, all.2020.ci.turb)
write.csv(beta.all.2020, "~/Documents/Storms_clean_repo/Output_from_analysis/06_BETA/beta.2020.csv")
beta.all.2020 <- beta.all.2020 %>%
filter(Parameter != "(Intercept)")
median_cl_boot <- function(x, conf = 0.95) {
lconf <- (1 - conf)/2
uconf <- 1 - lconf
require(boot)
bmedian <- function(x, ind) median(x[ind])
bt <- boot(x, bmedian, 10000)
bb <- boot.ci(bt, conf = 0.95, type = "perc")
data.frame(y = median(x), ymin = quantile(bt$t, lconf), ymax = quantile(bt$t,
uconf))
}
# FRCH #
FRCH.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/FRCH/FRCH.HI.df.csv")
storm.list = unique(FRCH.HI.df$storm.ID)
FRCH.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(FRCH.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
FRCH.HI.boot$storm.ID = storm.list
# MOOS #
MOOS.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/MOOS/MOOS.HI.df.csv")
storm.list = unique(MOOS.HI.df$storm.ID)
MOOS.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(MOOS.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
MOOS.HI.boot$storm.ID = storm.list
# CARI #
CARI.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/CARI/CARI.HI.df.csv")
storm.list = unique(CARI.HI.df$storm.ID)
CARI.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(CARI.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
CARI.HI.boot$storm.ID = storm.list
# POKE #
POKE.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/POKE/POKE.HI.df.csv")
storm.list = unique(POKE.HI.df$storm.ID)
POKE.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(POKE.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
POKE.HI.boot$storm.ID = storm.list
# VAUL #
VAUL.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/VAUL/VAUL.HI.df.csv")
storm.list = unique(VAUL.HI.df$storm.ID)
VAUL.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(VAUL.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
VAUL.HI.boot$storm.ID = storm.list
# STRT #
STRT.HI.df <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/STRT/STRT.HI.df.csv")
storm.list = unique(STRT.HI.df$storm.ID)
STRT.HI.boot <- do.call(rbind.data.frame,
lapply(storm.list, function(i){
dat = subset(STRT.HI.df, storm.ID == i)
median_cl_boot(dat$HI)
}))
STRT.HI.boot$storm.ID = storm.list
FRCH.HI.boot$site.ID = "FRCH"
MOOS.HI.boot$site.ID = "MOOS"
CARI.HI.boot$site.ID = "CARI"
POKE.HI.boot$site.ID = "POKE"
VAUL.HI.boot$site.ID = "VAUL"
STRT.HI.boot$site.ID = "STRT"
HI = rbind(FRCH.HI.boot, MOOS.HI.boot, CARI.HI.boot,
POKE.HI.boot, VAUL.HI.boot, STRT.HI.boot)
all.FI.diff.results = read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/05_FI/all.FI.diff.results_2020.csv", header = T, row.names = 1)
FI = subset(all.FI.diff.results, select=c("Flushing_index", "percCI_2.5", "percCI_97.5", "ID"))
FI$ID = as.character(FI$ID)
FI = separate(FI, ID, into=c("site.ID", "storm.ID", "month", "day", "response_var", NA), sep = "_")
names(FI) = c("Flush_index", "FI_ymin", "FI_ymax","site.ID", "storm.ID", "month", "day", "response_var")
HI$site.ID=NULL
HI = separate(HI, storm.ID, into=c("site.ID", "storm.ID", "month", "day", "response_var"), sep = "_")
names(HI) = c("Hyst_index", "HI_ymin", "HI_ymax","site.ID", "storm.ID", "month", "day", "response_var")
HI_FI = left_join(HI, FI, by=c("site.ID", "storm.ID", "response_var"))
HI_FI$year <- "2020"
write.csv(HI_FI, "~/Documents/Storms_clean_repo/Output_from_analysis/07_Combine_HI_BETA_FI/HI_FI.diff_results.2020.csv")
### BETA ####
beta_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/06_BETA/beta.2020.csv")
beta_2020$year <- "2020"
beta_2020 <- beta_2020 %>%
filter(Parameter != "(Intercept)")
names(beta_2020) = c("X1", "site.ID", "storm.ID","Parameter",
"Beta_index", "SE", "CI", "Beta_ymin",
"Beta_ymax", "t", "df", "p", "response_var",
"year")
### ANTECEDENT ####
antecedent_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/04_Antecedent_Conditions/2020/HI.2020.csv")
antecedent_2020 <- antecedent_2020[,-c(1)]
names(antecedent_2020)[names(antecedent_2020) == "storm.num"] <- "storm.ID"
names(antecedent_2020)[names(antecedent_2020) == "response"] <- "response_var"
antecedent_2020$year <- as.character(antecedent_2020$year)
HI_FI = left_join(HI_FI, beta_2020, by=c("site.ID", "storm.ID", "response_var", "year"))
HI_FI <- left_join(HI_FI, antecedent_2020, by = c("site.ID", "storm.ID", "response_var", "year"))
write.csv(HI_FI, "~/Documents/Storms_clean_repo/Output_from_analysis/07_Combine_HI_BETA_FI/antecedent_HI_FI_2020.csv")
#2019
AMC_2019 <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/07_Combine_HI_BETA_FI/antecedent_HI_FI_2019.csv")
antecedent_HI_FI_1_0 <- read_csv("~/Documents/Storms/Output_from_analysis/06_HI_fire_permafrost_script/antecedent_HI_FI_1.0.csv") # read in data
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
antecedent_HI_FI_1_0 <- read_csv("~/Documents/Storms/Output_from_analysis/06_HI_fire_permafrost_script/antecedent_HI_FI_1.0.csv") # read in data
antecedent_HI_FI_1_0 <- antecedent_HI_FI_1_0[,-c(1:2,14:15,17,19)] # cleaning up columns that are unnecessary
colNames <- c("Hyst_index", "HI_ymin", "HI_ymax", "site.ID", "storm.ID", "month", "day", "response_var", "Flush_index", "FI_ymin", "FI_ymax", "year", "beta", "StormPrecip", "StormTemp", "PrecipWeek", "PrecipMonth", "ThreeMonth", "TempWeek", "Duration", "Intensity", "doy", "burn", "pf", "date", "TimeSinceChena")
names(antecedent_HI_FI_1_0)<- colNames # renaming columns
rm(antecedent_HI_FI_1_0)
antecedent_HI_FI_1_0 <- read_csv("~/Documents/Storms/Output_from_analysis/06_HI_fire_permafrost_script/antecedent_HI_FI_1.0.csv") # read in data
names(antecedent_HI_FI_1_0)
antecedent_HI_FI_1_0 <- antecedent_HI_FI_1_0[,-c(1:2,14:15,17,18,20,21,24:26,37)] # cleaning up columns that are unnecessary
names(antecedent_HI_FI_1_0)
colNames
colNames <- c("Hyst_index", "HI_ymin", "HI_ymax", "site.ID", "storm.ID", "month", "day",
"response_var", "Flush_index", "FI_ymin", "FI_ymax", "year", "Beta_index",
"Beta_ymin", "Beta_ymax","HI", "StormPrecip", "StormTemp", "PrecipWeek",
"PrecipMonth", "ThreeMonth", "TempWeek", "Duration", "Intensity", "doy",
"burn", "pf", "date", "TimeSinceChena")
names(antecedent_HI_FI_1_0)<- colNames # renaming columns
names(antecedent_HI_FI_1_0)
View(antecedent_HI_FI_1_0)
colNames <- c("Hyst_index", "HI_ymin", "HI_ymax", "site.ID", "storm.ID", "month", "day",
"response_var", "Flush_index", "FI_ymin", "FI_ymax", "year", "Beta_index",
"Beta_ymin", "Beta_ymax","HI", "StormPrecip", "StormTemp", "PrecipWeek",
"PrecipMonth", "ThreeMonth", "TempWeek", "Duration", "Intensity", "doy",
"burn", "pf", "TimeSinceChena")
names(antecedent_HI_FI_1_0)<- colNames # renaming columns
View(AMC_2019)
### if then statement test ###
AMC_2019$TOTAL.TIME <- ifelse(AMC_2019$storm.ID %in% c('storm2'), 68.75, AMC_2019$TOTAL.TIME)
rm(AMC_2019)
#2019
AMC_2019 <- read.csv("~/Documents/Storms_clean_repo/Output_from_analysis/07_Combine_HI_BETA_FI/antecedent_HI_FI_2019.csv")
?filter
### if then statement test ###
AMC_2019$TOTAL.TIME <- AMC_2019 %>% filter(AMC_2019, site.ID  == "STRT") %>%
ifelse(AMC_2019$storm.ID %in% c('storm2'), 68.75, AMC_2019$TOTAL.TIME)
### if then statement test ###
AMC_2019$TOTAL.TIME <- AMC_2019 %>% filter(AMC_2019, AMC_2019$site.ID  == "STRT") %>%
ifelse(AMC_2019$storm.ID %in% c('storm2'), 68.75, AMC_2019$TOTAL.TIME)
AMC_2019$TOTAL.TIME <- ifelse(AMC_2019$site.ID == "STRT",
ifelse(AMC_2019$storm.ID == "storm2", 68.75))
AMC_2019$TOTAL.TIME <- ifelse(AMC_2019$site.ID == "STRT",
ifelse(AMC_2019$storm.ID == "storm2", 68.75, AMC_2019$TOTAL.TIME))
AMC_2019$TOTAL.TIME <- ifelse(AMC_2019$site.ID == "STRT" & AMC_2019$storm.ID == "storm2",
68.75, AMC_2019$TOTAL.TIME)
setwd("~/Documents/Storms_clean_repo")
# Import data #
FRCH_HI_doy_df_2018 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2018/FRCH/FRCH.HI.df.doy.csv")
MOOS_HI_doy_df_2018 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2018/MOOS/MOOS.HI.df.doy.csv")
CARI_HI_doy_df_2018 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2018/CARI/CARI.HI.df.doy.csv")
CARI_HI_doy_df_2018 <- CARI_HI_doy_df_2018[,-2]
FRCH_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/FRCH/FRCH.HI.df.doy.csv")
MOOS_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/MOOS/MOOS.HI.df.doy.csv")
POKE_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/POKE/POKE.HI.df.doy.csv")
STRT_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/STRT/STRT.HI.df.doy.csv")
VAUL_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/VAUL/VAUL.HI.df.doy.csv")
CARI_HI_doy_df_2019 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2019/CARI/CARI.HI.df.doy.csv")
STRT_HI_doy_df_2019[c(1701:1900), 7] <- "storm7c"
FRCH_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/FRCH/FRCH.HI.df.doy.csv")
MOOS_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/MOOS/MOOS.HI.df.doy.csv")
POKE_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/POKE/POKE.HI.df.doy.csv")
STRT_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/STRT/STRT.HI.df.doy.csv")
VAUL_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/VAUL/VAUL.HI.df.doy.csv")
CARI_HI_doy_df_2020 <- read_csv("~/Documents/Storms_clean_repo/Output_from_analysis/03_HI_FI/2020/CARI/CARI.HI.df.doy.csv")
HI.dat_2018 <- rbind(FRCH_HI_doy_df_2018, MOOS_HI_doy_df_2018, CARI_HI_doy_df_2018)
HI.dat_2018$year <- "2018"
HI.dat_2019 <- rbind(FRCH_HI_doy_df_2019, MOOS_HI_doy_df_2019, POKE_HI_doy_df_2019,
STRT_HI_doy_df_2019, VAUL_HI_doy_df_2019, CARI_HI_doy_df_2019)
HI.dat_2019$year <- "2019"
HI.dat_2020 <- rbind(FRCH_HI_doy_df_2020, MOOS_HI_doy_df_2020, POKE_HI_doy_df_2020, STRT_HI_doy_df_2020, VAUL_HI_doy_df_2020, CARI_HI_doy_df_2020)
HI.dat_2020$year <- "2020"
HI.dat <- rbind(HI.dat_2018, HI.dat_2019, HI.dat_2020)
#write.csv(HI.dat, "~/Documents/Storms_clean_repo/Output_from_analysis/04_Antecedent_Conditions/HI.dat.csv")
#HI.dat <- read_csv("~/Documents/Storms/Output_from_analysis/HI.dat.csv")
HI.mean<- HI.dat %>% group_by(site.ID, response, year) %>%
summarise_at(vars(HI), list(HI = median)) # takes the median by site response and year
# merged #
# By site and response
FRCH.fDOM <- subset(HI.mean, site.ID == "FRCH" & response == "fDOM")
POKE.fDOM <- subset(HI.mean, site.ID == "POKE" & response == "fDOM")
MOOS.fDOM <- subset(HI.mean, site.ID == "MOOS" & response == "fDOM")
STRT.fDOM <- subset(HI.mean, site.ID == "STRT" & response == "fDOM")
VAUL.fDOM <- subset(HI.mean, site.ID == "VAUL" & response == "fDOM")
CARI.fDOM <- subset(HI.mean, site.ID == "CARI" & response == "fDOM")
FRCH.NO3 <- subset(HI.mean, site.ID == "FRCH" & response == "NO3")
POKE.NO3 <- subset(HI.mean, site.ID == "POKE" & response == "NO3")
MOOS.NO3 <- subset(HI.mean, site.ID == "MOOS" & response == "NO3")
STRT.NO3 <- subset(HI.mean, site.ID == "STRT" & response == "NO3")
VAUL.NO3 <- subset(HI.mean, site.ID == "VAUL" & response == "NO3")
CARI.NO3 <- subset(HI.mean, site.ID == "CARI" & response == "NO3")
FRCH.fDOM$burn <- "unburned"
POKE.fDOM$burn <- "burned"
MOOS.fDOM$burn <- "burned"
STRT.fDOM$burn <- "burned"
VAUL.fDOM$burn <- "unburned"
CARI.fDOM$burn <- "burned"
FRCH.NO3$burn <- "unburned"
POKE.NO3$burn <- "burned"
MOOS.NO3$burn <- "burned"
STRT.NO3$burn <- "burned"
VAUL.NO3$burn <- "unburned"
CARI.NO3$burn <- "burned"
fdom.hi <- rbind(FRCH.fDOM, POKE.fDOM, MOOS.fDOM, STRT.fDOM, VAUL.fDOM, CARI.fDOM)
no3.hi <- rbind(FRCH.NO3, POKE.NO3, MOOS.NO3, STRT.NO3, VAUL.NO3, CARI.NO3)
fdom.hi$year <- as.character(fdom.hi$year)
no3.hi$year <- as.character(no3.hi$year)
fdom.lm <- lm(fdom.hi$HI ~ fdom.hi$burn)
no3.lm <- lm(no3.hi$HI ~ no3.hi$burn)
fdom.hi %>%
ggplot(aes(x=burn,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("DOC") +
xlab("Catchment burned (%)") +
ylab("HI-Solute Storage")
no3.hi %>%
ggplot(aes(x=burn,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("NO3") +
xlab("Catchment burned (%)") +
ylab("HI-Solute Storage")
# Permafrost #
FRCH.fDOM$pf <- "Moderate"
POKE.fDOM$pf <- "Moderate"
MOOS.fDOM$pf <- "Moderate"
STRT.fDOM$pf <- "High"
VAUL.fDOM$pf <- "High"
CARI.fDOM$pf <- "Moderate"
FRCH.NO3$pf <- "Moderate"
POKE.NO3$pf <- "Moderate"
MOOS.NO3$pf <- "Moderate"
STRT.NO3$pf <- "High"
VAUL.NO3$pf <- "High"
CARI.NO3$pf <- "Moderate"
pf.fdom.hi <- rbind(FRCH.fDOM, POKE.fDOM, MOOS.fDOM, STRT.fDOM, VAUL.fDOM, CARI.fDOM)
pf.no3.hi <- rbind(FRCH.NO3, POKE.NO3, MOOS.NO3, STRT.NO3, VAUL.NO3, CARI.NO3)
pf.fdom.hi$year <- as.character(pf.fdom.hi$year)
pf.no3.hi$year <- as.character(pf.no3.hi$year)
pf.fdom.lm <- lm(pf.fdom.hi$HI ~ pf.fdom.hi$burn)
pf.no3.lm <- lm(pf.no3.hi$HI ~ pf.no3.hi$burn)
pf.fdom.hi %>%
ggplot(aes(x=pf,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("DOC") +
xlab("Permafrost Extent (%)") +
ylab("HI-Solute Storage")
pf.no3.hi %>%
ggplot(aes(x=pf,
y=HI,
color=year))+
geom_boxplot() +
geom_smooth(method = "lm") +
ylim(-1,1) +
ggtitle("NO3") +
xlab("Permafrost Extent (%)") +
ylab("HI-Solute Storage")
### H 1.1: HI against precip ###
HI.mean.precip <- HI.dat %>% group_by(site.ID, year, storm.num) %>%
summarise_at(vars(HI), list(HI = median)) # take mean by site response and year
HI.mean.precip.response <- HI.dat %>% group_by(site.ID, year, storm.num, response) %>%
summarise_at(vars(HI), list(HI = median)) # take mean by site response and year
setwd("~/Documents/Storms_clean_repo")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
Sys.which("python")
use_python("/usr/bin/python")
library(tidyverse)
options(tz="America/Anchorage")
library(ggplot2)
library(gridExtra)
library(boot)
reticulate::repl_python()
