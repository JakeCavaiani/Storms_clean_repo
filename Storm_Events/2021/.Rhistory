}
CARI_turb_storm <- CARI_turb_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
CARI_turb_storm_ascending <- filter(CARI_turb_storm, limb == "ascending")
CARI_turb_storm_ascending <- CARI_turb_storm_ascending[is.finite(CARI_turb_storm_ascending$Q.norm) & is.finite(CARI_turb_storm_ascending$turb.norm), ]
beta.all.turb.cari <- CARI_turb_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
# ALL #
FRCH_turb_storm_ascending$DateTime <- as.POSIXct(FRCH_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS_turb_storm_ascending$DateTime <- as.POSIXct(MOOS_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT_turb_storm_ascending$DateTime <- as.POSIXct(STRT_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL_turb_storm_ascending$DateTime <- as.POSIXct(VAUL_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
CARI_turb_storm_ascending$DateTime <- as.POSIXct(CARI_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE_turb_storm_ascending$DateTime <- as.POSIXct(POKE_turb_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
All_turb_storm <- rbind(FRCH_turb_storm_ascending, MOOS_turb_storm_ascending,
STRT_turb_storm_ascending, VAUL_turb_storm_ascending,
CARI_turb_storm_ascending, POKE_turb_storm_ascending)
beta.all.turb <- All_turb_storm %>% group_by(storm.ID, site.ID) %>%
summarize(beta = slope(Q.norm, turb.norm)) # this works just like the beta one that is for an individual site
beta.all.turb$response_var <- "turb"
all.2021.ci.turb <- All_turb_storm %>%
group_by(site.ID, storm.ID) %>%
group_modify(~ parameters::model_parameters(stats::lm(turb.norm ~ Q.norm, data = .x)))
all.2021.ci.turb$response_var <- "turb"
##### ABS #####
FRCH_abs_storm <- map2_df(FRCH_Q_storm_list_beta, FRCH_abs_storm_list_beta, inner_join, by = "valuedatetime")
MOOS_abs_storm <- map2_df(MOOS_Q_storm_list_beta, MOOS_abs_storm_list_beta, inner_join, by = "valuedatetime")
POKE_abs_storm <- map2_df(POKE_Q_storm_list_beta, POKE_abs_storm_list_beta, inner_join, by = "valuedatetime")
STRT_abs_storm <- map2_df(STRT_Q_storm_list_beta, STRT_abs_storm_list_beta, inner_join, by = "valuedatetime")
VAUL_abs_storm <- map2_df(VAUL_Q_storm_list_beta, VAUL_abs_storm_list_beta, inner_join, by = "valuedatetime")
FRCH_abs_storm$storm.ID = c(rep("storm2", 303),
rep("storm3", 207),
rep("storm4", 223),
rep("storm5a", 443),
rep("storm6a", 423),
rep("storm7", 139),
rep("storm8", 467))
names(FRCH_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
FRCH_abs_storm$site.ID <- "FRCH"
cols <- c("abs.norm","Q.norm")
FRCH_abs_storm[cols] <- log(FRCH_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
FRCH_abs_storm <- FRCH_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
FRCH_abs_storm_ascending <- filter(FRCH_abs_storm, limb == "ascending")
FRCH_abs_storm_ascending <- FRCH_abs_storm_ascending[is.finite(FRCH_abs_storm_ascending$Q.norm) & is.finite(FRCH_abs_storm_ascending$abs.norm), ]
beta.all.abs <- FRCH_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# MOOS #
MOOS_abs_storm$storm.ID = c(rep("storm1", 191),
rep("storm2", 251),
rep("storm3a", 115),
rep("storm3b", 359),
rep("storm4a", 415),
rep("storm5a", 315),
rep("storm6", 127),
rep("storm7", 259))
names(MOOS_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
MOOS_abs_storm$site.ID <- "MOOS"
MOOS_abs_storm[cols] <- log(MOOS_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
MOOS_abs_storm <- MOOS_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
MOOS_abs_storm_ascending <- filter(MOOS_abs_storm, limb == "ascending")
MOOS_abs_storm_ascending <- MOOS_abs_storm_ascending[is.finite(MOOS_abs_storm_ascending$Q.norm) & is.finite(MOOS_abs_storm_ascending$abs.norm), ]
beta.all.abs.moos.with.all <- MOOS_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# POKE #
POKE_abs_storm$storm.ID = c(rep("storm1", 235),
rep("storm2", 191),
rep("storm3", 167),
rep("storm4", 191),
rep("storm5", 367),
rep("storm6", 159),
rep("storm7a", 451),
rep("storm7b", 263),
rep("storm7d", 147))
names(POKE_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
POKE_abs_storm$site.ID <- "POKE"
POKE_abs_storm[cols] <- log(POKE_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
POKE_abs_storm <- POKE_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
POKE_abs_storm_ascending <- filter(POKE_abs_storm, limb == "ascending")
POKE_abs_storm_ascending <- POKE_abs_storm_ascending[is.finite(POKE_abs_storm_ascending$Q.norm) & is.finite(POKE_abs_storm_ascending$abs.norm), ]
beta.all.poke.moos.with.all <- POKE_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# STRT #
STRT_abs_storm$storm.ID = c(rep("storm1a", 447),
rep("storm2a", 307),
rep("storm3", 127))
names(STRT_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
STRT_abs_storm$site.ID <- "STRT"
STRT_abs_storm[cols] <- log(STRT_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
STRT_abs_storm <- STRT_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
STRT_abs_storm_ascending <- filter(STRT_abs_storm, limb == "ascending")
STRT_abs_storm_ascending <- STRT_abs_storm_ascending[is.finite(STRT_abs_storm_ascending$Q.norm) & is.finite(STRT_abs_storm_ascending$abs.norm), ]
beta.all.abs.strt <- STRT_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# VAUL #
VAUL_abs_storm$storm.ID = c(rep("storm1a", 375),
rep("storm1b", 267),
rep("storm3", 667),
rep("storm4a", 427),
rep("storm4b", 319),
rep("storm5a", 715))
names(VAUL_abs_storm) <- c("DateTime", "Q", "Q.norm", "abs", "abs.norm", "storm.ID")
VAUL_abs_storm$site.ID <- "VAUL"
VAUL_abs_storm[cols] <- log(VAUL_abs_storm[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
VAUL_abs_storm <- VAUL_abs_storm %>% group_by(storm.ID) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(Q.norm)], "ascending", "descending"))
VAUL_abs_storm_ascending <- filter(VAUL_abs_storm, limb == "ascending")
VAUL_abs_storm_ascending <- VAUL_abs_storm_ascending[is.finite(VAUL_abs_storm_ascending$Q.norm) & is.finite(VAUL_abs_storm_ascending$abs.norm), ]
beta.all.abs.vaul <- VAUL_abs_storm_ascending %>% group_by(storm.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
# ALL #
FRCH_abs_storm_ascending$DateTime <- as.POSIXct(FRCH_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS_abs_storm_ascending$DateTime <- as.POSIXct(MOOS_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT_abs_storm_ascending$DateTime <- as.POSIXct(STRT_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL_abs_storm_ascending$DateTime <- as.POSIXct(VAUL_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE_abs_storm_ascending$DateTime <- as.POSIXct(POKE_abs_storm_ascending$DateTime,
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
All_abs_storm <- rbind(FRCH_abs_storm_ascending, MOOS_abs_storm_ascending,
STRT_abs_storm_ascending, VAUL_abs_storm_ascending,
POKE_abs_storm_ascending)
beta.all.abs <- All_abs_storm %>% group_by(storm.ID, site.ID) %>%
summarize(beta = slope(Q.norm, abs.norm)) # this works just like the beta one that is for an individual site
beta.all.abs$response_var <- "abs"
all.2021.ci.abs <- All_abs_storm %>%
group_by(site.ID, storm.ID) %>%
group_modify(~ parameters::model_parameters(stats::lm(abs.norm ~ Q.norm, data = .x)))
all.2021.ci.abs$response_var <- "abs"
beta.all.2021 <- rbind(all.2021.ci.no3, all.2021.ci.fDOM,
all.2021.ci.SPC, all.2021.ci.turb,
all.2021.ci.abs)
write.csv(beta.all.2021, here("Output_from_analysis", "06_BETA", "beta.2021.csv"))
View(beta.all.2021)
library(xfun)
library(bit)
library(vctrs)
library(tidyverse)
library(lubridate)
library(scales)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
library(readr)
library(googledrive)
library(purrr)
library(here)
Q.daily.2022 <- read.csv(here("Q", "2022", "Q.daily.2022.csv"))
Q.2022 <- read.csv(here("Q", "2022", "Predicted_Q_2022.csv"))
names(Q.2022)[names(Q.2022) == 'DateTimeAK'] <- 'datetimeAK'
names(Q.2022)[names(Q.2022) == 'Site'] <- 'site.ID'
Q.2022$datetimeAK <- ymd_hms(Q.2022$datetimeAK) # converting character to datetime
Q.2022$datetimeAK <- force_tz(Q.2022$datetimeAK, "America/Anchorage") # it already is in AK time so I want to make it recognize it without changing the actually time value
chem.2022 <- read.csv(here("processed_sensor_data", "2022", "SUNA.EXO.int.corr.lab_2022.csv"))
chem.2022 <- chem.2022[c("datetimeAK", "site.ID", "fDOM.QSU.T.turb.col", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
chem.2022$datetimeAK <- ymd_hms(chem.2022$datetimeAK) # converting character to datetime
chem.2022$datetimeAK <- force_tz(chem.2022$datetimeAK, "America/Anchorage") # converting character to datetime
names(chem.2022) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
### PLOTTING TO MAKE SURE OUR INPUT DATA LOOKS GOOD BEFORE DOING LITERALLY EVERYTHING ELSE ####
# pivot long to get all the response variables in one column
chem.2022_long <- chem.2022 %>%
filter(site.ID %in% c("FRCH", "MOOS", "POKE", "VAUL", "STRT")) %>%
pivot_longer(
cols = fDOM:ABS_254,
names_to = "response_var",
values_to = "concentration",
values_drop_na = TRUE
) # converting to a long format so each response_var is within a single column
ggplot(chem.2022_long, aes(x = datetimeAK, y = concentration, color = site.ID)) +
geom_point(size = 0.5) +
scale_color_manual(values=c("#FF7F00", "#A6761D", "#6A3D9A", "#66C2A5", "#E7298A")) +
facet_wrap(~response_var, scales = "free") +
theme_classic()
FRCH.2022 <-  subset(chem.2022, site.ID == "FRCH")
FRCH.2022 <- FRCH.2022[-c(14573:14900), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
MOOS.2022 <-  subset(chem.2022, site.ID == "MOOS")
MOOS.2022 <- MOOS.2022[-c(14666:15037), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
POKE.2022 <-  subset(chem.2022, site.ID == "POKE")
POKE.2022 <- POKE.2022[-c(14481:14857), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
VAUL.2022 <-  subset(chem.2022, site.ID == "VAUL")
VAUL.2022 <- VAUL.2022[-c(14198:14548), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
STRT.2022 <-  subset(chem.2022, site.ID == "STRT")
STRT.2022 <- STRT.2022[-c(12278:12787), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
DOD.2022 <- rbind(FRCH.2022, MOOS.2022, POKE.2022,
VAUL.2022, STRT.2022)
DOD.2022 <- full_join(DOD.2022, Q.2022) # merging chem and discharge data
frch.final.discharge.2022 <- subset(Q.2022, site.ID == "FRCH")
strt.final.discharge.2022 <- subset(Q.2022, site.ID == "STRT")
poke.final.discharge.2022 <- subset(Q.2022, site.ID == "POKE")
vaul.final.discharge.2022 <- subset(Q.2022, site.ID == "VAUL")
moos.final.discharge.2022 <- subset(Q.2022, site.ID == "MOOS")
#
# # join Q and chem data
# # FRCH #
FRCH = full_join(frch.final.discharge.2022, FRCH.2022)
# MOOS #
MOOS = full_join(moos.final.discharge.2022, MOOS.2022)
# STRT #
STRT = full_join(strt.final.discharge.2022, STRT.2022)
# POKE #
POKE = full_join(poke.final.discharge.2022, POKE.2022)
# VAUL #
VAUL = full_join(vaul.final.discharge.2022, VAUL.2022)
View(MOOS.2022)
CPCRW <- read_csv(here("Climate", "Precip", "CPCRW.RainGauge.2022.final.csv"))
CPCRW$datetimeAK <- force_tz(CPCRW$datetimeAK, "America/Anchorage") # it already is in AK time so I want to make it recognize it without changing the actually time value
frch.precip.discharge <- full_join(frch.final.discharge.2022, CPCRW) # merging precip data and discharge
moos.precip.discharge <- full_join(moos.final.discharge.2022, CPCRW) # merging precip data and discharge
poke.precip.discharge <- full_join(poke.final.discharge.2022, CPCRW) # merging precip data and discharge
vaul.precip.discharge <- full_join(vaul.final.discharge.2022, CPCRW) # merging precip data and discharge
strt.precip.discharge <- full_join(strt.final.discharge.2022, CPCRW) # merging precip data and discharge
#cari.precip.discharge <- full_join(cari.final.discharge.2022, CPCRW) # merging precip data and discharge
frch.precip.discharge <- frch.precip.discharge[order(frch.precip.discharge$datetimeAK),]
moos.precip.discharge <- moos.precip.discharge[order(moos.precip.discharge$datetimeAK),]
poke.precip.discharge <- poke.precip.discharge[order(poke.precip.discharge$datetimeAK),]
vaul.precip.discharge <- vaul.precip.discharge[order(vaul.precip.discharge$datetimeAK),]
strt.precip.discharge <- strt.precip.discharge[order(strt.precip.discharge$datetimeAK),]
#cari.precip.discharge <- cari.precip.discharge[order(cari.precip.discharge$datetimeAK),]
# making a uniform time series with 30 minute intervals and then I can sum precip by 24/48hour windows
ts <- seq(as.POSIXct("2022-04-01", tz = "America/Anchorage"),
as.POSIXct("2022-11-01", tz = "America/Anchorage"),
by = "30 min")
head(ts)
ts <- as.data.frame(ts)
names(ts) <- c("datetimeAK")
frch.precip.discharge <- left_join(ts, frch.precip.discharge, by = "datetimeAK")
frch.precip.discharge$twentyfour <- rollapplyr(frch.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
frch.precip.discharge$fourtyeight <- rollapplyr(frch.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
moos.precip.discharge$twentyfour <- rollapplyr(moos.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
moos.precip.discharge$fourtyeight <- rollapplyr(moos.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$twentyfour <- rollapplyr(strt.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$fourtyeight <- rollapplyr(strt.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$twentyfour <- rollapplyr(vaul.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$fourtyeight <- rollapplyr(vaul.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$twentyfour <- rollapplyr(poke.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$fourtyeight <- rollapplyr(poke.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
#
# Greater than 5 #
frch.five.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
frch.five.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
moos.five.twenty.four <- moos.precip.discharge[which(moos.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
moos.five.fourty.eight <- moos.precip.discharge[which(moos.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
strt.five.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
strt.five.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
vaul.five.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
vaul.five.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
poke.five.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
poke.five.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
# Greater than 10 #
frch.ten.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
frch.ten.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
moos.ten.twenty.four <- moos.precip.discharge[which(moos.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
moos.ten.fourty.eight <- moos.precip.discharge[which(moos.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
strt.ten.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
strt.ten.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
vaul.ten.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
vaul.ten.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
poke.ten.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
poke.ten.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
# FRC
# FRCH
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(10,0),
axes=F, xlab="", ylab="")
axis(side = 4)
par(mfrow=c(1,1))
abline(v = as.POSIXct(frch.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(10,0),
axes=F, xlab="", ylab="")
par(new = T)
plot(frch.final.discharge.2022$Q ~ frch.final.discharge.2022$datetimeAK, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$NO3 * 20 ~ FRCH$datetimeAK, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$fDOM * 10 ~ FRCH$datetimeAK, type="l", xlab="", ylab="", col="brown",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$SPC * 10 ~ FRCH$datetimeAK, type="l", xlab="", ylab="", col="red",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$Turb * 60 ~ FRCH$datetimeAK, type="l", xlab="", ylab="", col="blue",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"))
# storm 1 #
plot(FRCH$Q ~ FRCH$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-07-01 00:00:00","2022-07-15 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 1200))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-07-01 00:00:00","2022-07-15 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(frch.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-07-10 16:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-07-12 23:30:00", tz="America/Anchorage"), col="purple")
FRCH_storm1_07_10 = FRCH[FRCH$datetimeAK > as.POSIXct("2022-07-10 16:30:00", tz="America/Anchorage") &
FRCH$datetimeAK < as.POSIXct("2022-07-12 23:30:00", tz="America/Anchorage"),]
plot(FRCH_storm1_07_10$Q ~ as.POSIXct(FRCH_storm1_07_10$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(0,1200), col="blue", main="FRCH 220710 storm 1",
xlim = as.POSIXct(c("2022-07-09 00:00:00","2022-07-13 23:45:00"), tz="America/Anchorage"))
par(new = T)
plot(FRCH$Q ~ FRCH$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-08-01 00:00:00","2022-08-15 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 1200))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-08-01 00:00:00","2022-08-15 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(frch.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-08-05 12:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-08-07 23:30:00", tz="America/Anchorage"), col="purple")
FRCH_storm2_08_05 = FRCH[FRCH$datetimeAK > as.POSIXct("2022-08-05 12:30:00", tz="America/Anchorage") &
FRCH$datetimeAK < as.POSIXct("2022-08-07 23:30:00", tz="America/Anchorage"),]
plot(FRCH_storm2_08_05$Q ~ as.POSIXct(FRCH_storm2_08_05$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(0,800), col="blue", main="FRCH 220805 storm 2",
xlim = as.POSIXct(c("2022-08-04 00:00:00","2022-08-08 23:45:00"), tz="America/Anchorage"))
plot(FRCH$Q ~ FRCH$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-09-01 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 600))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-09-01 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(frch.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-09-14 12:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-09-16 20:30:00", tz="America/Anchorage"), col="purple")
FRCH_storm3_09_14 = FRCH[FRCH$datetimeAK > as.POSIXct("2022-09-14 12:30:00", tz="America/Anchorage") &
FRCH$datetimeAK < as.POSIXct("2022-09-16 20:30:00", tz="America/Anchorage"),]
plot(FRCH_storm3_09_14$Q ~ as.POSIXct(FRCH_storm3_09_14$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(0,600), col="blue", main="FRCH 220914 storm 3",
xlim = as.POSIXct(c("2022-09-14 00:00:00","2022-09-17 23:45:00"), tz="America/Anchorage"))
plot(FRCH$Q ~ FRCH$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-09-01 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 600))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-09-01 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(frch.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-09-19 15:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-09-21 09:30:00", tz="America/Anchorage"), col="purple")
FRCH_storm4_09_19 = FRCH[FRCH$datetimeAK > as.POSIXct("2022-09-19 15:30:00", tz="America/Anchorage") &
FRCH$datetimeAK < as.POSIXct("2022-09-21 09:30:00", tz="America/Anchorage"),]
plot(FRCH_storm4_09_19$Q ~ as.POSIXct(FRCH_storm4_09_19$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(0,600), col="blue", main="FRCH 220919 storm 4",
xlim = as.POSIXct(c("2022-09-18 00:00:00","2022-09-21 23:45:00"), tz="America/Anchorage"))
FRCH_storm1_07_10_Q = subset(FRCH_storm1_07_10, select = c("datetimeAK","Q"))
names(FRCH_storm1_07_10_Q) = c("valuedatetime","datavalue")
FRCH_storm1_07_10_NO3 = subset(FRCH_storm1_07_10, select = c("datetimeAK","NO3"))
names(FRCH_storm1_07_10_NO3) = c("valuedatetime","datavalue")
FRCH_storm1_07_10_fDOM = subset(FRCH_storm1_07_10, select = c("datetimeAK","fDOM"))
names(FRCH_storm1_07_10_fDOM) = c("valuedatetime","datavalue")
FRCH_storm1_07_10_SPC = subset(FRCH_storm1_07_10, select = c("datetimeAK","SPC"))
names(FRCH_storm1_07_10_SPC) = c("valuedatetime","datavalue")
FRCH_storm1_07_10_turb = subset(FRCH_storm1_07_10, select = c("datetimeAK","Turb"))
names(FRCH_storm1_07_10_turb) = c("valuedatetime","datavalue")
FRCH_storm1_07_10_abs = subset(FRCH_storm1_07_10, select = c("datetimeAK","ABS_254"))
names(FRCH_storm1_07_10_abs) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_Q = subset(FRCH_storm2_08_05, select = c("datetimeAK","Q"))
names(FRCH_storm2_08_05_Q) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_NO3 = subset(FRCH_storm2_08_05, select = c("datetimeAK","NO3"))
names(FRCH_storm2_08_05_NO3) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_fDOM = subset(FRCH_storm2_08_05, select = c("datetimeAK","fDOM"))
names(FRCH_storm2_08_05_fDOM) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_SPC = subset(FRCH_storm2_08_05, select = c("datetimeAK","SPC"))
names(FRCH_storm2_08_05_SPC) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_turb = subset(FRCH_storm2_08_05, select = c("datetimeAK","Turb"))
names(FRCH_storm2_08_05_turb) = c("valuedatetime","datavalue")
FRCH_storm2_08_05_abs = subset(FRCH_storm2_08_05, select = c("datetimeAK","ABS_254"))
names(FRCH_storm2_08_05_abs) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_Q = subset(FRCH_storm3_09_14, select = c("datetimeAK","Q"))
names(FRCH_storm3_09_14_Q) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_NO3 = subset(FRCH_storm3_09_14, select = c("datetimeAK","NO3"))
names(FRCH_storm3_09_14_NO3) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_fDOM = subset(FRCH_storm3_09_14, select = c("datetimeAK","fDOM"))
names(FRCH_storm3_09_14_fDOM) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_SPC = subset(FRCH_storm3_09_14, select = c("datetimeAK","SPC"))
names(FRCH_storm3_09_14_SPC) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_turb = subset(FRCH_storm3_09_14, select = c("datetimeAK","Turb"))
names(FRCH_storm3_09_14_turb) = c("valuedatetime","datavalue")
FRCH_storm3_09_14_abs = subset(FRCH_storm3_09_14, select = c("datetimeAK","ABS_254"))
names(FRCH_storm3_09_14_abs) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_Q = subset(FRCH_storm4_09_19, select = c("datetimeAK","Q"))
names(FRCH_storm4_09_19_Q) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_NO3 = subset(FRCH_storm4_09_19, select = c("datetimeAK","NO3"))
names(FRCH_storm4_09_19_NO3) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_fDOM = subset(FRCH_storm4_09_19, select = c("datetimeAK","fDOM"))
names(FRCH_storm4_09_19_fDOM) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_SPC = subset(FRCH_storm4_09_19, select = c("datetimeAK","SPC"))
names(FRCH_storm4_09_19_SPC) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_turb = subset(FRCH_storm4_09_19, select = c("datetimeAK","Turb"))
names(FRCH_storm4_09_19_turb) = c("valuedatetime","datavalue")
FRCH_storm4_09_19_abs = subset(FRCH_storm4_09_19, select = c("datetimeAK","ABS_254"))
names(FRCH_storm4_09_19_abs) = c("valuedatetime","datavalue")
write.csv(FRCH_storm1_07_10, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10.csv"))
write.csv(FRCH_storm1_07_10_Q, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_Q.csv"))
write.csv(FRCH_storm1_07_10_NO3, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_NO3.csv"))
write.csv(FRCH_storm1_07_10_fDOM, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_fDOM.csv"))
write.csv(FRCH_storm1_07_10_SPC, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_SPC.csv"))
write.csv(FRCH_storm1_07_10_turb, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_turb.csv"))
write.csv(FRCH_storm1_07_10_abs, here("Storm_Events", "2022", "FRCH", "FRCH_storm1_07_10_abs.csv"))
write.csv(FRCH_storm2_08_05, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05.csv"))
write.csv(FRCH_storm2_08_05_Q, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_Q.csv"))
write.csv(FRCH_storm2_08_05_NO3, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_NO3.csv"))
write.csv(FRCH_storm2_08_05_fDOM, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_fDOM.csv"))
write.csv(FRCH_storm2_08_05_SPC, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_SPC.csv"))
write.csv(FRCH_storm2_08_05_turb, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_turb.csv"))
write.csv(FRCH_storm2_08_05_abs, here("Storm_Events", "2022", "FRCH", "FRCH_storm2_08_05_abs.csv"))
write.csv(FRCH_storm3_09_14, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14.csv"))
write.csv(FRCH_storm3_09_14_Q, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_Q.csv"))
write.csv(FRCH_storm3_09_14_NO3, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_NO3.csv"))
write.csv(FRCH_storm3_09_14_fDOM, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_fDOM.csv"))
write.csv(FRCH_storm3_09_14_SPC, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_SPC.csv"))
write.csv(FRCH_storm3_09_14_turb, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_turb.csv"))
write.csv(FRCH_storm3_09_14_abs, here("Storm_Events", "2022", "FRCH", "FRCH_storm3_09_14_abs.csv"))
write.csv(FRCH_storm4_09_19, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19.csv"))
write.csv(FRCH_storm4_09_19_Q, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_Q.csv"))
write.csv(FRCH_storm4_09_19_NO3, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_NO3.csv"))
write.csv(FRCH_storm4_09_19_fDOM, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_fDOM.csv"))
write.csv(FRCH_storm4_09_19_SPC, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_SPC.csv"))
write.csv(FRCH_storm4_09_19_turb, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_turb.csv"))
write.csv(FRCH_storm4_09_19_abs, here("Storm_Events", "2022", "FRCH", "FRCH_storm4_09_19_abs.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(boot)
library(lubridate)
library(here)
Sys.which("python")
use_python("/usr/local/bin/python3")
options(tz="America/Anchorage")
# install pandas #
virtualenv_create("r-reticulate")
# RETICULATE_PYTHON = "lib/python3.8"
reticulate::py_config()
reticulate::py_install("pandas")
reticulate::repl_python()
