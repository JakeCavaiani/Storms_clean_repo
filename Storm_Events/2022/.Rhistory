DOD.2022 <- read.csv(here("processed_sensor_data", "2022", "SUNA.EXO.int.corr.lab_2022.csv"))
DOD.2022 <- DOD.2022[c("datetimeAK", "site.ID", "fDOM.QSU.T.turb.col", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
names(DOD.2022) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
# summing up week/month/threemonth antecedent precip
DOD.2022$datetimeAK <- ymd_hms(DOD.2022$datetimeAK) # converting character to datetime
DOD.2022$datetimeAK <- force_tz(DOD.2022$datetimeAK, "America/Anchorage") # converting character to datetime
DOD.2022 <- left_join(DOD.2022, CPCRW, by = "datetimeAK")
FRCH.2022 <- subset(DOD.2022, site.ID == "FRCH")
MOOS.2022 <- subset(DOD.2022, site.ID == "MOOS")
POKE.2022 <- subset(DOD.2022, site.ID == "POKE")
VAUL.2022 <- subset(DOD.2022, site.ID == "VAUL")
STRT.2022 <- subset(DOD.2022, site.ID == "STRT")
### STRT ####
STRTstorm_file_list <- list.files(path = "All_sites/",
recursive=F,
pattern="STRT",
full.names=TRUE)
STRT_storms<-do.call("rbind", lapply(STRTstorm_file_list,
read.csv,
check.names = FALSE,
stringsAsFactors=FALSE,
header=T, blank.lines.skip = TRUE, fill=TRUE))
STRT_storms$storm.num = c(rep("storm1", 103),
rep("storm2", 191),
rep("storm3", 107))
STRT_storms$datetimeAK <- as.POSIXct(STRT_storms$datetimeAK, tz = "America/Anchorage", format = "%Y-%m-%d %H:%M")
STRT.2022.storms.1<- left_join(STRT_storms, CPCRW, by = "datetimeAK")
STRT.2022.storms.1<- left_join(STRT.2022.storms.1, airtempmean, by = "datetimeAK")
names(STRT.2022.storms.1)[names(STRT.2022.storms.1) == ''] <- 'x'
STRT.2022.per.storm.1 <- STRT.2022.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(mean), list(precip = sum), na.rm = TRUE)
temp <- STRT.2022.storms.1 %>% group_by(storm.num) %>%
summarise_at(vars(airtemp_100.1000cm_mean), list(temp = mean), na.rm = TRUE) # finding the mean temperature for each storm event
STRT.2022.per.storm.1$temp <- temp$temp
#making a uniform time series with 15 minute intervals and then I can sum precip by 24/48hour windows
ts <- seq(as.POSIXct("2022-05-01", tz = "America/Anchorage"),
as.POSIXct("2022-10-31", tz = "America/Anchorage"),
by = "15 min")
head(ts)
ts <- as.data.frame(ts)
names(ts) <- c("datetimeAK")
STRT.2022 <- left_join(ts, STRT.2022, by = "datetimeAK")
STRT.2022 <- left_join(STRT.2022, airtempmean, by = "datetimeAK")
STRT.2022$week <- rollapplyr(STRT.2022$mean, 672, sum, na.rm = TRUE, fill = NA, partial = TRUE)
STRT.2022$month <- rollapplyr(STRT.2022$mean, 2688, sum, na.rm = TRUE, fill = NA, partial = TRUE)
STRT.2022$ThreeMonth <- rollapplyr(STRT.2022$mean, 8064, sum, na.rm = TRUE, fill = NA, partial = TRUE)
STRT.2022$temp.week <- rollapplyr(STRT.2022$airtemp_100.1000cm_mean.x, 672, mean, na.rm = TRUE, fill = NA, partial = TRUE)
# joining with storms
STRT.2022.1 <- left_join(STRT.2022.storms.1, STRT.2022, by = c("datetimeAK", "NO3", "fDOM", "SPC", "Turb", "ABS_254", "site.ID",
"CRREL", "CARI")) # week month and 3 month precip totals
# renaming antecedent month
names(STRT.2022.1)[names(STRT.2022.1) == 'month.y'] <- 'month'
names(STRT.2022.1)[names(STRT.2022.1) == 'airtemp_100.1000cm_mean.y'] <- 'airtemp_100.1000cm_mean'
STRT.2022.per.storm.2 <- STRT.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(week), list(precip.week = first), na.rm = TRUE) # grouping weekly precip leading up to storm event
STRT.2022.per.storm.3 <- STRT.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(month), list(precip.month = first), na.rm = TRUE) # groouping monthly precip leading up to a storm
STRT.2022.per.storm.4 <- STRT.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(ThreeMonth), list(ThreeMonth = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
# STRT.2022.per.storm.5 <- STRT.2022.1 %>% group_by(storm.num) %>%
#   summarise_at(vars(temp.week), list(temp.week = first), na.rm = TRUE) # grouping one week mean temperature leading up to a storm
HI.mean.precip.strt.NO3 <- subset(HI.mean.precip.response, year == "2022" & site.ID == "STRT" & response == "NO3")
HI.mean.precip.strt.fDOM <- subset(HI.mean.precip.response, year == "2022" & site.ID == "STRT" & response == "fDOM")
HI.mean.precip.strt.SPC <- subset(HI.mean.precip.response, year == "2022" & site.ID == "STRT" & response == "SPC")
HI.mean.precip.strt.turb <- subset(HI.mean.precip.response, year == "2022" & site.ID == "STRT" & response == "turb")
HI.mean.precip.strt.abs <- subset(HI.mean.precip.response, year == "2022" & site.ID == "STRT" & response == "abs")
# NO3
HI.strt.no3.2022 <- left_join(HI.mean.precip.strt.NO3, STRT.2022.per.storm.1, by = "storm.num")
HI.strt.no3.2022 <- left_join(HI.strt.no3.2022, STRT.2022.per.storm.2, by = "storm.num")
HI.strt.no3.2022 <- left_join(HI.strt.no3.2022, STRT.2022.per.storm.3, by = "storm.num")
HI.strt.no3.2022 <- left_join(HI.strt.no3.2022, STRT.2022.per.storm.4, by = "storm.num")
#HI.strt.no3.2022 <- left_join(HI.strt.no3.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.no3 <- lm(HI.strt.no3.2022$HI ~ HI.strt.no3.2022$precip) # model one with just total precip
strt.lm.no3.2 <- lm(HI.strt.no3.2022$HI ~ HI.strt.no3.2022$precip.week) # model one with just total precip
strt.lm.no3.3 <- lm(HI.strt.no3.2022$HI ~ HI.strt.no3.2022$precip.month) # model one with just total precip
strt.lm.no3.4 <- lm(HI.strt.no3.2022$HI ~ HI.strt.no3.2022$ThreeMonth) # model one with just total precip
# fDOM #
HI.strt.fDOM.2022 <- left_join(HI.mean.precip.strt.fDOM, STRT.2022.per.storm.1, by = "storm.num")
HI.strt.fDOM.2022 <- left_join(HI.strt.fDOM.2022, STRT.2022.per.storm.2, by = "storm.num")
HI.strt.fDOM.2022 <- left_join(HI.strt.fDOM.2022, STRT.2022.per.storm.3, by = "storm.num")
HI.strt.fDOM.2022 <- left_join(HI.strt.fDOM.2022, STRT.2022.per.storm.4, by = "storm.num")
#HI.strt.fDOM.2021 <- left_join(HI.strt.fDOM.2021, STRT.2021.per.storm.5, by = "storm.num")
strt.lm.fDOM <- lm(HI.strt.fDOM.2022$HI ~ HI.strt.fDOM.2022$precip) # model one with just total precip
strt.lm.fDOM.2 <- lm(HI.strt.fDOM.2022$HI ~ HI.strt.fDOM.2022$precip.week) # model one with just total precip
strt.lm.fDOM.3 <- lm(HI.strt.fDOM.2022$HI ~ HI.strt.fDOM.2022$precip.month) # model one with just total precip
strt.lm.fDOM.4 <- lm(HI.strt.fDOM.2022$HI ~ HI.strt.fDOM.2022$ThreeMonth) # model one with just total precip
#strt.lm.fDOM.5 <- lm(HI.poke.fDOM.2022$HI ~ HI.strt.fDOM.2022$temp.week) # model one with just total precip
# SPC #
HI.strt.SPC.2022 <- left_join(HI.mean.precip.strt.SPC, STRT.2022.per.storm.1, by = "storm.num")
HI.strt.SPC.2022 <- left_join(HI.strt.SPC.2022, STRT.2022.per.storm.2, by = "storm.num")
HI.strt.SPC.2022 <- left_join(HI.strt.SPC.2022, STRT.2022.per.storm.3, by = "storm.num")
HI.strt.SPC.2022 <- left_join(HI.strt.SPC.2022, STRT.2022.per.storm.4, by = "storm.num")
#HI.strt.SPC.2021 <- left_join(HI.strt.SPC.2021, STRT.2021.per.storm.5, by = "storm.num")
strt.lm.SPC <- lm(HI.strt.SPC.2022$HI ~ HI.strt.SPC.2022$precip) # model one with just total precip
strt.lm.SPC.2 <- lm(HI.strt.SPC.2022$HI ~ HI.strt.SPC.2022$precip.week) # model one with just total precip
strt.lm.SPC.3 <- lm(HI.strt.SPC.2022$HI ~ HI.strt.SPC.2022$precip.month) # model one with just total precip
strt.lm.SPC.4 <- lm(HI.strt.SPC.2022$HI ~ HI.strt.SPC.2022$ThreeMonth) # model one with just total precip
#strt.lm.SPC.5 <- lm(HI.strt.SPC.2022$HI ~ HI.strt.SPC.2022$temp.week) # model one with just total precip
# turb #
HI.strt.turb.2022 <- left_join(HI.mean.precip.strt.turb, STRT.2022.per.storm.1, by = "storm.num")
HI.strt.turb.2022 <- left_join(HI.strt.turb.2022, STRT.2022.per.storm.2, by = "storm.num")
HI.strt.turb.2022 <- left_join(HI.strt.turb.2022, STRT.2022.per.storm.3, by = "storm.num")
HI.strt.turb.2022 <- left_join(HI.strt.turb.2022, STRT.2022.per.storm.4, by = "storm.num")
#HI.strt.turb.2021 <- left_join(HI.strt.turb.2021, STRT.2021.per.storm.5, by = "storm.num")
strt.lm.turb <- lm(HI.strt.turb.2022$HI ~ HI.strt.turb.2022$precip) # model one with just total precip
strt.lm.turb.2 <- lm(HI.strt.turb.2022$HI ~ HI.strt.turb.2022$precip.week) # model one with just total precip
strt.lm.turb.3 <- lm(HI.strt.turb.2022$HI ~ HI.strt.turb.2022$precip.month) # model one with just total precip
strt.lm.turb.4 <- lm(HI.strt.turb.2022$HI ~ HI.strt.turb.2022$ThreeMonth) # model one with just total precip
#strt.lm.turb.5 <- lm(HI.strt.turb.2022$HI ~ HI.strt.turb.2022$temp.week) # model one with just total precip
# abs #
HI.strt.abs.2022 <- left_join(HI.mean.precip.strt.abs, STRT.2022.per.storm.1, by = "storm.num")
HI.strt.abs.2022 <- left_join(HI.strt.abs.2022, STRT.2022.per.storm.2, by = "storm.num")
HI.strt.abs.2022 <- left_join(HI.strt.abs.2022, STRT.2022.per.storm.3, by = "storm.num")
HI.strt.abs.2022 <- left_join(HI.strt.abs.2022, STRT.2022.per.storm.4, by = "storm.num")
#HI.strt.abs.2021 <- left_join(HI.strt.abs.2021, STRT.2021.per.storm.5, by = "storm.num")
strt.lm.abs <- lm(HI.strt.abs.2022$HI ~ HI.strt.abs.2022$precip) # model one with just total precip
strt.lm.abs.2 <- lm(HI.strt.abs.2022$HI ~ HI.strt.abs.2022$precip.week) # model one with just total precip
strt.lm.abs.3 <- lm(HI.strt.abs.2022$HI ~ HI.strt.abs.2022$precip.month) # model one with just total precip
strt.lm.abs.4 <- lm(HI.strt.abs.2022$HI ~ HI.strt.abs.2022$ThreeMonth) # model one with just total precip
#strt.lm.abs.5 <- lm(HI.strt.abs.2022$HI ~ HI.strt.abs.2022$temp.week) # model one with just total precip
# this would be for intensity but we are not doing this right now if just comparing to the DOD stuff
# sum.time <- FRCH.2018.storms.1 %>%
#   mutate(grp=data.table::rleid(storm.num))%>%
#   group_by(grp) %>%
#   summarise(storm.num=max(storm.num),TOTAL.TIME=difftime(max(DateTime),
#                                                          min(DateTime),units="hour"))%>%
#   group_by(storm.num) %>%
#   summarise(TOTAL.TIME=sum(TOTAL.TIME)) # creating a total time column for each individual storm and then I can generate an intensity metric which would be TotalPrecip/duration of event
#
# HI.frch.fDOM.2.2018 <- left_join(HI.frch.fDOM.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.fDOM.2.2018$TOTAL.TIME <- as.numeric(HI.frch.fDOM.2.2018$TOTAL.TIME)
# HI.frch.fDOM.2.2018$Intensity <- HI.frch.fDOM.2.2018$precip/HI.frch.fDOM.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.fDOM.2 <- lm(HI.frch.fDOM.2.2018$HI ~ HI.frch.fDOM.2.2018$precip + HI.frch.fDOM.2.2018$Intensity) # model one with total precip and intensity
#
# br <- HI.frch.fDOM.2.2018 %>%
#   ggplot(aes(x=Intensity,
#              y=HI)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   stat_poly_eq(formula = frch.formula,
#                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
#                parse = TRUE) +
#   ggtitle("FRCH fDOM") +
#   xlab("Intensity (mm/hr)") +
#   ylab("HI-Solute Storage") +
#   theme_classic() # plot model
#
# HI.frch.SPC.2.2018 <- left_join(HI.frch.SPC.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.SPC.2.2018$TOTAL.TIME <- as.numeric(HI.frch.SPC.2.2018$TOTAL.TIME)
# HI.frch.SPC.2.2018$Intensity <- HI.frch.SPC.2.2018$precip/HI.frch.SPC.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.SPC.2 <- lm(HI.frch.SPC.2.2018$HI ~ HI.frch.SPC.2.2018$precip + HI.frch.SPC.2.2018$Intensity) # model one with total precip and intensity
#
# HI.frch.turb.2.2018 <- left_join(HI.frch.turb.2018, sum.time, by = "storm.num") # merging total time per storm event and the HI per storm
# HI.frch.turb.2.2018$TOTAL.TIME <- as.numeric(HI.frch.turb.2.2018$TOTAL.TIME)
# HI.frch.turb.2.2018$Intensity <- HI.frch.turb.2.2018$precip/HI.frch.turb.2.2018$TOTAL.TIME # Intensity is total precip for individual storm divided by total time so we get mm/hr
#
# frch.lm.turb.2 <- lm(HI.frch.turb.2.2018$HI ~ HI.frch.turb.2.2018$precip + HI.frch.turb.2.2018$Intensity) # model one with total precip and intensity
# day of year # SEASONALITY
STRT.2022.1$day <- julian(STRT.2022.1$datetimeAK, origin = as.POSIXct('2022-01-01', tz = 'America/Anchorage')) # making a fractional day column
STRT.2022.1$day <- as.numeric(STRT.2022.1$day)
STRT.2022.per.storm.5 <- STRT.2022.1 %>% group_by(storm.num) %>%
summarise_at(vars(day), list(doy = first), na.rm = TRUE) # grouping 3 month precip leading up to a storm
HI.strt.fDOM.2.2022 <- left_join(HI.strt.fDOM.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.fDOM.5 <- lm(HI.strt.fDOM.2.2022$HI ~ HI.strt.fDOM.2.2022$doy)
# HI.salcha.fDOM.2.2021 %>%
#   ggplot(aes(x=doy,
#              y=HI)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   stat_poly_eq(formula = salcha.formula,
#                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
#                parse = TRUE) +
#   ggtitle("SALCHA fDOM") +
#   xlab("Day of year") +
#   ylab("HI-Solute Storage") +
#   theme_classic() # plot model
HI.strt.SPC.2.2022 <- left_join(HI.strt.SPC.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.SPC.5 <- lm(HI.strt.SPC.2.2022$HI ~ HI.strt.SPC.2.2022$doy)
HI.strt.turb.2.2022 <- left_join(HI.strt.turb.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.turb.5 <- lm(HI.strt.turb.2.2022$HI ~ HI.strt.turb.2.2022$doy)
HI.strt.no3.2.2022 <- left_join(HI.strt.no3.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.no3.5 <- lm(HI.strt.no3.2.2022$HI ~ HI.strt.no3.2.2022$doy)
HI.strt.abs.2.2022 <- left_join(HI.strt.abs.2022, STRT.2022.per.storm.5, by = "storm.num")
strt.lm.abs.5 <- lm(HI.strt.turb.2.2022$HI ~ HI.strt.turb.2.2022$doy)
HI.strt.2022 <- rbind(HI.strt.no3.2.2022, HI.strt.fDOM.2.2022, HI.strt.SPC.2.2022, HI.strt.turb.2.2022, HI.strt.abs.2.2022) # merging all responses together
HI.strt.2022$date <- as.Date(HI.strt.2022$doy, origin = "2022-01-01")
origin_date <- as.Date("2022-05-13")
HI.strt.2022$TimeSinceChena <- julian(HI.strt.2022$date, origin_date)
write.csv(HI.strt.2022, here("Output_from_analysis", "04_Antecedent_Conditions", "2022", "HI.strt.2022.csv"))
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
library(dataRetrieval)
setwd("~/GitHub/Storms_clean_repo/Storm_Events/2022")
storm_file_list_beta <- list.files(path="FRCH_MOOS_VAUL_POKE_STRT_CARI/",
recursive=F,
pattern=".csv",
full.names=TRUE)
storm_list_beta<-do.call("list", lapply(storm_file_list_beta,
read.csv,
stringsAsFactors=FALSE,
header=T, row.names=1))
storm_file_list_beta = sub("FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
# storm_file_list_beta = sub("~/Documents/Storms_clean_repo/Storm_Events/2022/FRCH_MOOS_VAUL_POKE_STRT_CARI//", storm_file_list_beta, replacement = "")
storm_file_list_beta = sub(".csv", storm_file_list_beta, replacement = "")
names(storm_list_beta) = storm_file_list_beta
for(i in 1:length(storm_list_beta)){
storm_list_beta[[i]][["valuedatetime"]] = as.POSIXct(storm_list_beta[[i]][["valuedatetime"]],
"%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
} # changing character format into datetime
STRT_storm_list_beta = storm_list_beta[c(118:147)] #18
View(STRT_storm_list_beta)
STRT_storm_list_beta = storm_list_beta[c(118:141)] #18
View(STRT_storm_list_beta)
STRT_storm_list_beta = storm_list_beta[c(118:137)] #18
STRT_storm_list_beta = storm_list_beta[c(118:135)] #18
STRT_storm_list_beta = storm_list_beta[c(118:136)] #18
STRT_storm_list_beta = storm_list_beta[c(118:135)] #18
STRT_NO3_storm_list_beta = STRT_storm_list_beta[c(grep("NO3", names(STRT_storm_list_beta)))]
STRT_fDOM_storm_list_beta = STRT_storm_list_beta[c(grep("fDOM", names(STRT_storm_list_beta)))]
STRT_SpCond_storm_list_beta = STRT_storm_list_beta[c(grep("SPC", names(STRT_storm_list_beta)))]
STRT_turb_storm_list_beta = STRT_storm_list_beta[c(grep("turb", names(STRT_storm_list_beta)))]
STRT_abs_storm_list_beta = STRT_storm_list_beta[c(grep("abs", names(STRT_storm_list_beta)))]
STRT_Q_storm_list_beta = STRT_storm_list_beta[c(grep("Q", names(STRT_storm_list_beta)))]
# STRT
for(i in 1:length(STRT_Q_storm_list_beta)){
STRT_Q_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_Q_storm_list_beta[[i]][["datavalue"]]-min(STRT_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_Q_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(STRT_NO3_storm_list_beta)){
STRT_NO3_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_NO3_storm_list_beta[[i]][["datavalue"]]-min(STRT_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_NO3_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(STRT_fDOM_storm_list_beta)){
STRT_fDOM_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_fDOM_storm_list_beta[[i]][["datavalue"]]-min(STRT_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_fDOM_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(STRT_SpCond_storm_list_beta)){
STRT_SpCond_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_SpCond_storm_list_beta[[i]][["datavalue"]]-min(STRT_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_SpCond_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(STRT_turb_storm_list_beta)){
STRT_turb_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_turb_storm_list_beta[[i]][["datavalue"]]-min(STRT_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_turb_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
for(i in 1:length(STRT_abs_storm_list_beta)){
STRT_abs_storm_list_beta[[i]][["datavalue.norm"]] =
(STRT_abs_storm_list_beta[[i]][["datavalue"]]-min(STRT_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))/
(max(STRT_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T)-min(STRT_abs_storm_list_beta[[i]][["datavalue"]], na.rm=T))
}
STRT_NO3_storm <- map2_df(STRT_Q_storm_list_beta, STRT_NO3_storm_list_beta, inner_join, by = "valuedatetime")
# STRT #
STRT_NO3_storm$storm.ID = c(rep("storm1", 103),
rep("storm2", 191),
rep("storm3", 107))
library(xfun)
library(bit)
library(vctrs)
library(tidyverse)
library(lubridate)
library(scales)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
library(readr)
library(googledrive)
library(purrr)
library(here)
Q.daily.2022 <- read.csv(here("Q", "2022", "Q.daily.2022.csv"))
Q.2022 <- read.csv(here("Q", "2022", "Predicted_Q_2022.csv"))
names(Q.2022)[names(Q.2022) == 'DateTimeAK'] <- 'datetimeAK'
names(Q.2022)[names(Q.2022) == 'Site'] <- 'site.ID'
Q.2022$datetimeAK <- ymd_hms(Q.2022$datetimeAK) # converting character to datetime
Q.2022$datetimeAK <- force_tz(Q.2022$datetimeAK, "America/Anchorage") # it already is in AK time so I want to make it recognize it without changing the actually time value
chem.2022 <- read.csv(here("processed_sensor_data", "2022", "SUNA.EXO.int.corr.lab_2022.csv"))
chem.2022 <- chem.2022[c("datetimeAK", "site.ID", "fDOM.QSU.T.turb.col", "SpCond.uScm.mn.adj",
"Turbidity.FNU.mn.adj", "nitrateuM.mn.lab", "abs254.adj.mn")]
chem.2022$datetimeAK <- ymd_hms(chem.2022$datetimeAK) # converting character to datetime
chem.2022$datetimeAK <- force_tz(chem.2022$datetimeAK, "America/Anchorage") # converting character to datetime
names(chem.2022) <- c("datetimeAK", "site.ID", "fDOM", "SPC", "Turb", "NO3", "ABS_254")
FRCH.2022 <-  subset(chem.2022, site.ID == "FRCH")
FRCH.2022 <- FRCH.2022[-c(14573:14900), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
MOOS.2022 <-  subset(chem.2022, site.ID == "MOOS")
MOOS.2022 <- MOOS.2022[-c(14666:15037), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
POKE.2022 <-  subset(chem.2022, site.ID == "POKE")
POKE.2022 <- POKE.2022[-c(14481:14857), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
VAUL.2022 <-  subset(chem.2022, site.ID == "VAUL")
VAUL.2022 <- VAUL.2022[-c(14198:14548), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
STRT.2022 <-  subset(chem.2022, site.ID == "STRT")
STRT.2022 <- STRT.2022[-c(12278:12787), ] # removing unnecessary rows that correspond to when I merge the file the NO3 from the lab merges weird with datetimes from another section within the dataframe
DOD.2022 <- rbind(FRCH.2022, MOOS.2022, POKE.2022,
VAUL.2022, STRT.2022)
DOD.2022 <- full_join(DOD.2022, Q.2022) # merging chem and discharge data
frch.final.discharge.2022 <- subset(Q.2022, site.ID == "FRCH")
strt.final.discharge.2022 <- subset(Q.2022, site.ID == "STRT")
poke.final.discharge.2022 <- subset(Q.2022, site.ID == "POKE")
vaul.final.discharge.2022 <- subset(Q.2022, site.ID == "VAUL")
moos.final.discharge.2022 <- subset(Q.2022, site.ID == "MOOS")
#
# # join Q and chem data
# # FRCH #
FRCH = full_join(frch.final.discharge.2022, FRCH.2022)
# MOOS #
MOOS = full_join(moos.final.discharge.2022, MOOS.2022)
# STRT #
STRT = full_join(strt.final.discharge.2022, STRT.2022)
# POKE #
POKE = full_join(poke.final.discharge.2022, POKE.2022)
# VAUL #
VAUL = full_join(vaul.final.discharge.2022, VAUL.2022)
CPCRW <- read_csv(here("Climate", "Precip", "CPCRW.RainGauge.2022.final.csv"))
CPCRW$datetimeAK <- force_tz(CPCRW$datetimeAK, "America/Anchorage") # it already is in AK time so I want to make it recognize it without changing the actually time value
frch.precip.discharge <- full_join(frch.final.discharge.2022, CPCRW) # merging precip data and discharge
moos.precip.discharge <- full_join(moos.final.discharge.2022, CPCRW) # merging precip data and discharge
poke.precip.discharge <- full_join(poke.final.discharge.2022, CPCRW) # merging precip data and discharge
vaul.precip.discharge <- full_join(vaul.final.discharge.2022, CPCRW) # merging precip data and discharge
strt.precip.discharge <- full_join(strt.final.discharge.2022, CPCRW) # merging precip data and discharge
#cari.precip.discharge <- full_join(cari.final.discharge.2022, CPCRW) # merging precip data and discharge
frch.precip.discharge <- frch.precip.discharge[order(frch.precip.discharge$datetimeAK),]
moos.precip.discharge <- moos.precip.discharge[order(moos.precip.discharge$datetimeAK),]
poke.precip.discharge <- poke.precip.discharge[order(poke.precip.discharge$datetimeAK),]
vaul.precip.discharge <- vaul.precip.discharge[order(vaul.precip.discharge$datetimeAK),]
strt.precip.discharge <- strt.precip.discharge[order(strt.precip.discharge$datetimeAK),]
#cari.precip.discharge <- cari.precip.discharge[order(cari.precip.discharge$datetimeAK),]
ts <- seq(as.POSIXct("2022-04-01", tz = "America/Anchorage"),
as.POSIXct("2022-11-01", tz = "America/Anchorage"),
by = "30 min")
head(ts)
ts <- as.data.frame(ts)
names(ts) <- c("datetimeAK")
frch.precip.discharge <- left_join(ts, frch.precip.discharge, by = "datetimeAK")
### Sum daily discharge ###
frch.precip.discharge$twentyfour <- rollapplyr(frch.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
frch.precip.discharge$fourtyeight <- rollapplyr(frch.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
moos.precip.discharge$twentyfour <- rollapplyr(moos.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
moos.precip.discharge$fourtyeight <- rollapplyr(moos.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$twentyfour <- rollapplyr(strt.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$fourtyeight <- rollapplyr(strt.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$twentyfour <- rollapplyr(vaul.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$fourtyeight <- rollapplyr(vaul.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$twentyfour <- rollapplyr(poke.precip.discharge$mean, 48, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$fourtyeight <- rollapplyr(poke.precip.discharge$mean, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
#
# Greater than 5 #
frch.five.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
frch.five.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
moos.five.twenty.four <- moos.precip.discharge[which(moos.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
moos.five.fourty.eight <- moos.precip.discharge[which(moos.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
strt.five.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
strt.five.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
vaul.five.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
vaul.five.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
poke.five.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
poke.five.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
# Greater than 10 #
frch.ten.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
frch.ten.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
moos.ten.twenty.four <- moos.precip.discharge[which(moos.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
moos.ten.fourty.eight <- moos.precip.discharge[which(moos.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
strt.ten.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
strt.ten.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
vaul.ten.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
vaul.ten.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
poke.ten.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
poke.ten.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(10,0),
axes=F, xlab="", ylab="")
axis(side = 4)
par(mfrow=c(1,1))
abline(v = as.POSIXct(vaul.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(vaul.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-05-01 0:00:00","2022-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(10,0),
axes=F, xlab="", ylab="")
par(new = T)
plot(VAUL$fDOM ~ VAUL$datetimeAK, xlab="", ylab="", col="maroon",
xlim = as.POSIXct(c("2022-05-01 00:00:00","2022-10-31 23:45:00"), tz="America/Anchorage"))
abline(v= as.POSIXct("2022-09-14 05:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-09-22 04:30:00", tz="America/Anchorage"), col="purple")
# storm 1 #
plot(VAUL$Q ~ VAUL$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-08-01 00:00:00","2022-08-15 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 200))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-08-01 00:00:00","2022-08-15 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(vaul.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(vaul.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-08-01 20:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-08-03 04:30:00", tz="America/Anchorage"), col="purple")
VAUL_storm1_08_01 = VAUL[VAUL$datetimeAK > as.POSIXct("2022-08-01 20:30:00", tz="America/Anchorage") &
VAUL$datetimeAK < as.POSIXct("2022-08-03 04:30:00", tz="America/Anchorage"),]
plot(VAUL_storm1_08_01$Q ~ as.POSIXct(VAUL_storm1_08_01$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(50,150), col="blue", main="VAUL 220801 storm 1",
xlim = as.POSIXct(c("2022-08-01 00:00:00","2022-08-04 23:45:00"), tz="America/Anchorage"))
plot(VAUL$Q ~ VAUL$datetimeAK, type="p", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2022-09-14 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(0, 500))
par(new = T)
plot(CPCRW$mean ~ CPCRW$datetimeAK, type="h",
xlim = as.POSIXct(c("2022-09-14 00:00:00","2022-09-30 23:45:00"), tz="America/Anchorage"),
ylim = c(8,0),
axes=F, xlab="", ylab="")
axis(side = 4)
mtext(side = 4, line = 3, 'CRREL Met Station precip. (mm)')
abline(v = as.POSIXct(vaul.five.fourty.eight$datetimeAK), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(vaul.five.twenty.four$datetimeAK), col="green", lwd = 0.1)
abline(v= as.POSIXct("2022-09-14 05:30:00", tz="America/Anchorage"), col="purple")
abline(v= as.POSIXct("2022-09-22 04:30:00", tz="America/Anchorage"), col="purple")
VAUL_storm2_09_14 = VAUL[VAUL$datetimeAK > as.POSIXct("2022-09-14 05:30:00", tz="America/Anchorage") &
VAUL$datetimeAK < as.POSIXct("2022-09-22 04:30:00", tz="America/Anchorage"),]
plot(VAUL_storm2_09_14$Q ~ as.POSIXct(VAUL_storm2_09_14$datetimeAK, tz="America/Anchorage"), xlab="", ylab="Q (L/sec)",ylim = c(50,450), col="blue", main="VAUL 220914 storm 2",
xlim = as.POSIXct(c("2022-09-14 00:00:00","2022-09-23 23:45:00"), tz="America/Anchorage"))
VAUL_storm1_08_01_Q = subset(VAUL_storm1_08_01, select = c("datetimeAK","Q"))
names(VAUL_storm1_08_01_Q) = c("valuedatetime","datavalue")
VAUL_storm1_08_01_NO3 = subset(VAUL_storm1_08_01, select = c("datetimeAK","NO3"))
names(VAUL_storm1_08_01_NO3) = c("valuedatetime","datavalue")
VAUL_storm1_08_01_fDOM = subset(VAUL_storm1_08_01, select = c("datetimeAK","fDOM"))
names(VAUL_storm1_08_01_fDOM) = c("valuedatetime","datavalue")
VAUL_storm1_08_01_SPC = subset(VAUL_storm1_08_01, select = c("datetimeAK","SPC"))
names(VAUL_storm1_08_01_SPC) = c("valuedatetime","datavalue")
VAUL_storm1_08_01_turb = subset(VAUL_storm1_08_01, select = c("datetimeAK","Turb"))
names(VAUL_storm1_08_01_turb) = c("valuedatetime","datavalue")
VAUL_storm1_08_01_abs = subset(VAUL_storm1_08_01, select = c("datetimeAK","ABS_254"))
names(VAUL_storm1_08_01_abs) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_Q = subset(VAUL_storm2_09_14, select = c("datetimeAK","Q"))
names(VAUL_storm2_09_14_Q) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_NO3 = subset(VAUL_storm2_09_14, select = c("datetimeAK","NO3"))
names(VAUL_storm2_09_14_NO3) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_fDOM = subset(VAUL_storm2_09_14, select = c("datetimeAK","fDOM"))
names(VAUL_storm2_09_14_fDOM) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_SPC = subset(VAUL_storm2_09_14, select = c("datetimeAK","SPC"))
names(VAUL_storm2_09_14_SPC) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_turb = subset(VAUL_storm2_09_14, select = c("datetimeAK","Turb"))
names(VAUL_storm2_09_14_turb) = c("valuedatetime","datavalue")
VAUL_storm2_09_14_abs = subset(VAUL_storm2_09_14, select = c("datetimeAK","ABS_254"))
names(VAUL_storm2_09_14_abs) = c("valuedatetime","datavalue")
write.csv(VAUL_storm1_08_01, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01.csv"))
write.csv(VAUL_storm1_08_01_Q, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_Q.csv"))
write.csv(VAUL_storm1_08_01_NO3, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_NO3.csv"))
write.csv(VAUL_storm1_08_01_fDOM, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_fDOM.csv"))
write.csv(VAUL_storm1_08_01_SPC, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_SPC.csv"))
write.csv(VAUL_storm1_08_01_turb, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_turb.csv"))
write.csv(VAUL_storm1_08_01_abs, here("Storm_Events", "2022", "VAUL", "VAUL_storm1_08_01_abs.csv"))
write.csv(VAUL_storm2_09_14, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14.csv"))
write.csv(VAUL_storm2_09_14_Q, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_Q.csv"))
write.csv(VAUL_storm2_09_14_NO3, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_NO3.csv"))
write.csv(VAUL_storm2_09_14_fDOM, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_fDOM.csv"))
write.csv(VAUL_storm2_09_14_SPC, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_SPC.csv"))
write.csv(VAUL_storm2_09_14_turb, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_turb.csv"))
write.csv(VAUL_storm2_09_14_abs, here("Storm_Events", "2022", "VAUL", "VAUL_storm2_09_14_abs.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(boot)
library(lubridate)
library(here)
Sys.which("python")
use_python("/usr/local/bin/python3")
options(tz="America/Anchorage")
# install pandas #
virtualenv_create("r-reticulate")
# RETICULATE_PYTHON = "lib/python3.8"
reticulate::py_config()
reticulate::py_install("pandas")
reticulate::repl_python()
